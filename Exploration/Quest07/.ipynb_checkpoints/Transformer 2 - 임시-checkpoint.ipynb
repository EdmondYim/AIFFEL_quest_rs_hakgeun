{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6b47dc-f154-4083-9af7-1f19e7a5e877",
   "metadata": {},
   "source": [
    "# 한국어 데이터로 챗봇 만들기\n",
    "프로젝트 제출 루브릭\n",
    "| **학습 목표** | **평가 기준** |\n",
    "|----------------|----------------|\n",
    "| 한국어 전처리를 통해 학습 데이터셋을 구축하였다. | 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다. |\n",
    "| 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다. | 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다. |\n",
    "| 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다. | 한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a79cd-5fd1-4327-b57a-dfeafa5a8899",
   "metadata": {},
   "source": [
    "# Step 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "23c8f3a8-4883-45e0-830a-b44e376fb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "32e3439a-9021-4b80-aef7-5a95c4559aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee125c-3a04-44d5-b9d7-3dd01e4ae18b",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b12deaf-d8d8-4d00-adb4-b4aed6585b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv\n",
    "#!mv ChatbotData.csv data/chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab255b0-762b-4fdb-83f9-bd764382d674",
   "metadata": {},
   "source": [
    "데이터 자체가 이런식으로 표현되어 있다.\n",
    "\n",
    "| **Q** | **A** | **Label** |\n",
    "|----------------|----------------|----------------|\n",
    "|12시 땡!, |하루가 또 가네요., |0|\n",
    "\n",
    "---\n",
    "\n",
    "데이터의 Label은 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링로 되어있다.\n",
    "\n",
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab26c0-f278-4194-8f9a-e4f0981a3844",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cbac6b56-bbfd-49b0-9c60-e4c250dc5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a94aad0a-2b30-4b5e-909c-d4e36380bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "questions = [preprocess_sentence(q) for q in df['Q']]\n",
    "answers   = [preprocess_sentence(a) for a in df['A']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5975c1b-1573-4395-892b-09f4c73ad9c9",
   "metadata": {},
   "source": [
    "# Step 3. SentencePiece 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c6629654-30e3-47ef-a927-20f54491d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823.0\n"
     ]
    }
   ],
   "source": [
    "corpus = questions + answers\n",
    "print('전체 샘플 수 :', len(corpus)/2)\n",
    "with open('data/chatbot/corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for s in corpus:\n",
    "        f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "110240cc-a19b-4c10-a77c-3c58113a7a66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/chatbot/corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: data/chatbot/chatbot_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: data/chatbot/corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23646 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=369707\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1241\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23646 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=171185\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 18516 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 20712\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 20712 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10948 obj=11.1052 num_tokens=40674 num_tokens/piece=3.7152\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9519 obj=10.2576 num_tokens=40778 num_tokens/piece=4.28385\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=7139 obj=10.5566 num_tokens=43809 num_tokens/piece=6.13657\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7138 obj=10.5022 num_tokens=43815 num_tokens/piece=6.13827\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5353 obj=10.9562 num_tokens=47769 num_tokens/piece=8.92378\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5353 obj=10.886 num_tokens=47770 num_tokens/piece=8.92397\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4014 obj=11.5505 num_tokens=52056 num_tokens/piece=12.9686\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4014 obj=11.4621 num_tokens=52175 num_tokens/piece=12.9983\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3010 obj=12.146 num_tokens=56898 num_tokens/piece=18.903\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3010 obj=12.0462 num_tokens=57026 num_tokens/piece=18.9455\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2257 obj=13.1607 num_tokens=62369 num_tokens/piece=27.6336\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2257 obj=13.013 num_tokens=62495 num_tokens/piece=27.6894\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2200 obj=13.2322 num_tokens=63146 num_tokens/piece=28.7027\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2200 obj=13.2113 num_tokens=63217 num_tokens/piece=28.735\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: data/chatbot/chatbot_tokenizer.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: data/chatbot/chatbot_tokenizer.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='data/chatbot/corpus.txt',\n",
    "    model_prefix='data/chatbot/chatbot_tokenizer',\n",
    "    vocab_size=8000,\n",
    "    model_type='unigram',\n",
    "    character_coverage=1.0,\n",
    "    pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
    ")\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='data/chatbot/chatbot_tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2f2415e0-1a83-41d7-b8e9-a4e87c4d462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징 + BOS/EOS\n",
    "tokenized_questions = [sp.encode_as_ids(q) for q in questions]\n",
    "tokenized_answers   = [[sp.bos_id()] + sp.encode_as_ids(a) + [sp.eos_id()] for a in answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640a84c-1fdb-4274-9757-0f967a4b4d56",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af65d8-7b12-459c-848b-3478333ce714",
   "metadata": {},
   "source": [
    "## Step 4-1. Model class 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4245b215-84dd-497c-a7ea-1ff0c2cc0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, pos, i, d_model):\n",
    "        return pos / (10000 ** ((2 * (i // 2)) / d_model))\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        angle_rads = self._get_angles(\n",
    "            torch.arange(position, dtype=torch.float32).unsqueeze(1),\n",
    "            torch.arange(d_model, dtype=torch.float32).unsqueeze(0),\n",
    "            d_model\n",
    "        )\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "        return pos_encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47a2a558-72c3-40d6-8129-3b7c64ff4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "    depth = key.size(-1)\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "    if mask is not None:\n",
    "        logits = logits.masked_fill(mask == 0, -1e9)\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "94d13111-c972-4946-97e4-d4f5e4bc716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense   = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "        self.out_dense   = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        query = self.split_heads(self.query_dense(query), batch_size)\n",
    "        key   = self.split_heads(self.key_dense(key), batch_size)\n",
    "        value = self.split_heads(self.value_dense(value), batch_size)\n",
    "\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "de532363-f9d3-429d-94d0-412a9523fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x, pad_id=0):\n",
    "    return (x != pad_id).unsqueeze(1).unsqueeze(2).float()\n",
    "\n",
    "def create_look_ahead_mask(seq_len):\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e826f523-fb66-43cc-b906-45b4e3f6110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_out = self.mha(x, x, x, mask)\n",
    "        attn_out = self.dropout1(attn_out)\n",
    "        out1 = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.dropout2(ffn_out)\n",
    "        out2 = self.norm2(out1 + ffn_out)\n",
    "        return out2\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_layers, ff_dim, d_model, num_heads, max_len=40, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "29d0f84e-9aef-4805-a1f2-60ea645d3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        self_attn = self.self_mha(x, x, x, look_ahead_mask)\n",
    "        self_attn = self.dropout1(self_attn)\n",
    "        out1 = self.norm1(x + self_attn)\n",
    "\n",
    "        encdec_attn = self.encdec_mha(out1, enc_output, enc_output, padding_mask)\n",
    "        encdec_attn = self.dropout2(encdec_attn)\n",
    "        out2 = self.norm2(out1 + encdec_attn)\n",
    "\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)\n",
    "        return out3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_layers, ff_dim, d_model, num_heads, max_len=200, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_output, look_ahead_mask, padding_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6e25740f-f1a4-48e3-910d-8dbe4a4c740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, num_layers=6, units=2048, d_model=512, num_heads=8, dropout=0.1, max_len=200):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, num_layers, units, d_model, num_heads, max_len, dropout)\n",
    "        self.decoder = Decoder(vocab_size, num_layers, units, d_model, num_heads, max_len, dropout)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        enc_padding_mask = create_padding_mask(inputs, sp.pad_id())\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs.size(1)).to(inputs.device)\n",
    "        look_ahead_mask = look_ahead_mask.unsqueeze(0).unsqueeze(1)\n",
    "        dec_padding_mask = create_padding_mask(inputs, sp.pad_id())\n",
    "\n",
    "        enc_output = self.encoder(inputs, enc_padding_mask)\n",
    "        dec_output = self.decoder(dec_inputs, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        logits = self.final_linear(dec_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bbdfa-f794-4a63-8a56-0074126507f0",
   "metadata": {},
   "source": [
    "## Step 4-2. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "102e9701-7a2f-4d49-bdf7-d47aea72cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9458 | Valid: 1182 | Test: 1183\n"
     ]
    }
   ],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, qs, ans):\n",
    "        self.qs, self.ans = qs, ans\n",
    "    def __len__(self): return len(self.qs)\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.qs[i]), torch.tensor(self.ans[i])\n",
    "\n",
    "def collate(batch):\n",
    "    src, tgt = zip(*batch)\n",
    "    src = pad_sequence(src, batch_first=True, padding_value=sp.pad_id())\n",
    "    tgt = pad_sequence(tgt, batch_first=True, padding_value=sp.pad_id())\n",
    "    return src, tgt\n",
    "\n",
    "\n",
    "# 전체 데이터셋\n",
    "full_dataset = ChatbotDataset(tokenized_questions, tokenized_answers)\n",
    "\n",
    "# 80% train, 10% valid, 10% test\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "valid_size = int(0.1 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, valid_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, collate_fn=collate)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Valid: {len(valid_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b406e-607d-454b-ab5c-b8b5fec7abbe",
   "metadata": {},
   "source": [
    "## Step 4-3. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa5b4f27-9a60-41d2-b442-b135ab298dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    \"\"\"\n",
    "    Transformer 논문의 학습률 스케줄링\n",
    "    lr = d_model^(-0.5) * min(step^(-0.5), step * warmup_steps^(-1.5))\n",
    "    \"\"\"\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        step = step + 1  # 0-based -> 1-based\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "772226f2-7d58-48fe-9c58-9b51f904e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "VOCAB_SIZE = sp.get_piece_size()\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=3,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=8,\n",
    "    dropout=0.1,\n",
    "    max_len=40\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1.0, betas=(0.9, 0.98), eps=1e-9)  # lr은 scheduler가 조절\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(d_model=128, warmup_steps=4000))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61c075fc-8318-48d7-afb6-ec5e68d47ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 경로\n",
    "os.makedirs(\"data/chatbot/checkpoints\", exist_ok=True)\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "044f1f20-879c-461a-bb39-e048ff9b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, crit):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_target = tgt[:, 1:].contiguous().view(-1)\n",
    "        logits = model(src, tgt_input)\n",
    "        loss = crit(logits.view(-1, VOCAB_SIZE), tgt_target)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "81163c61-67c9-4a71-a4c0-4766ac3fdb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, opt, scheduler, crit):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for step, (src, tgt) in enumerate(loader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_target = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(src, tgt_input)\n",
    "        loss = crit(logits.view(-1, VOCAB_SIZE), tgt_target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"  Step {step+1} | Loss: {loss.item():.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "67208309-c219-48d7-9b71-d0a88f83d876",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (44) must match the size of tensor b (40) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, N_EPOCHS + \u001b[32m1\u001b[39m):\n\u001b[32m      3\u001b[39m     start = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     val_loss = evaluate(model, valid_loader, criterion)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_loss < best_val_loss:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[160]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, opt, scheduler, crit)\u001b[39m\n\u001b[32m      7\u001b[39m tgt_target = tgt[:, \u001b[32m1\u001b[39m:].contiguous().view(-\u001b[32m1\u001b[39m)\n\u001b[32m      9\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m loss = crit(logits.view(-\u001b[32m1\u001b[39m, VOCAB_SIZE), tgt_target)\n\u001b[32m     12\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, inputs, dec_inputs)\u001b[39m\n\u001b[32m     12\u001b[39m dec_padding_mask = create_padding_mask(inputs, sp.pad_id())\n\u001b[32m     14\u001b[39m enc_output = \u001b[38;5;28mself\u001b[39m.encoder(inputs, enc_padding_mask)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m dec_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.final_linear(dec_output)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[153]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, enc_output, look_ahead_mask, padding_mask):\n\u001b[32m     45\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.embedding(x) * math.sqrt(\u001b[38;5;28mself\u001b[39m.d_model)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dec_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mPositionalEncoding.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_encoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (44) must match the size of tensor b (40) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start = time.time()\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion)\n",
    "    val_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"data/chatbot/checkpoints/best_transformer.pth\")\n",
    "        print(f\"  [SAVE] Best model saved | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(f'Epoch {epoch:02d} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | '\n",
    "          f'PPL: {math.exp(val_loss):6.2f} | {time.time()-start:.1f}s\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fc366-af93-4ca6-bd6a-c40a1c1443a1",
   "metadata": {},
   "source": [
    "# Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d073c5-731f-4050-8248-3a4c1324dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"data/chatbot/checkpoints/best_transformer.pth\"))\n",
    "print(\"Best model loaded.\\n\")\n",
    "\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f\"=== FINAL TEST LOSS: {test_loss:.4f} | PPL: {math.exp(test_loss):6.2f} ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a288865-400e-4058-a31a-c3fc096a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def respond(model, sp, sentence, max_len=50):\n",
    "    model.eval()\n",
    "    src = torch.tensor([sp.encode_as_ids(sentence)], device=device)\n",
    "    enc_padding_mask = create_padding_mask(src, sp.pad_id())\n",
    "    enc_output = model.encoder(src, enc_padding_mask)\n",
    "\n",
    "    dec_input = torch.tensor([[sp.bos_id()]], device=device)\n",
    "    output_ids = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_input.size(1)).to(device)\n",
    "        look_ahead_mask = look_ahead_mask.unsqueeze(0).unsqueeze(1)\n",
    "        dec_padding_mask = create_padding_mask(src, sp.pad_id())\n",
    "\n",
    "        dec_output = model.decoder(dec_input, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        logits = model.final_linear(dec_output[:, -1, :])\n",
    "        next_id = logits.argmax(dim=-1).item()\n",
    "\n",
    "        output_ids.append(next_id)\n",
    "        if next_id == sp.eos_id():\n",
    "            break\n",
    "\n",
    "        dec_input = torch.cat([dec_input, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "\n",
    "    return sp.decode_ids(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33304ba-c285-4372-87b1-aab13dcae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = test_dataset.indices  # 원본 df에서의 인덱스 리스트\n",
    "test_questions = [df.Q[idx] for idx in test_indices]\n",
    "test_answers   = [df.A[idx] for idx in test_indices]\n",
    "\n",
    "for i in range(len(test_questions)):\n",
    "    q = test_questions[i]\n",
    "    real_a = test_answers[i]\n",
    "    pred_a = respond(model, sp, q)\n",
    "\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"실제 A: {real_a}\")\n",
    "    print(f\"모델 A: {pred_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c6819-c29f-4c78-9fd6-ef944818af42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
