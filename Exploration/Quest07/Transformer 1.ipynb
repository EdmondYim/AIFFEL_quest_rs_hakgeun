{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e962164c-3fb8-4bfe-8333-c078dec20851",
   "metadata": {},
   "source": [
    "# ㅇㅇ\n",
    "- 코드 구현하는 단원만 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0400d-4923-4704-bcd4-9d8c999dc79f",
   "metadata": {},
   "source": [
    "# 4. 트랜스포머의 입력 이해하기 - 입력 방식을 알아보고, PositionalEncoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c121a9d-4116-4c3d-91b7-fa13b198cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.12/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a44a90e0-503f-49d5-9d55-379adf999998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b8fee0e-48ce-4c14-9187-7dbaf1be4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Positional Encoding 클래스\n",
    "\n",
    "        Args:\n",
    "            position (int): 문장의 최대 길이 (max sequence length)\n",
    "            d_model (int): 임베딩 벡터의 차원 (model dimension)\n",
    "        \"\"\"\n",
    "        \n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        # 위치별로 미리 계산된 사인/코사인 기반 위치 인코딩 행렬 생성\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        \"\"\"\n",
    "        각 위치(pos)와 차원(i)에 대해 angle 값을 계산.\n",
    "\n",
    "        Args:\n",
    "            position (Tensor): [position, 1] 위치 인덱스\n",
    "            i (Tensor): [1, d_model] 차원 인덱스\n",
    "            d_model (int): 임베딩 차원\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 위치-차원별 angle 값\n",
    "        \"\"\"\n",
    "        # (2 * (i // 2)) : 짝수/홀수 차원 구분용\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "        # 사실 위처럼 지수계산보다는 log계산으로 푸는 것이 더 안정적이라 한다. \n",
    "        # angle_rates = torch.exp(- (2 * (i // 2)) * torch.log(torch.tensor(10000.0)) / d_model)\n",
    "        # return position * angle_rates.unsqueeze(0)\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        \"\"\"\n",
    "        전체 위치 인코딩 행렬을 생성.\n",
    "\n",
    "        Returns:\n",
    "            pos_encoding: [1, position, d_model]\n",
    "        \"\"\"\n",
    "        # 각 위치에 대해 0 ~ position-1까지의 인덱스 생성 → shape: [position, 1]\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        # 각 차원에 대해 0 ~ d_model-1까지의 인덱스 생성 → shape: [1, d_model]\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # 각 위치와 차원에 대한 각도(angle) 계산\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "\n",
    "        # 짝수 인덱스(0, 2, 4, ...)에는 sin, 홀수 인덱스(1, 3, 5, ...)에는 cos 적용\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # 최종 위치 인코딩 행렬 초기화\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines  # 짝수 차원 → sin 값\n",
    "        pos_encoding[:, 1::2] = cosines  # 홀수 차원 → cos 값\n",
    "\n",
    "        # 배치 차원 추가: shape [1, position, d_model]\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        입력 임베딩(x)에 위치 인코딩을 더함.\n",
    "        Args:\n",
    "            x (Tensor): [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            Tensor: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # 입력 길이(seq_len)에 맞는 부분만 잘라서 더함\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee3a397c-e583-4187-bad9-03e6551ca6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(30, 256)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 256))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73eee0a-a513-45b6-8d79-a2b97ae9845b",
   "metadata": {},
   "source": [
    "# 6. Scaled dot-product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cdd4bdf-c93d-4b1f-beba-785bccd65cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention\n",
    "    -------------------------------------------------------\n",
    "    query: (batch_size, heads, seq_len_q, depth)\n",
    "    key:   (batch_size, heads, seq_len_k, depth)\n",
    "    value: (batch_size, heads, seq_len_v, depth)\n",
    "    mask:  (optional) attention mask tensor\n",
    "    return: (output, attention_weights)\n",
    "    -------------------------------------------------------\n",
    "    핵심 수식:\n",
    "        Attention(Q, K, V) = softmax( (QK^T) / sqrt(d_k) ) * V\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Query와 Key의 내적(dot-product)을 통해 유사도(score) 계산\n",
    "    #    - key.transpose(-1, -2): 마지막 두 차원을 전치하여 (depth, seq_len_k)\n",
    "    #    - 결과 shape: (batch_size, heads, seq_len_q, seq_len_k)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) Key 벡터의 차원(depth)에 따라 스케일링 (정규화)\n",
    "    #    - 큰 값으로 인한 softmax gradient vanishing 방지\n",
    "    #    - sqrt(depth)로 나눠줌\n",
    "    depth = key.size(-1)\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크(mask)가 주어진 경우 적용\n",
    "    #    - 패딩 토큰 또는 미래 토큰(Decoder의 causal mask) 무시용\n",
    "    #    - 매우 작은 값(-1e9)을 더해 softmax에서 해당 위치의 확률을 0으로 만듦\n",
    "    if mask is not None:\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) Softmax를 통해 attention weight 계산\n",
    "    #    - 각 query에 대해 모든 key의 가중치 분포 생성\n",
    "    #    - dim=-1: seq_len_k 차원(즉, key 차원)에 대해 정규화\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weight를 value에 곱해 weighted sum 계산\n",
    "    #    - 결과: (batch_size, heads, seq_len_q, depth)\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    # output: context vector, attention_weights: 각 token 간 주의 분포\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78cd5a-b430-44f1-9f5b-f00f2bd402a9",
   "metadata": {},
   "source": [
    "이외에도 Additive Attention (Bahdanau)와 Bilinear Attention(“General” Luong Attention)가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99abb051-a6ac-466a-b8eb-6281feaab5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Bahdanau Attention with Mask\n",
    "# ===========================================\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim, attn_dim):\n",
    "        super().__init__()\n",
    "        # Query와 Key를 동일한 차원(attn_dim)으로 변환하기 위한 가중치 행렬\n",
    "        self.Wq = nn.Linear(query_dim, attn_dim)\n",
    "        self.Wk = nn.Linear(key_dim, attn_dim)\n",
    "        # tanh 출력(attn_dim)을 스칼라 값으로 바꾸는 벡터 v (유사도 점수용)\n",
    "        self.v = nn.Linear(attn_dim, 1)\n",
    "\n",
    "    def forward(self, query, keys, values, mask=None):\n",
    "        \"\"\"\n",
    "        query : [batch_size, 1, query_dim] -> 디코더의 현재 hidden state \n",
    "        keys : [batch_size, seq_len, key_dim] -> 인코더의 hidden states \n",
    "        values: [batch_size, seq_len, value_dim] -> 실제 attention으로 가중합할 값 (보통 key와 동일)\n",
    "        mask  : [batch_size, seq_len] (PAD 위치: 0, 실제 단어: 1)\n",
    "        \"\"\"\n",
    "        # (1) Query, Key를 각각 attn_dim 차원으로 변환\n",
    "        q_proj = self.Wq(query)\n",
    "        k_proj = self.Wk(keys)\n",
    "\n",
    "        # (2) 비선형 결합 (Additive 방식) # 각 Query와 Key의 조합에 대해 tanh(Wq*q + Wk*k) \n",
    "        # broadcasting에 의해 q_proj이 seq_len 차원으로 자동 확장됨\n",
    "        score = self.v(torch.tanh(q_proj + k_proj)).squeeze(-1)  # [batch, seq_len]\n",
    "\n",
    "        # 마스크 적용\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # (3) softmax를 적용하여 attention weight 계산\n",
    "        attn_weights = F.softmax(score, dim=-1).unsqueeze(-1)  # [batch, seq_len, 1]\n",
    "        # (4) attention weight로 values의 가중합 (context vector)\n",
    "        context = torch.sum(attn_weights * values, dim=1)       # [batch, value_dim]\n",
    "        # (5) context: attention 결과 벡터, attn_weights: 가중치 분포\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07055e74-d561-4a04-9b1a-c3b0c0fed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Bilinear (Luong General) Attention with Mask\n",
    "# ===========================================\n",
    "class BilinearAttention(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim):\n",
    "        super().__init__()\n",
    "        # Key를 Query 차원으로 선형 변환하는 가중치 행렬 W_a (bias 없음) \n",
    "        # 즉, W_a ∈ ℝ^(key_dim × query_dim)\n",
    "        self.Wa = nn.Linear(key_dim, query_dim, bias=False)\n",
    "\n",
    "    def forward(self, query, keys, values, mask=None):\n",
    "        \"\"\"\n",
    "        query : [batch_size, query_len, query_dim]\n",
    "        keys  : [batch_size, seq_len, key_dim]\n",
    "        values: [batch_size, seq_len, value_dim]\n",
    "        mask  : [batch_size, 1, seq_len] (PAD 위치: 0)\n",
    "        \"\"\"\n",
    "        # (1) Key를 W_a로 변환하여 Query와 동일한 차원으로 맞춤\n",
    "        keys_transformed = self.Wa(keys)\n",
    "        # (2) Query와 변환된 Key의 쌍선형 내적 계산 (qᵀW_a k) \n",
    "        # -> (batch, query_len, seq_len)\n",
    "        score = torch.matmul(query, keys_transformed.transpose(-1, -2))  # [batch, query_len, seq_len]\n",
    "\n",
    "        # 마스크 적용\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # (3) softmax로 attention weight 계산 (각 query에 대한 key 중요도)\n",
    "        attn_weights = F.softmax(score, dim=-1)\n",
    "        # (4) attention weight를 이용해 values의 가중합(context vector) 계산 \n",
    "        # -> (batch, query_len, value_dim)\n",
    "        context = torch.matmul(attn_weights, values)\n",
    "        # (5) context: attention 출력, attn_weights: attention 분포\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3419c-d16f-459c-a586-8a6273144832",
   "metadata": {},
   "source": [
    "# 7. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90d282a9-44dd-4176-b307-af3ce9643fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads  # 병렬적으로 나눠 계산할 헤드(head)의 개수\n",
    "        self.d_model = d_model      # 입력/출력의 전체 차원 (embedding dimension)\n",
    "\n",
    "        # d_model은 num_heads로 정확히 나누어떨어져야 함\n",
    "        # (예: d_model=512, num_heads=8 → head당 depth=64)\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        # 각 head에서 사용할 벡터의 차원\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # Q, K, V를 생성하기 위한 선형 변환 (각각 d_model → d_model)\n",
    "        # 학습 가능한 가중치 행렬을 통해 입력을 head 차원으로 투영\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 모든 head를 다시 결합한 후, 최종 출력 차원 복원용 선형 변환\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        입력 x를 num_heads 개로 분리하는 함수\n",
    "        ---------------------------------------------------\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        반환: (batch_size, num_heads, seq_len, depth)\n",
    "        ---------------------------------------------------\n",
    "        - d_model을 num_heads로 나누어 각 head가 처리할 부분 벡터로 분할\n",
    "        - 이후 permute를 통해 head 차원을 앞으로 이동\n",
    "        \"\"\"\n",
    "        # (batch_size, seq_len, d_model) → (batch_size, seq_len, num_heads, depth)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) 형태로 차원 재배치\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention의 순전파(forward) 과정\n",
    "        ---------------------------------------------------\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (optional) Attention mask\n",
    "        ---------------------------------------------------\n",
    "        출력: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # 1) 입력 벡터에 각각 Linear layer 적용 → Q, K, V 생성\n",
    "        #    shape: (batch_size, seq_len, d_model)\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2) Head별로 분리 (num_heads, depth 구조로 변환)\n",
    "        #    shape: (batch_size, num_heads, seq_len, depth)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3) 각 head별로 Scaled Dot-Product Attention 수행\n",
    "        #    반환값: (batch_size, num_heads, seq_len, depth)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # 4) 모든 head의 결과를 다시 결합하기 위해 차원 순서 재정렬\n",
    "        #    (batch_size, num_heads, seq_len, depth)\n",
    "        #      → (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 5) num_heads와 depth를 결합해 원래 d_model 차원으로 복원\n",
    "        #    shape: (batch_size, seq_len, d_model)\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 6) 최종 선형 변환을 통해 head 통합 결과를 출력 차원으로 투영\n",
    "        #    (batch_size, seq_len, d_model)\n",
    "        output = self.out_dense(concat_attention)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff8e6a-c663-4318-9de0-a4bfa9f2beca",
   "metadata": {},
   "source": [
    "# 8. Masking - Padding Masking, Look ahead Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e310f7d-2cd5-4e8d-b013-5bb1c0702fb3",
   "metadata": {},
   "source": [
    "## 8-1. Padding Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0256c8f-9837-4bcf-b5b8-2070549153fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기 : torch.Size([2, 5])\n",
      "생성된 마스크 크기 : torch.Size([2, 1, 1, 5])\n",
      "tensor([[[[0., 0., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask\n",
    "\n",
    "x = torch.tensor([[1, 2, 0, 3, 0],\n",
    "                  [0, 0, 0, 4, 5]])\n",
    "mask = create_padding_mask(x)\n",
    "print(\"입력 텐서 크기 :\", x.shape)    # (2, 5)\n",
    "print(\"생성된 마스크 크기 :\", mask.shape)  # (2, 1, 1, 5)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78773db4-796b-4dcd-9d42-338da5dadf89",
   "metadata": {},
   "source": [
    "## 8-2. Look ahead Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f066ae6c-c166-4414-a876-84fe3c7bd97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # 1) Look-ahead 마스크 생성\n",
    "    # torch.ones((seq_len, seq_len)) → 1로 채워진 정방행렬 생성\n",
    "    # torch.tril() → 하삼각(자기 자신 포함) 부분만 남기고 나머지를 0으로 만듦\n",
    "    # 1 - tril(...) → 상삼각(즉, 미래 토큰 위치)이 1, 나머지는 0\n",
    "    # => Decoder가 아직 보지 않은 미래 단어를 참고하지 않도록 차단\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 2) 입력 x에서 패딩 위치(0인 부분)를 찾아 패딩 마스크 생성\n",
    "    # shape: (batch_size, 1, 1, seq_len)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # 3) Look-ahead 마스크 차원 확장\n",
    "    # (seq_len, seq_len) → (1, seq_len, seq_len) → (1, 1, seq_len, seq_len)\n",
    "    # => Attention 연산 시 브로드캐스팅이 가능하도록 형태 맞춤\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0).unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # 4) Look-ahead 마스크와 패딩 마스크를 결합\n",
    "    # torch.max()를 사용하여 둘 중 하나라도 1인 위치는 모두 마스킹 처리\n",
    "    # 최종 shape: (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    \n",
    "    return combined_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddc5788b-0a77-4081-804a-ecd732c8e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 시퀀스:\n",
      " tensor([[[[0., 1., 1., 1., 1.],\n",
      "          [0., 0., 1., 1., 1.],\n",
      "          [0., 0., 0., 1., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 0.]]]]) torch.Size([1, 1, 5, 5]) \n",
      "\n",
      "두 번째 시퀀스:\n",
      " tensor([[[[1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 0., 0., 1., 1.],\n",
      "          [1., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0.]]]]) torch.Size([1, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "mask_1 = create_look_ahead_mask(x)\n",
    "print(\"첫 번째 시퀀스:\\n\", mask_1, mask_1.shape, '\\n')\n",
    "\n",
    "x2 = torch.tensor([[0, 5, 1, 5, 5]])\n",
    "mask_2 = create_look_ahead_mask(x2)\n",
    "print(\"두 번째 시퀀스:\\n\", mask_2, mask_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc933c2-31ac-440f-99df-e0290caa2f2b",
   "metadata": {},
   "source": [
    "# 9. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3824519a-037a-40f5-8481-7a82ec2df2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        # (1) 멀티-헤드 어텐션 (Self-Attention)\n",
    "        # 입력 문장 내 단어들이 서로 어떤 관계를 맺고 있는지 학습\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)  # 잔차 연결 후 정규화\n",
    "\n",
    "        # (2) 포지션별 피드포워드 네트워크 (Feed Forward Network)\n",
    "        # 각 위치의 특징을 비선형 변환을 통해 확장\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # 차원 확장\n",
    "            nn.ReLU(),                   # 비선형 활성화\n",
    "            nn.Linear(ff_dim, d_model)   # 원래 차원으로 복귀\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)  # 두 번째 정규화\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 입력 텐서 (batch_size, seq_len, d_model)\n",
    "            mask: 패딩 마스크 (선택적)\n",
    "\n",
    "        Returns:\n",
    "            out2: 인코더 레이어의 출력 (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # (1) 멀티-헤드 셀프 어텐션\n",
    "        # Query, Key, Value 모두 같은 입력 x를 사용\n",
    "        attn_output = self.mha(x, x, x, mask)         # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)      # 드롭아웃으로 과적합 방지\n",
    "        out1 = self.norm1(x + attn_output)            # 잔차 연결(residual) + LayerNorm\n",
    "\n",
    "        # (2) 포지션별 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)                   # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)        # 드롭아웃 적용\n",
    "        out2 = self.norm2(out1 + ffn_output)          # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42e9f3af-6227-4fd8-ab0e-ad216a678500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 단어 임베딩 (Word Embedding)\n",
    "        # 입력 토큰 ID를 고정 크기 벡터(d_model 차원)로 변환\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 위치 임베딩 (Positional Encoding)\n",
    "        # 문장 내 단어 순서(위치) 정보를 추가해 순서 의존성 학습 가능하게 함\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        # 드롭아웃: 학습 시 일부 뉴런 비활성화로 과적합 방지\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) 인코더 블록(EncoderLayer)들을 num_layers 개만큼 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 입력 토큰 시퀀스 (batch_size, seq_len)\n",
    "            mask: 패딩 마스크 (선택적)\n",
    "\n",
    "        Returns:\n",
    "            x: 인코더의 출력 벡터 (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # (1) 단어 임베딩 + 스케일링\n",
    "        # sqrt(d_model)로 스케일링해 학습 안정화 (Attention 계산 시 값이 너무 작아지는 것 방지)\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 추가 + 드롭아웃\n",
    "        # 위치 정보가 추가된 임베딩이 self-attention으로 입력됨\n",
    "        x = self.pos_encoding(x)                     # (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) N개의 EncoderLayer를 순차적으로 통과\n",
    "        # 각 레이어에서 self-attention → feed-forward → 정규화 과정을 거침\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        # (4) 최종 인코더 출력\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70034dd-4d35-4d35-96d0-6ad0cd6d1196",
   "metadata": {},
   "source": [
    "# 10. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "139cf585-3a74-468b-b430-3bd7d047b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # (1) 디코더 내부의 셀프 어텐션 (Masked Multi-Head Attention)\n",
    "        # => 이전 시점까지만 참조하도록 Look-ahead Mask 사용\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # (2) 인코더-디코더 어텐션\n",
    "        # => 디코더가 인코더의 출력(컨텍스트)을 참고하도록 하는 Cross-Attention\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # (3) 포지션별 피드포워드 네트워크 (Position-wise Feed Forward Network)\n",
    "        # => 각 위치의 피처를 독립적으로 비선형 변환\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # 확장\n",
    "            nn.ReLU(),                   # 비선형 활성화\n",
    "            nn.Linear(ff_dim, d_model)   # 축소 (원래 차원 복원)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃: 각 서브 레이어의 출력에 적용\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 디코더 입력 (batch_size, target_seq_len, d_model)\n",
    "            enc_outputs: 인코더 출력 (batch_size, input_seq_len, d_model)\n",
    "            look_ahead_mask: 미래 단어를 가리는 마스크\n",
    "            padding_mask: 인코더 출력에서 패딩 위치를 가리는 마스크\n",
    "\n",
    "        Returns:\n",
    "            out3: 디코더 레이어의 출력 (batch_size, target_seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # (1) Masked Self-Attention\n",
    "        # => 디코더가 다음 단어를 미리 보지 않도록 Look-ahead Mask 사용\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) Encoder-Decoder Attention (Cross-Attention)\n",
    "        # => 인코더 출력(enc_outputs)을 Key, Value로 사용해 입력 문맥 정보 활용\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (3) Position-wise Feed Forward Network\n",
    "        # => 각 시점별로 독립적인 비선형 변환 수행\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d436c40-c882-477b-bd92-33a2aa9c2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 토큰 임베딩 레이어\n",
    "        # 입력된 토큰 인덱스(정수 시퀀스)를 d_model 차원의 임베딩 벡터로 변환\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 (Positional Encoding)\n",
    "        # 디코더 입력 시퀀스의 위치 정보를 벡터에 더해줌\n",
    "        # ※ 실제 구현에서는 vocab_size 대신 max_seq_len을 사용하는 경우가 많음\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        # (3) 드롭아웃\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (4) DecoderLayer를 num_layers만큼 스택\n",
    "        # 각 레이어는 (Self-Attention → Encoder-Decoder Attention → FFN) 순서로 구성\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 디코더 입력 (batch_size, target_seq_len)\n",
    "            enc_outputs: 인코더 출력 (batch_size, input_seq_len, d_model)\n",
    "            look_ahead_mask: 미래 단어 마스크 (디코더 셀프 어텐션용)\n",
    "            padding_mask: 인코더 출력의 패딩 위치 마스크 (Cross-Attention용)\n",
    "        Returns:\n",
    "            x: 디코더 출력 (batch_size, target_seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # (1) 임베딩 + 스케일링\n",
    "        # 임베딩 결과를 √d_model로 스케일링해 학습 안정화\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 추가 + 드롭아웃\n",
    "        # 위치 정보(positional encoding)를 더해 순서 정보 보존\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) 여러 개의 DecoderLayer를 순차적으로 통과\n",
    "        # 각 layer는 Masked Self-Attention → Cross-Attention → FFN 구조\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        # (4) 디코더의 최종 출력 반환\n",
    "        # 각 타임스텝별로 문맥이 반영된 벡터 (d_model 차원)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93901852-1da8-4d6c-863b-16c1ec8cec4e",
   "metadata": {},
   "source": [
    "# 11. 챗봇의 병렬 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6acadf2-c561-42eb-a722-07e8fffe4e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data/Node4/cornell_movie_dialogs.zip ...\n",
      "Download complete.\n",
      "path_to_dataset: data/Node4/cornell movie-dialogs corpus\n",
      "path_to_movie_lines: data/Node4/cornell movie-dialogs corpus/movie_lines.txt\n",
      "path_to_movie_conversations: data/Node4/cornell movie-dialogs corpus/movie_conversations.txt\n"
     ]
    }
   ],
   "source": [
    "# 코넬 대사 데이터셋 다운로드 URL\n",
    "url = 'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip'\n",
    "zip_filename = 'data/Node4/cornell_movie_dialogs.zip'\n",
    "\n",
    "# 이미 파일이 없는 경우에만 다운로드\n",
    "if not os.path.exists(zip_filename):\n",
    "    print(f\"Downloading {zip_filename} ...\")\n",
    "    urllib.request.urlretrieve(url, zip_filename)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "extract_dir = os.path.join(\"data/Node4\")\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# ZIP 파일 압축 해제\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)  # 압축을 data/Node4/ 안에 풀기\n",
    "\n",
    "# ZIP 파일 삭제\n",
    "!rm -rf data/Node4/cornell_movie_dialogs.zip\n",
    "\n",
    "# 코넬 대사 데이터 폴더 경로\n",
    "path_to_dataset = os.path.join(extract_dir, \"cornell movie-dialogs corpus\")\n",
    "\n",
    "# 개별 파일 경로 설정\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset, 'movie_conversations.txt')\n",
    "\n",
    "print(\"path_to_dataset:\", path_to_dataset)\n",
    "print(\"path_to_movie_lines:\", path_to_movie_lines)\n",
    "print(\"path_to_movie_conversations:\", path_to_movie_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74580858-de53-4edd-9b43-6fb623a2fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    문장 전처리 함수\n",
    "    - 입력 문장을 소문자로 변환하고, 불필요한 공백 및 특수문자를 정리합니다.\n",
    "    - 구두점(punctuation) 앞뒤에 공백을 추가하여 토큰화를 용이하게 합니다.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): 원본 문장\n",
    "\n",
    "    Returns:\n",
    "        str: 전처리된 문장\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = sentence.lower().strip() # 1. 소문자로 변환 및 양쪽 공백 제거\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # 2. 구두점 앞뒤에 공백 추가 (예: \"student.\" → \"student .\")\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3. 다중 공백을 단일 공백으로 축소\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence) # 4. 알파벳(a-z, A-Z) 및 구두점(?.!,)을 제외한 모든 문자 제거\n",
    "    sentence = sentence.strip() # 5. 앞뒤 공백 제거 후 반환\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cce4d6ea-36fd-4f02-82ed-a8afe6b1d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cornell_data(path_to_movie_lines, path_to_movie_conversations, max_samples=50000):\n",
    "    \"\"\"\n",
    "    코넬 영화 대사 데이터셋을 읽어 (질문, 답변) 쌍으로 구성하는 함수.\n",
    "\n",
    "    Args:\n",
    "        path_to_movie_lines (str): movie_lines.txt 파일 경로\n",
    "        path_to_movie_conversations (str): movie_conversations.txt 파일 경로\n",
    "        max_samples (int, optional): 최대 추출할 (질문, 답변) 쌍 수. 기본값은 50,000\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: (질문, 답변) 쌍의 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # (1) 각 대사(line_id → 대사 내용) 매핑 딕셔너리 생성\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, 'r', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) >= 5:\n",
    "            line_id = parts[0]      # 예: \"L194\"\n",
    "            text = parts[4]         # 실제 대사 내용\n",
    "            id2line[line_id] = text\n",
    "\n",
    "    # (2) 대화(conversation) 파일을 읽어 (질문, 답변) 쌍 생성\n",
    "    pairs = []\n",
    "    with open(path_to_movie_conversations, 'r', errors='ignore') as f:\n",
    "        conv_lines = f.readlines()\n",
    "\n",
    "    for line in conv_lines:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "\n",
    "        # (3) 대화 ID 리스트 추출 → [\"L1045\", \"L1044\", \"L1043\", ...]\n",
    "        conv_str = parts[3]\n",
    "        conv_list = conv_str[1:-1].split(\", \")\n",
    "        conv_list = [c.strip(\"'\") for c in conv_list]  # \"'L1045'\" → \"L1045\"\n",
    "\n",
    "        # (4) 연속된 두 문장을 (질문, 답변) 쌍으로 구성\n",
    "        for i in range(len(conv_list) - 1):\n",
    "            q_id = conv_list[i]\n",
    "            a_id = conv_list[i + 1]\n",
    "            q_text = id2line.get(q_id, \"\")\n",
    "            a_text = id2line.get(a_id, \"\")\n",
    "\n",
    "            # (5) 문장 전처리 (소문자 변환, 특수문자 정리 등)\n",
    "            q_text = preprocess_sentence(q_text)\n",
    "            a_text = preprocess_sentence(a_text)\n",
    "\n",
    "            pairs.append((q_text, a_text))\n",
    "\n",
    "            # (6) 최대 샘플 개수 도달 시 종료\n",
    "            if len(pairs) >= max_samples:\n",
    "                return pairs\n",
    "\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31947059-f57c-4302-8850-8fbc3d5b3974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "\n",
    "pairs = read_cornell_data(path_to_movie_lines, path_to_movie_conversations, max_samples=MAX_SAMPLES)\n",
    "\n",
    "print('전체 샘플 수 :', len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af06f75-78c2-4994-89b9-87c97e40c46d",
   "metadata": {},
   "source": [
    "# 12. 병렬 데이터 전처리하기 - 전처리과정을 수행 및 교사 강요에 대해서 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abeb74b-5e23-4002-98bc-1a8a4c567952",
   "metadata": {},
   "source": [
    "## 12-1 Tokenizer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf57f24-d49e-4399-8922-2b3c17e508fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = extract_dir+\"clean_corpus.txt\"\n",
    "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "    for q, a in pairs:\n",
    "        f.write(q + \"\\n\")\n",
    "        f.write(a + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6947e3c-60c3-4fd4-8940-e74469c5e196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/Node4clean_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: data/Node4spm_cornell\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: data/Node4clean_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 99993 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=5711705\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=31\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 99993 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 99993\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 23064\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=154642 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37582 size=20 all=1108 active=1077 piece=▁?\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21179 size=40 all=1739 active=1708 piece=en\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13709 size=60 all=2683 active=2652 piece=at\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10325 size=80 all=3454 active=3423 piece=ut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7314 size=100 all=3987 active=3956 piece=ad\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7271 min_freq=302\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5767 size=120 all=4808 active=1723 piece=▁ne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4834 size=140 all=5381 active=2296 piece=ink\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4044 size=160 all=5955 active=2870 piece=▁him\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3380 size=180 all=6542 active=3457 piece=▁now\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3022 size=200 all=7302 active=4217 piece=us\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2969 min_freq=299\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2583 size=220 all=7847 active=1437 piece=▁or\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2306 size=240 all=8187 active=1777 piece=rou\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2087 size=260 all=8853 active=2443 piece=way\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1903 size=280 all=9566 active=3156 piece=ation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1731 size=300 all=9942 active=3532 piece=▁int\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1719 min_freq=266\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1508 size=320 all=10301 active=1347 piece=▁ok\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1419 size=340 all=10676 active=1722 piece=▁bet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1340 size=360 all=11007 active=2053 piece=▁mr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1241 size=380 all=11366 active=2412 piece=▁hu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1151 size=400 all=11772 active=2818 piece=▁because\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1145 min_freq=235\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1055 size=420 all=12223 active=1452 piece=riend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=996 size=440 all=12458 active=1687 piece=ire\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=945 size=460 all=12772 active=2001 piece=▁again\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=905 size=480 all=13115 active=2344 piece=ep\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=851 size=500 all=13444 active=2673 piece=ways\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=846 min_freq=205\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=787 size=520 all=13662 active=1211 piece=▁pr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=746 size=540 all=13978 active=1527 piece=▁father\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=703 size=560 all=14348 active=1897 piece=▁ra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=667 size=580 all=14586 active=2135 piece=▁mind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=635 size=600 all=14810 active=2359 piece=▁dad\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=633 min_freq=181\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=604 size=620 all=15145 active=1334 piece=▁fucking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=573 size=640 all=15299 active=1488 piece=▁tom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=543 size=660 all=15582 active=1771 piece=dy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=514 size=680 all=16067 active=2256 piece=▁mor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=492 size=700 all=16273 active=2462 piece=▁went\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=490 min_freq=162\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=475 size=720 all=16473 active=1201 piece=▁most\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=457 size=740 all=16618 active=1346 piece=▁pol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=444 size=760 all=16838 active=1566 piece=▁many\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=430 size=780 all=17019 active=1747 piece=▁thi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=416 size=800 all=17188 active=1916 piece=ny\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=415 min_freq=147\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=403 size=820 all=17392 active=1187 piece=ready\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=386 size=840 all=17511 active=1306 piece=▁exc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=377 size=860 all=17698 active=1493 piece=▁wife\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=365 size=880 all=17905 active=1700 piece=▁took\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=900 all=18056 active=1851 piece=▁probably\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=349 min_freq=132\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=338 size=920 all=18242 active=1187 piece=ost\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=330 size=940 all=18433 active=1378 piece=ans\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=320 size=960 all=18647 active=1592 piece=vil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=313 size=980 all=18812 active=1757 piece=ract\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=1000 all=19067 active=2012 piece=llow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=307 min_freq=120\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=297 size=1020 all=19232 active=1154 piece=▁fight\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=288 size=1040 all=19393 active=1315 piece=▁least\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=279 size=1060 all=19487 active=1409 piece=▁quite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=1080 all=19718 active=1640 piece=▁ready\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=1100 all=19996 active=1918 piece=▁country\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=267 min_freq=109\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=258 size=1120 all=20206 active=1208 piece=▁town\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=251 size=1140 all=20409 active=1411 piece=▁hun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=244 size=1160 all=20695 active=1697 piece=▁stupid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=239 size=1180 all=20868 active=1870 piece=side\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=233 size=1200 all=20983 active=1985 piece=▁chance\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=232 min_freq=97\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=226 size=1220 all=21261 active=1328 piece=▁sweet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=221 size=1240 all=21401 active=1468 piece=ention\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=215 size=1260 all=21594 active=1661 piece=▁vi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=1280 all=21785 active=1852 piece=ames\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=1300 all=21973 active=2040 piece=▁din\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=205 min_freq=87\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=203 size=1320 all=22125 active=1244 piece=▁terri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=198 size=1340 all=22240 active=1359 piece=▁ind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=193 size=1360 all=22400 active=1519 piece=▁wall\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=189 size=1380 all=22528 active=1647 piece=io\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=186 size=1400 all=22777 active=1896 piece=▁wind\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=186 min_freq=79\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=181 size=1420 all=22895 active=1252 piece=▁party\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=177 size=1440 all=23141 active=1498 piece=▁ref\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=173 size=1460 all=23245 active=1602 piece=▁complete\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=169 size=1480 all=23387 active=1744 piece=▁mary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=166 size=1500 all=23510 active=1867 piece=▁rather\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=165 min_freq=72\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=162 size=1520 all=23665 active=1331 piece=▁begin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=159 size=1540 all=23809 active=1475 piece=▁disapp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=1560 all=23929 active=1595 piece=▁jim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=152 size=1580 all=24029 active=1695 piece=▁med\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=147 size=1600 all=24199 active=1865 piece=ike\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=147 min_freq=67\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=145 size=1620 all=24314 active=1318 piece=osp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=143 size=1640 all=24409 active=1413 piece=▁clothes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=141 size=1660 all=24565 active=1569 piece=▁quit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=137 size=1680 all=24682 active=1686 piece=chi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=135 size=1700 all=24836 active=1840 piece=▁ought\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=135 min_freq=62\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=1720 all=24971 active=1374 piece=ublic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=1740 all=25128 active=1531 piece=▁learn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=127 size=1760 all=25271 active=1674 piece=ash\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=1780 all=25384 active=1787 piece=uation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=1800 all=25497 active=1900 piece=▁wal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=122 min_freq=58\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=1820 all=25635 active=1408 piece=▁paper\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=1840 all=25770 active=1543 piece=aster\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117 size=1860 all=25817 active=1590 piece=▁killing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114 size=1880 all=25896 active=1669 piece=ume\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=1900 all=25986 active=1759 piece=▁ger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=112 min_freq=55\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=1920 all=26101 active=1407 piece=▁pur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=1940 all=26178 active=1484 piece=▁girlf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=1960 all=26242 active=1548 piece=▁hist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=1980 all=26339 active=1645 piece=▁cir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=2000 all=26467 active=1773 piece=▁occ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=102 min_freq=52\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=2020 all=26609 active=1462 piece=▁base\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=2040 all=26682 active=1535 piece=▁given\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=2060 all=26774 active=1627 piece=▁bott\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=2080 all=26826 active=1679 piece=▁pleasure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95 size=2100 all=26896 active=1749 piece=▁ted\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=95 min_freq=49\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=2120 all=26988 active=1436 piece=▁bought\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=2140 all=27033 active=1481 piece=▁dunno\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=2160 all=27132 active=1580 piece=▁sar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=2180 all=27224 active=1672 piece=▁acting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=2200 all=27333 active=1781 piece=▁picked\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=89 min_freq=46\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=2220 all=27385 active=1419 piece=ney\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=2240 all=27470 active=1504 piece=vies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=2260 all=27556 active=1590 piece=▁agree\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=2280 all=27603 active=1637 piece=▁worried\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=2300 all=27691 active=1725 piece=▁goodbye\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=82 min_freq=44\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=2320 all=27761 active=1455 piece=tin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=2340 all=27898 active=1592 piece=▁fro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=2360 all=27963 active=1657 piece=▁bre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=2380 all=28028 active=1722 piece=▁lang\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=2400 all=28107 active=1801 piece=▁dir\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=2420 all=28162 active=1459 piece=▁pardon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=2440 all=28234 active=1531 piece=▁cla\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=2460 all=28291 active=1588 piece=lex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=2480 all=28341 active=1638 piece=icide\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=2500 all=28394 active=1691 piece=▁mac\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=72 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=2520 all=28422 active=1440 piece=▁witness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=2540 all=28469 active=1487 piece=▁fur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=2560 all=28504 active=1522 piece=▁ordell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=2580 all=28650 active=1668 piece=▁beer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2600 all=28675 active=1693 piece=aret\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=68 min_freq=38\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2620 all=28774 active=1528 piece=▁decis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=2640 all=28834 active=1588 piece=▁hal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=2660 all=28861 active=1615 piece=▁lee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=2680 all=28883 active=1637 piece=▁profession\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=2700 all=28912 active=1666 piece=▁russian\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=65 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=2720 all=28995 active=1529 piece=▁evan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=2740 all=29022 active=1556 piece=▁fle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=2760 all=29076 active=1610 piece=▁princ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2780 all=29107 active=1641 piece=sey\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2800 all=29167 active=1701 piece=▁negro\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=62 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=2820 all=29230 active=1520 piece=▁vol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=2840 all=29251 active=1541 piece=▁survive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=2860 all=29353 active=1643 piece=▁ital\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=2880 all=29369 active=1659 piece=▁believed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=2900 all=29476 active=1766 piece=▁mount\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=59 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=2920 all=29549 active=1544 piece=rison\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=2940 all=29581 active=1576 piece=▁closed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=2960 all=29706 active=1701 piece=▁cru\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=2980 all=29750 active=1745 piece=▁surely\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=3000 all=29802 active=1797 piece=iliar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=56 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=3020 all=29826 active=1511 piece=▁losing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=3040 all=29877 active=1562 piece=▁prin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3060 all=29901 active=1586 piece=ari\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3080 all=30000 active=1685 piece=▁rail\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3100 all=30000 active=1685 piece=▁evidence\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=54 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3120 all=30070 active=1570 piece=▁thom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3140 all=30082 active=1582 piece=▁justice\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3160 all=30153 active=1653 piece=▁anth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3180 all=30188 active=1688 piece=▁success\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3200 all=30285 active=1785 piece=▁host\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3220 all=30284 active=1506 piece=▁complain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3240 all=30350 active=1572 piece=▁thr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3260 all=30387 active=1609 piece=▁trade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3280 all=30392 active=1614 piece=omm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3300 all=30474 active=1696 piece=▁vien\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=49 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3320 all=30479 active=1527 piece=▁picking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3340 all=30533 active=1581 piece=▁ruiz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3360 all=30539 active=1587 piece=▁vacation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3380 all=30663 active=1711 piece=ondon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3400 all=30680 active=1728 piece=▁sport\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3420 all=30717 active=1569 piece=osop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3440 all=30772 active=1624 piece=▁heads\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3460 all=30768 active=1620 piece=▁weekend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3480 all=30869 active=1721 piece=igger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3500 all=30892 active=1744 piece=▁sheriff\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3520 all=30976 active=1628 piece=▁exam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3540 all=30983 active=1635 piece=▁porters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3560 all=31008 active=1660 piece=▁boo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3580 all=31055 active=1707 piece=▁berlin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3600 all=31050 active=1702 piece=bon\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3620 all=31128 active=1622 piece=▁chair\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3640 all=31132 active=1626 piece=▁knowledge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3660 all=31237 active=1731 piece=ograp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3680 all=31266 active=1760 piece=▁stone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3700 all=31281 active=1775 piece=▁disappeared\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3720 all=31365 active=1649 piece=▁junk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3740 all=31385 active=1669 piece=▁opera\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3760 all=31388 active=1672 piece=▁fourteen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3780 all=31461 active=1745 piece=▁jul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3800 all=31519 active=1803 piece=▁nerve\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=3820 all=31534 active=1591 piece=▁concern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3840 all=31594 active=1651 piece=ites\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3860 all=31670 active=1727 piece=▁bound\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=3880 all=31684 active=1741 piece=▁europe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3900 all=31675 active=1732 piece=ai\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3920 all=31800 active=1696 piece=▁dare\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3940 all=31812 active=1708 piece=▁assign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3960 all=31813 active=1709 piece=▁details\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=3980 all=31800 active=1696 piece=▁motherfucker\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4000 all=31870 active=1766 piece=▁chap\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4020 all=31903 active=1621 piece=▁storm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4040 all=31893 active=1611 piece=▁streets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4060 all=31943 active=1661 piece=▁typ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4080 all=31987 active=1705 piece=▁walls\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4100 all=31980 active=1698 piece=▁penelope\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4120 all=32062 active=1681 piece=itty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4140 all=32124 active=1743 piece=▁nest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4160 all=32142 active=1761 piece=▁holly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4180 all=32143 active=1762 piece=▁toward\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4200 all=32130 active=1749 piece=▁mentioned\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4220 all=32190 active=1667 piece=arant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4240 all=32207 active=1684 piece=▁descri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4260 all=32213 active=1690 piece=▁official\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4280 all=32269 active=1746 piece=ummy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4300 all=32318 active=1795 piece=▁unha\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4320 all=32315 active=1611 piece=▁marvel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4340 all=32314 active=1610 piece=▁soldiers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4360 all=32386 active=1682 piece=▁jac\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4380 all=32437 active=1733 piece=▁sway\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4400 all=32449 active=1745 piece=▁usual\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=31 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4420 all=32452 active=1626 piece=▁holiday\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4440 all=32462 active=1636 piece=dom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4460 all=32561 active=1735 piece=▁tob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4480 all=32607 active=1781 piece=▁teen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4500 all=32643 active=1817 piece=▁sharp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4520 all=32641 active=1628 piece=▁fingers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4540 all=32628 active=1615 piece=iar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4560 all=32705 active=1692 piece=▁gree\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4580 all=32732 active=1719 piece=▁lyssa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4600 all=32733 active=1720 piece=▁strike\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=29 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4620 all=32723 active=1626 piece=▁operation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4640 all=32795 active=1698 piece=▁gig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4660 all=32842 active=1745 piece=▁grus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4680 all=32856 active=1759 piece=▁union\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4700 all=32850 active=1753 piece=▁pattern\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4720 all=32840 active=1632 piece=▁convention\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4740 all=32891 active=1683 piece=hest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4760 all=32937 active=1729 piece=▁deny\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4780 all=32944 active=1736 piece=▁angel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4800 all=32948 active=1740 piece=▁widow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4820 all=32956 active=1654 piece=▁senate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=4840 all=32949 active=1647 piece=▁instruct\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4860 all=32985 active=1683 piece=gger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4880 all=33063 active=1761 piece=▁gump\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4900 all=33087 active=1785 piece=▁final\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4920 all=33089 active=1655 piece=▁grandp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4940 all=33090 active=1656 piece=▁precise\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=4960 all=33078 active=1644 piece=▁satisfied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=4980 all=33139 active=1705 piece=cred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5000 all=33203 active=1769 piece=ilton\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=25 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5020 all=33226 active=1683 piece=▁adult\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5040 all=33231 active=1688 piece=▁werew\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5060 all=33230 active=1687 piece=▁strict\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5080 all=33234 active=1691 piece=▁thursday\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5100 all=33296 active=1753 piece=wer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5120 all=33360 active=1725 piece=▁oui\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5140 all=33381 active=1746 piece=▁adele\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5160 all=33383 active=1748 piece=▁spear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5180 all=33395 active=1760 piece=▁robber\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5200 all=33390 active=1755 piece=▁scratch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5220 all=33371 active=1650 piece=▁equipment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5240 all=33420 active=1699 piece=fied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5260 all=33471 active=1750 piece=iving\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5280 all=33501 active=1780 piece=▁givin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5300 all=33503 active=1782 piece=▁august\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5320 all=33506 active=1678 piece=▁counter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5340 all=33495 active=1667 piece=▁insulted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5360 all=33483 active=1655 piece=▁philosophy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5380 all=33559 active=1731 piece=away\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5400 all=33608 active=1780 piece=▁una\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5420 all=33639 active=1704 piece=▁neat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5440 all=33650 active=1715 piece=▁lamar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5460 all=33647 active=1712 piece=▁button\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5480 all=33639 active=1704 piece=▁anxious\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5500 all=33634 active=1699 piece=▁shoulda\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5520 all=33618 active=1666 piece=▁concentrate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5540 all=33686 active=1734 piece=gain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5560 all=33739 active=1787 piece=▁acce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5580 all=33747 active=1795 piece=▁tips\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5600 all=33757 active=1805 piece=▁moral\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5620 all=33761 active=1691 piece=▁hambur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5640 all=33751 active=1681 piece=▁musical\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5660 all=33745 active=1675 piece=▁wondered\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5680 all=33786 active=1716 piece=rop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5700 all=33844 active=1774 piece=yers\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5720 all=33897 active=1743 piece=▁beam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5740 all=33931 active=1777 piece=▁puts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5760 all=33941 active=1787 piece=▁ellie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5780 all=33941 active=1787 piece=▁scram\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5800 all=33948 active=1794 piece=▁issues\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5820 all=33947 active=1697 piece=▁charged\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5840 all=33932 active=1682 piece=▁basement\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5860 all=33917 active=1667 piece=▁touching\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=5880 all=33903 active=1653 piece=▁shuffleboard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=5900 all=33956 active=1706 piece=itel\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=5920 all=34015 active=1756 piece=▁tag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=5940 all=34035 active=1776 piece=▁newt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=5960 all=34047 active=1788 piece=▁grain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=5980 all=34041 active=1782 piece=assador\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6000 all=34043 active=1784 piece=▁salary\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6020 all=34026 active=1686 piece=▁eternal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6040 all=34012 active=1672 piece=▁material\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6060 all=33997 active=1657 piece=▁activities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6080 all=34048 active=1708 piece=daya\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6100 all=34100 active=1760 piece=eeney\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6120 all=34126 active=1730 piece=▁dict\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6140 all=34151 active=1755 piece=▁sack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6160 all=34182 active=1786 piece=▁blond\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6180 all=34180 active=1784 piece=▁trail\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6200 all=34182 active=1786 piece=▁length\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6220 all=34178 active=1704 piece=▁busting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6240 all=34167 active=1693 piece=▁settled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6260 all=34152 active=1678 piece=▁suitcase\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6280 all=34136 active=1662 piece=▁proposition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6300 all=34188 active=1714 piece=efur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6320 all=34234 active=1755 piece=▁rag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6340 all=34262 active=1783 piece=▁enjo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6360 all=34282 active=1803 piece=▁unex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6380 all=34289 active=1810 piece=▁latin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6400 all=34286 active=1807 piece=▁elijah\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6420 all=34278 active=1707 piece=▁article\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6440 all=34276 active=1705 piece=▁pushing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6460 all=34258 active=1687 piece=▁gambling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6480 all=34246 active=1675 piece=▁inspector\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6500 all=34228 active=1657 piece=eu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6520 all=34316 active=1792 piece=nard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6540 all=34352 active=1828 piece=llian\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6560 all=34377 active=1853 piece=▁grat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6580 all=34382 active=1858 piece=▁tack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6600 all=34396 active=1872 piece=▁havin\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6620 all=34399 active=1723 piece=▁steak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6640 all=34397 active=1721 piece=▁higher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6660 all=34391 active=1715 piece=▁sealed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6680 all=34382 active=1706 piece=▁figures\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6700 all=34366 active=1690 piece=▁salvage\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6720 all=34357 active=1710 piece=▁independ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=6740 all=34344 active=1697 piece=▁sentiment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6760 all=34366 active=1719 piece=lve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6780 all=34400 active=1753 piece=▁amy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6800 all=34426 active=1779 piece=▁rod\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6820 all=34452 active=1745 piece=▁crit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6840 all=34458 active=1751 piece=▁plug\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6860 all=34462 active=1755 piece=▁bizar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6880 all=34463 active=1756 piece=▁niner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6900 all=34469 active=1762 piece=▁whack\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6920 all=34455 active=1709 piece=▁larger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6940 all=34450 active=1704 piece=▁worlds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6960 all=34445 active=1699 piece=▁madness\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=6980 all=34434 active=1688 piece=▁activity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7000 all=34419 active=1673 piece=▁swinging\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7020 all=34401 active=1703 piece=▁passenger\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=7040 all=34382 active=1684 piece=▁destruction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7060 all=34413 active=1715 piece=ids\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7080 all=34486 active=1788 piece=osis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7100 all=34538 active=1840 piece=andal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7120 all=34571 active=1756 piece=▁cosm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7140 all=34579 active=1764 piece=▁walt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7160 all=34590 active=1775 piece=▁chaos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7180 all=34585 active=1770 piece=▁plumb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7200 all=34588 active=1773 piece=▁breast\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7220 all=34580 active=1721 piece=▁halluc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7240 all=34579 active=1720 piece=▁sittin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7260 all=34566 active=1707 piece=▁dealers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7280 all=34549 active=1690 piece=▁network\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7300 all=34530 active=1671 piece=▁banister\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7320 all=34516 active=1713 piece=▁vanished\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=7340 all=34497 active=1694 piece=▁nightmares\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7360 all=34549 active=1746 piece=now\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7380 all=34598 active=1795 piece=semb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7400 all=34629 active=1826 piece=▁ped\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7420 all=34673 active=1770 piece=otted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7440 all=34702 active=1799 piece=▁lili\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7460 all=34703 active=1800 piece=▁zone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7480 all=34721 active=1818 piece=▁forms\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7500 all=34727 active=1824 piece=▁persp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7520 all=34727 active=1735 piece=▁twins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7540 all=34721 active=1729 piece=▁castro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7560 all=34708 active=1716 piece=▁losers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7580 all=34694 active=1702 piece=▁severe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7600 all=34676 active=1684 piece=▁cassius\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7620 all=34671 active=1729 piece=▁passage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7640 all=34655 active=1713 piece=▁campaign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7660 all=34640 active=1698 piece=▁peerless\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7680 all=34628 active=1686 piece=▁honorable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=7700 all=34611 active=1669 piece=▁retirement\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7720 all=34615 active=1735 piece=ems\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7740 all=34678 active=1798 piece=iman\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7760 all=34726 active=1846 piece=▁etc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7780 all=34752 active=1872 piece=iable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7800 all=34767 active=1887 piece=▁drew\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7820 all=34775 active=1747 piece=▁mush\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7840 all=34780 active=1752 piece=▁vern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7860 all=34788 active=1760 piece=▁bayon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7880 all=34790 active=1762 piece=▁fraud\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7900 all=34779 active=1751 piece=▁ridge\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7920 all=34770 active=1729 piece=▁wiped\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7940 all=34760 active=1719 piece=▁hatred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=7960 all=34756 active=1715 piece=▁starve\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: data/Node4spm_cornell.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: data/Node4spm_cornell.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input=corpus_file,                     # 학습할 말뭉치 파일 경로 (한 줄에 한 문장)\n",
    "    model_prefix=extract_dir+\"spm_cornell\",# 생성될 모델 파일 이름 접두사\n",
    "    vocab_size=8000,                       # 단어 집합 크기 (토큰 개수)\n",
    "    character_coverage=1.0,                # 말뭉치 내 모든 문자를 학습에 포함 (1.0 = 전체)\n",
    "    model_type=\"bpe\",                       # 모델 유형: 'bpe', 'unigram', 'char', 'word'\n",
    "    max_sentence_length=999999,            # 한 문장 최대 길이 제한 (길게 잡음)\n",
    "    bos_id=1,                              # 문장 시작 토큰 <s> ID\n",
    "    eos_id=2,                              # 문장 종료 토큰 </s> ID\n",
    "    pad_id=0,                              # 패딩 토큰 ID\n",
    "    unk_id=3                               # 알 수 없는 단어(UNK) 토큰 ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc26e224-1e96-4e60-8455-cf4db6a0dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(extract_dir+\"spm_cornell.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23f34c04-db79-48e2-a336-826975f9fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 문장: i m learning pytorch with sentencepiece !\n",
      "Tokenized: ['▁i', '▁m', '▁learning', '▁p', 'y', 't', 'or', 'ch', '▁with', '▁sent', 'ence', 'p', 'iece', '▁!']\n",
      "Encoded: [6, 13, 4954, 37, 7983, 7971, 36, 119, 113, 1412, 651, 7991, 4122, 69]\n",
      "Decoded: i m learning pytorch with sentencepiece !\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장\n",
    "sentence = \"I'm learning PyTorch with SentencePiece!\"\n",
    "\n",
    "sentence = preprocess_sentence(sentence)\n",
    "print(\"전처리 후의 문장:\", sentence)\n",
    "\n",
    "# 1. 토크나이징 (subword 단위로 분할)\n",
    "tokens = sp.encode(sentence, out_type=str)\n",
    "print(\"Tokenized:\", tokens)\n",
    "\n",
    "# 2. 인코딩 (서브워드를 정수 ID로 변환)\n",
    "encoded = sp.encode(sentence, out_type=int)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# 3. 디코딩 (정수 ID → 원본 문장 복원)\n",
    "decoded = sp.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0849391a-8460-4a8a-8c5b-c5edd5cad3f7",
   "metadata": {},
   "source": [
    "## 12-2 Dataset 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4032134e-a08f-45f8-8cef-11c2c4e71d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CornellDataset(Dataset):\n",
    "    def __init__(self, pairs, sp, max_length=40):\n",
    "        super().__init__()\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        for q_text, a_text in pairs:\n",
    "            # 1) 질문과 답변 문장을 SentencePiece로 토크나이즈 (ID 시퀀스로 변환)\n",
    "            # sp.EncodeAsIds() 사용: 문장을 토큰 ID 리스트로 변환\n",
    "            # 예: \"hello world\" -> [12, 345]\n",
    "            q_ids = sp.EncodeAsIds(q_text)\n",
    "            a_ids = sp.EncodeAsIds(a_text)\n",
    "\n",
    "            # 2) BOS(<s>)와 EOS(</s>) 토큰 추가\n",
    "            # sp.bos_id(), sp.eos_id()로 문장의 시작과 끝 표시\n",
    "            # 학습 시 모델이 문장 시작과 끝을 알 수 있도록 함\n",
    "            # 만약 BOS/EOS ID가 정의되지 않았으면 임의값 사용\n",
    "            bos_id = sp.bos_id() if sp.bos_id() >= 0 else 1\n",
    "            eos_id = sp.eos_id() if sp.eos_id() >= 0 else 2\n",
    "            q_tokens = [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            # 3) 최대 길이(max_length) 초과 시 제외\n",
    "            # 너무 긴 문장은 학습에서 제외\n",
    "            if len(q_tokens) > max_length or len(a_tokens) > max_length:\n",
    "                continue\n",
    "\n",
    "            # 4) 패딩: 최대 길이에 맞게 0(<pad>)으로 채움\n",
    "            # sp.piece_to_id('<pad>')를 이용하면 모델에서 정의된 pad ID를 활용 가능\n",
    "            q_tokens += [0] * (max_length - len(q_tokens))\n",
    "            a_tokens += [0] * (max_length - len(a_tokens))\n",
    "\n",
    "            # 5) 디코더 입력과 타겟 생성 (Teacher Forcing 적용)\n",
    "            # 디코더 입력(dec_input)은 [BOS, 토큰1, ...] (마지막 토큰 제외)\n",
    "            # 타겟(target)은 [토큰1, 토큰2, ..., EOS] (첫 번째 토큰 제외)\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            # 6) 데이터셋에 샘플 저장\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,  # Encoder 입력\n",
    "                \"dec_input\": dec_input,  # Decoder 입력 (Teacher Forcing)\n",
    "                \"target\": target         # Decoder 출력(타겟)\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        # 전체 샘플 수 반환\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx 번째 샘플 반환\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07c8f293-22fd-4cb7-9585-f907bf091633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CornellDataset(pairs, sp, max_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d23900ef-2dc1-437c-9e5b-d1e1ce1de0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서 크기 : torch.Size([40])\n",
      "tensor([   1,  115,   52,  321,   99, 1609,   23,  304, 7997, 7734,   62,   36,\n",
      "        7978,  271,   61,   61,  891, 6222,  121, 1060,   39, 3631, 7741, 1337,\n",
      "          15,  141,  280, 1882,  919,  161,   72,   19,  333,  103,    5,  463,\n",
      "           5,    2,    0,    0])\n",
      "can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .\n",
      "tensor([   1,  189,   17,    6,  450,   52,   20,  539,  113,  523,   21,  182,\n",
      "        5984,   17,  156,   57,   10,  358,  113,   14,    5,    2,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "well , i thought we d start with pronunciation , if that s okay with you .\n",
      "tensor([ 189,   17,    6,  450,   52,   20,  539,  113,  523,   21,  182, 5984,\n",
      "          17,  156,   57,   10,  358,  113,   14,    5,    2,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "well , i thought we d start with pronunciation , if that s okay with you .\n"
     ]
    }
   ],
   "source": [
    "for encoder_input, decoder_input, decoder_label  in dataset:\n",
    "    print(\"텐서 크기 :\",encoder_input.size())\n",
    "    print(encoder_input)\n",
    "    print(sp.decode(encoder_input.tolist()))\n",
    "    print(decoder_input)\n",
    "    print(sp.decode(decoder_input.tolist()))\n",
    "    print(decoder_label)\n",
    "    print(sp.decode(decoder_label.tolist()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b8ed1-0f67-4a8f-ad13-242f1feabdba",
   "metadata": {},
   "source": [
    "## 12-3 DataLoader 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54be83d8-1d3c-4013-af9f-469e5c6893ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501eb541-236d-4173-8d68-d33e946c91cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n",
      "torch.Size([32, 39])\n",
      "torch.Size([32, 39])\n"
     ]
    }
   ],
   "source": [
    "for encoder_input, decoder_input, decoder_label in dataloader:\n",
    "    print(encoder_input.size())\n",
    "    print(decoder_input.size())\n",
    "    print(decoder_label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab61cb-a23f-4a9f-93d1-7a5dbd1460b6",
   "metadata": {},
   "source": [
    "# 13. 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "becc41e1-9401-4552-8258-4c41171ca01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # Feed-Forward Network의 은닉 차원 (ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 1) 인코더 초기화\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 2) 디코더 초기화\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 3) 최종 출력층: d_model -> vocab_size\n",
    "        # 디코더 출력 벡터를 단어 확률로 변환\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        \"\"\"\n",
    "        inputs: 인코더 입력 (batch_size, src_seq_len)\n",
    "        dec_inputs: 디코더 입력 (batch_size, tgt_seq_len)\n",
    "        \"\"\"\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        # PAD 토큰 위치는 1, 실제 토큰은 0\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape: (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 Look-Ahead Mask + 패딩 마스크\n",
    "        # 디코더에서 미래 토큰을 보지 않도록 상삼각 마스크 적용\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape: (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 사용\n",
    "        # 인코더 입력의 PAD 토큰 위치를 마스크\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape: (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # 디코더 입력 (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# 인코더 출력 (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Linear 레이어: d_model -> vocab_size\n",
    "        # 각 위치마다 단어 확률(logits) 출력\n",
    "        logits = self.final_linear(dec_outputs)  # shape: (batch_size, tgt_seq_len, vocab_size)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4bede6d-28f1-4652-a464-fd0a96f64221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-1): 2 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-1): 2 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=256, out_features=8000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예시: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 2      # 인코더/디코더 층 수\n",
    "D_MODEL = 256       # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8       # 멀티헤드 어텐션 헤드 수\n",
    "UNITS = 512         # Feed-Forward Network 은닉 차원 (ff_dim)\n",
    "DROPOUT = 0.1       # 드롭아웃 비율\n",
    "VOCAB_SIZE = 8000   # 단어 집합 크기 (예시)\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bfe12b4-f263-4213-b194-37fa68939f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e21b7242-c3a0-43b3-8739-9a5056584697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    \"\"\"\n",
    "    Transformer 학습 시 사용되는 학습률 스케줄 함수(Step-wise learning rate scheduler) 생성.\n",
    "\n",
    "    d_model: 모델 내부 표현 차원 (embedding 차원)\n",
    "    warmup_steps: 학습률 warm-up 단계 수\n",
    "\n",
    "    반환값: 현재 step에 따른 학습률 비율 계산 함수\n",
    "    \"\"\"\n",
    "    d_model = float(d_model)\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        # step은 0부터 시작하므로 +1로 보정\n",
    "        step = step + 1\n",
    "\n",
    "        # 수식: d_model^-0.5 * min(step^-0.5, step * warmup_steps^-1.5)\n",
    "        # - 초기 단계(warmup)에서는 step * warmup_steps^-1.5가 작아 학습률 점점 증가\n",
    "        # - warmup 이후에는 step^-0.5가 작아져 학습률 점점 감소\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "\n",
    "    return lr_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "983f4773-295a-47f0-821c-d7b5810d7ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAAHUCAYAAACgQ2AkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlAJJREFUeJzs3XlcVOX+B/DPzDALwy47Cog7SrmgqaSilphWWmbS8qPFpbxWri1imWmLeTMjKzW7lnVvqfemZqUVlHuS5ZK7poniAiIgsjMzzPn9McyRcQZkkMMMzOf9es0L5pnnnOeZ75xovj7LkQmCIICIiIiIiIicgtzRHSAiIiIiIqJrmKQRERERERE5ESZpREREREREToRJGhERERERkRNhkkZEREREROREmKQRERERERE5ESZpREREREREToRJGhERERERkRNhkkZEREREROREmKQREVWRyWR1emzdutXRXbXwyy+/oGfPnvDw8IBMJsM333zj6C5JTiaT4dlnn3V0N+y2cuVKyGQynDlzxmFtmx9ubm4IDQ3FQw89hJMnT9b7vG+99ZYk15xer8fHH3+MXr16oUWLFtBqtYiMjMTIkSOxfv16u8515swZyGQyLFy4sMH7eb2b+Yy3bt3qlH9jiKjxuTm6A0REziI9Pd3i+euvv44tW7Zg8+bNFuWdO3duzG7VShAEjBkzBh06dMC3334LDw8PdOzY0dHdohrcfffdSE9PR2hoqMP68Nlnn6FTp04oLy/Hr7/+ijfffBNbtmzB8ePH4efnZ/f53nrrLYwePRr33Xdfg/YzKSkJ69atw9SpUzF37lyo1WqcPn0aP/74I3766Sfcf//9DdoeEZEzYZJGRFSlT58+Fs8DAwMhl8utyq9XWloKrVYrZddqdPHiReTn5+P+++/HHXfc0SDnLCsrg0ajgUwma5Dz1YderxdHe5yZvZ99YGAgAgMDJezRjcXExKBnz54AgIEDB6KyshJz5szBN998gyeffNKhfTPLyMjAmjVr8Oqrr2Lu3Lli+R133IEJEybAaDQ6sHdERNLjdEciIjsMHDgQMTEx2L59O+Li4qDVajF27FgAwJo1a5CQkIDQ0FC4u7sjOjoaM2fORElJicU5nnjiCXh6euLUqVMYPnw4PD09ER4ejhkzZqCiosKi7tKlS9G1a1d4enrCy8sLnTp1wqxZswAAr732Glq1agUAeOmllyCTydC6dWvx2J07d+KOO+6Al5cXtFot4uLisHHjRovzm6dmpaamYuzYsQgMDIRWq0VFRYX4XtPT0xEXFwd3d3e0bt0an332GQBg48aN6NGjB7RaLW655Rb8+OOPVvE6efIkHnnkEQQFBUGtViM6OhofffSRRR3zFK9///vfmDFjBlq2bAm1Wo1Tp07V4xO6RqfT4Y033kCnTp2gVqsRGBiIJ598EpcvX7aoZ+/ndujQISQkJMDLy0tMjM3TL//9738jOjoaWq0WXbt2xffff28z3tWnwpnj/Mcff6B///7QarVo06YN3n77batk5MiRI0hISIBWq0VgYCCeeeYZbNy48aamyJkTtkuXLoll5eXlmDFjBrp16wYfHx+0aNECffv2xYYNGyyOlclkKCkpweeffy5Ooxw4cKD4enZ2Np5++mm0atUKKpUKUVFRmDt3LgwGQ619ysvLA4AaRxzlcsuvLwUFBZgxYwbatGkDtVqNoKAgDB8+HMePH7c6dtGiRYiKioKnpyf69u2L3377zarOnj17MGLECLRo0QIajQbdu3fHf//7X6t6v/32G26//XZoNBqEhYUhOTkZer3eqp5MJsNrr71mVd66dWs88cQTNt9jffpDRM2Hc/8TJRGRE8rKysL//d//4cUXX8Rbb70lfmE8efIkhg8fjqlTp8LDwwPHjx/HggUL8Pvvv1tNmdTr9RgxYgTGjRuHGTNmYPv27Xj99dfh4+ODV199FQCwevVqTJo0Cc899xwWLlwIuVyOU6dO4ejRowCA8ePHo2vXrhg1ahSee+45PPLII1Cr1QCAbdu2YciQIbj11luxYsUKqNVqLFmyBPfeey9WrVqFxMREi/6MHTsWd999N/7973+jpKQESqUSgOlL9pNPPokXX3wRrVq1wgcffICxY8fi3Llz+PrrrzFr1iz4+Phg3rx5uO+++3D69GmEhYUBAI4ePYq4uDhERETg3XffRUhICH766SdMnjwZubm5mDNnjkUfkpOT0bdvXyxbtgxyuRxBQUH1/oyMRiNGjhyJHTt24MUXX0RcXBzOnj2LOXPmYODAgdizZw/c3d3t/tx0Oh1GjBiBp59+GjNnzrRINjZu3Ig//vgD8+bNg6enJ/75z3/i/vvvx4kTJ9CmTZta+5udnY1HH30UM2bMwJw5c7B+/XokJycjLCwMjz32GADTdRcfHw8PDw8sXboUQUFBWLVq1U2vzcvIyAAAdOjQQSyrqKhAfn4+nn/+ebRs2RI6nQ4///wzRo0ahc8++0zsU3p6OgYPHoxBgwZh9uzZAABvb2/xPd12222Qy+V49dVX0bZtW6Snp+ONN97AmTNnxGTflujoaPj6+mLu3LmQy+VISEiw+AeI6oqKitCvXz+cOXMGL730Enr37o3i4mJs374dWVlZ6NSpk1j3o48+QqdOnZCSkgIAmD17NoYPH46MjAz4+PgAALZs2YK77roLvXv3xrJly+Dj44PVq1cjMTERpaWlYlJ19OhR3HHHHWjdujVWrlwJrVaLJUuW4KuvvrL/Q6hFXftDRM2MQERENj3++OOCh4eHRVl8fLwAQPjll19qPdZoNAp6vV7Ytm2bAEA4cOCAxXkBCP/9738tjhk+fLjQsWNH8fmzzz4r+Pr61tpORkaGAEB45513LMr79OkjBAUFCUVFRWKZwWAQYmJihFatWglGo1EQBEH47LPPBADCY489ZnVu83vds2ePWJaXlycoFArB3d1duHDhglj+559/CgCExYsXi2VDhw4VWrVqJVy9etXivM8++6yg0WiE/Px8QRAEYcuWLQIAYcCAAbW+1+oACM8880yNr69atUoAIKxdu9ai/I8//hAACEuWLLF5XF0+t08//dRmf4KDg4XCwkKxLDs7W5DL5cL8+fPFMnO8MzIyxDJznHfv3m1xzs6dOwtDhw4Vn7/wwguCTCYTjhw5YlFv6NChAgBhy5YtNcajetu//faboNfrhaKiIuHHH38UQkJChAEDBgh6vb7GYw0Gg6DX64Vx48YJ3bt3t3jNw8NDePzxx62OefrppwVPT0/h7NmzFuULFy4UAFi9j+tt3LhRCAgIEAAIAAR/f3/hwQcfFL799luLevPmzRMACGlpaTWey/zfyS233CIYDAax/PfffxcACKtWrRLLOnXqJHTv3t0qHvfcc48QGhoqVFZWCoIgCImJiYK7u7uQnZ0t1jEYDEKnTp2sPmMAwpw5c6z6FRkZaRE7838L1T/LuvaHiJoXTnckIrKTn58fBg8ebFV++vRpPPLIIwgJCYFCoYBSqUR8fDwA4NixYxZ1ZTIZ7r33XouyW2+9FWfPnhWf33bbbSgoKMDDDz+MDRs2IDc3t079Kykpwe7duzF69Gh4enqK5QqFAklJSTh//jxOnDhhccwDDzxg81yhoaGIjY0Vn7do0QJBQUHo1q2bOGIGmEY+AIj9Ly8vxy+//IL7778fWq0WBoNBfAwfPhzl5eVW08xq6kN9fP/99/D19cW9995r0Xa3bt0QEhJiMTXQns+ttn4OGjQIXl5e4vPg4GAEBQVZfKY1CQkJwW233WZRdv31sG3bNsTExFhtXPPwww/f8PzV9enTB0qlEl5eXrjrrrvg5+eHDRs2WK3/+9///ofbb78dnp6ecHNzg1KpxIoVK2zGxJbvv/8egwYNQlhYmMVnMGzYMPH91Gb48OHIzMzE+vXr8fzzz6NLly745ptvMGLECIvRwx9++AEdOnTAnXfeecM+3X333VAoFOLzW2+9FcC16/bUqVM4fvw4Hn30UQCwum6zsrLE/3a2bNmCO+64A8HBweL5FAqF1Sj1zbCnP0TUvHC6IxGRnWytkykuLkb//v2h0WjwxhtvoEOHDtBqtTh37hxGjRqFsrIyi/parRYajcaiTK1Wo7y8XHyelJQEg8GATz75BA888ACMRiN69eqFN954A0OGDKmxf1euXIEgCDb7aU6szGt+antPgCkpu55KpbIqV6lUACD2Py8vDwaDAR988AE++OADm+e+PulsyB0PL126hIKCArFfNbVdn8/NPJ3vev7+/lZlarXa6hz1PTYvLw9RUVFW9aonCXXxxRdfIDo6GkVFRVizZg0+/vhjPPzww/jhhx/EOuvWrcOYMWPw4IMP4oUXXkBISAjc3NywdOlSfPrpp3Vq59KlS/juu+/EqbPXq8s/Ori7u+O+++4Td47MzMzEsGHD8NFHH+Ef//gHunTpgsuXLyMiIqJOfbo+zubpweY4m9flPf/883j++edr7XdeXh5CQkKsXrdVVl/29IeImhcmaUREdrK16+HmzZtx8eJFbN26VRyFAUwbGtyMJ598Ek8++SRKSkqwfft2zJkzB/fccw/++usvREZG2jzGz88PcrkcWVlZVq9dvHgRABAQEGBR3tA7Ofr5+Ykjd88884zNOtcnHA3Zh4CAAPj7+9vczASAOOJl7+fmyB0v/f39LTb3MMvOzrbrPNHR0eJmIYMGDUJlZSX+9a9/4euvv8bo0aMBAP/5z38QFRWFNWvWWLzn6ze2qU1AQABuvfVWvPnmmzZfrz4SW1cRERF46qmnMHXqVBw5cgRdunRBYGAgzp8/b/e5bDH/d5GcnIxRo0bZrGO+xYW/v7/N2NsqU6vVNmN3/T+W3Ex/iKh5YZJGRNQAzF9kzf8yb/bxxx83yPk9PDwwbNgw6HQ63HfffThy5EiNSZqHhwd69+6NdevWYeHCheIGGUajEf/5z3/QqlUri00ipKDVajFo0CDs378ft956a40jWlK55557sHr1alRWVqJ379411pP6c2tI8fHxWLhwIY4ePWox5XH16tU3dd5//vOfWLt2LV599VWMGjUKcrkcMpkMKpXKIkHLzs622t0RqHm08J577sGmTZvQtm1bu++/VlRUBJlMZjFd18w83dKc5A0bNgyvvvoqNm/ebHMasj06duyI9u3b48CBA3jrrbdqrTto0CB8++23uHTpkjiaWVlZiTVr1ljVbd26NQ4ePGhRtnnzZhQXFzdYf4ioeWGSRkTUAOLi4uDn54eJEydizpw5UCqV+PLLL3HgwIF6n3PChAlwd3fH7bffjtDQUGRnZ2P+/Pnw8fFBr169aj12/vz5GDJkCAYNGoTnn38eKpUKS5YsweHDh7Fq1apGGRF6//330a9fP/Tv3x//+Mc/0Lp1axQVFeHUqVP47rvvrHZOtNfff/+Nr7/+2qq8c+fOeOihh/Dll19i+PDhmDJlCm677TYolUqcP38eW7ZswciRI3H//fdL8rlJZerUqfj0008xbNgwzJs3D8HBwfjqq6/Ebeav35a+rvz8/JCcnIwXX3wRX331Ff7v//4P99xzD9atW4dJkyZh9OjROHfuHF5//XWEhobi5MmTFsffcsst2Lp1K7777juEhobCy8sLHTt2xLx585CWloa4uDhMnjwZHTt2RHl5Oc6cOYNNmzZh2bJl4i0krnfixAkMHToUDz30EOLj4xEaGoorV65g48aNWL58OQYOHIi4uDgxLmvWrMHIkSMxc+ZM3HbbbSgrK8O2bdtwzz33YNCgQXbF4+OPP8awYcMwdOhQPPHEE2jZsiXy8/Nx7Ngx7Nu3D//73/8AAK+88gq+/fZbDB48GK+++iq0Wi0++ugjq1s3AKapy7Nnz8arr76K+Ph4HD16FB9++KG4o2RD9IeImhlH71xCROSsatrdsUuXLjbr79q1S+jbt6+g1WqFwMBAYfz48cK+ffsEAMJnn31W63kFQRDmzJkjVP+z/PnnnwuDBg0SgoODBZVKJYSFhQljxowRDh48KNapaXdHQRCEHTt2CIMHDxY8PDwEd3d3oU+fPsJ3331nUce8498ff/xhdXxN7zUyMlK4++67rcphY8fFjIwMYezYsULLli0FpVIpBAYGCnFxccIbb7wh1jHvaPe///3P6pw1QdWOf7Ye5l309Hq9sHDhQqFr166CRqMRPD09hU6dOglPP/20cPLkSfFcN/u51fTezbGqvntfTbs72orz448/LkRGRlqUHT58WLjzzjsFjUYjtGjRQhg3bpzw+eefW+1EaUttn3VZWZkQEREhtG/fXtz98O233xZat24tqNVqITo6Wvjkk0+srlFBMO3sefvttwtarVYAIMTHx4uvXb58WZg8ebIQFRUlKJVKoUWLFkJsbKzw8ssvC8XFxTX29cqVK8Ibb7whDB48WGjZsqWgUqkEDw8PoVu3bsIbb7whlJaWWtWfMmWKEBERISiVSiEoKEi4++67hePHjwuCUPt/J7Cx8+KBAweEMWPGCEFBQYJSqRRCQkKEwYMHC8uWLbOo9+uvvwp9+vQR1Gq1EBISIrzwwgvC8uXLrT7jiooK4cUXXxTCw8MFd3d3IT4+Xvjzzz/rtLujPf0houZDJgiC0HgpIRERETWkp556CqtWrUJeXl6jTyslIiJpcLojERFREzFv3jyEhYWhTZs2KC4uxvfff49//etfeOWVV5igERE1I0zSiIiImgilUol33nkH58+fh8FgQPv27bFo0SJMmTLF0V0jIqIGxOmORERERERETqR+W0ERERERERGRJJikEREREREROREmaURERERERE6EG4dIyGg04uLFi/Dy8mqUG8cSEREREZFzEgQBRUVFCAsLg1xe+1gZkzQJXbx4EeHh4Y7uBhEREREROYlz586hVatWtdZhkiYhLy8vAKYPwtvb26F90ev1SE1NRUJCApRKpUP70hwxvtJifKXF+EqPMZYW4ystxldajK+0nCm+hYWFCA8PF3OE2jBJk5B5iqO3t7dTJGlarRbe3t4Ov0CbI8ZXWoyvtBhf6THG0mJ8pcX4SovxlZYzxrcuy6C4cQgREREREZETYZJGRERERETkRJikERERERERORGuSSMiIiIigmmLdIPBgMrKykZrU6/Xw83NDeXl5Y3arqtozPgqFAq4ubk1yK23mKQRERERkcvT6XTIyspCaWlpo7YrCAJCQkJw7tw53ldXAo0dX61Wi9DQUKhUqps6D5M0IiIiInJpRqMRGRkZUCgUCAsLg0qlarSEyWg0ori4GJ6enje8wTHZr7HiKwgCdDodLl++jIyMDLRv3/6m2mOSRkREREQuTafTwWg0Ijw8HFqttlHbNhqN0Ol00Gg0TNIk0JjxdXd3h1KpxNmzZ8U264tXAhERERERwCSJblpDXUO8EomIiIiIiJwIkzQiIiIiIiIn4vAkbcmSJYiKioJGo0FsbCx27NhRa/1t27YhNjYWGo0Gbdq0wbJly6zqrF27Fp07d4ZarUbnzp2xfv16u9uVyWQ2H++8887NvWEiIiIiIhfQunVrpKSkOLobTZJDk7Q1a9Zg6tSpePnll7F//370798fw4YNQ2Zmps36GRkZGD58OPr374/9+/dj1qxZmDx5MtauXSvWSU9PR2JiIpKSknDgwAEkJSVhzJgx2L17t13tZmVlWTw+/fRTyGQyPPDAA9IFhIiIiIjIDk888QTuu+8+R3fDpj/++ANPPfWU5O20bt1aHFBxd3dHp06d8M4770AQBLvP4yxJpUOTtEWLFmHcuHEYP348oqOjkZKSgvDwcCxdutRm/WXLliEiIgIpKSmIjo7G+PHjMXbsWCxcuFCsk5KSgiFDhiA5ORmdOnVCcnIy7rjjDouA16XdkJAQi8eGDRswaNAgtGnTRrJ4EBERERE5O71eX6d6gYGBjbZb5rx585CVlYVjx47h+eefx6xZs7B8+fJGaVsKDtuCX6fTYe/evZg5c6ZFeUJCAnbt2mXzmPT0dCQkJFiUDR06FCtWrIBer4dSqUR6ejqmTZtmVcecpNWn3UuXLmHjxo34/PPPa31PFRUVqKioEJ8XFhYCMF3Idb2YpWJu395+/HI8B1/9fg7z749BkJdaiq41C/WNL9UN4ystxld6jLG0GF9puUJ89Xo9BEGA0WiE0WgEYLrvVZm+UvK2BUFAma4Sigq9eG82d6WizvdpEwRB7LstR48exQsvvIAdO3bAw8MDQ4YMwaJFixAQEAAA+PHHH/HWW2/h8OHDUCgU6NOnD1JSUtC2bVsAwJkzZ9C2bVusWrUKy5Ytw2+//YaPPvoI27dvR0FBAfr164dFixZBp9MhMTER7733HpRKJQCgTZs2mDJlCqZMmQIAUCgU+Pjjj7Fp0yakpqaiZcuWeOeddzBixAixv99++y1eeOEFnD9/Hn369MFjjz2GsWPHIi8vD76+vjXGwdPTE0FBQQCAsWPHYunSpfjpp58wfvx4AMCpU6fw/PPPY/fu3SgpKUF0dDTefPNN3HnnnQCAwYMH4+zZs5g2bZqYS1RWmj7/Xbt2YdasWfjjjz8QEBCA++67D2+99RY8PDys+mE0GiEIAvR6PRQKhcVr9vw35LAkLTc3F5WVlQgODrYoDw4ORnZ2ts1jsrOzbdY3GAzIzc1FaGhojXXM56xPu59//jm8vLwwatSoWt/T/PnzMXfuXKvy1NTURr/nRk3S0tLsqj8l3XSJTPrXFoztaPs/frrG3viSfRhfaTG+0mOMpcX4Sqs5x9fNzQ0hISEoLi6GTqcDAJTpKtF30W8O6U/69D5wVyluXBGmL/4Gg0EcHKguOzsbAwcOxGOPPYa5c+eivLwcr732GkaPHo1vv/0WgOm78dNPP43OnTujtLQUb731Fu677z7s2LEDcrkcxcXFAICXXnoJb7zxBt5//32oVCr88ssv2LJlC/z9/bFhwwacPn0a48aNQ8eOHfH4448DMCUs5eXlFn2bO3cu5s6di1dffRXLly9HUlISDh48CD8/P2RmZmLMmDF4+umn8dhjj+HgwYN45ZVXAABFRUU1bm9fvR1BEPDrr7/i2LFjiIyMRFFREQDToMugQYPw0ksvQaPRYNWqVRg5ciR+//13hIeH47PPPkO/fv3wxBNP4LHHHgNgGnA5cuQIhg0bhlmzZuG9995Dbm4uXnzxRUycOBEfffSRVV90Oh3Kysqwfft2GAwGi9dKS0vr9JkCTnAz6+v/lUAQhFr/5cBW/evL63JOe9r99NNP8eijj97whnTJycmYPn26+LywsBDh4eFISEiAt7d3rcdKTa/XIy0tDUOGDBH/daMupqSnAgAqlN4YPjxOqu41efWNL9UN4ystxld6jLG0GF9puUJ8y8vLce7cOXh6eorf99x0hhscJR0vby9oVXX7mq5UKuHm5mbzu+a7776LHj16WCwNWrlyJSIjI5GdnY0OHTrg//7v/yyOWblyJUJCQnD+/HnExMTA09MTADBt2jQ8+uijFu22aNECH3/8MRQKBXr27Im1a9di165deO655wCY7hmm0Wgs+vbkk09i7NixAIB33nkHy5cvx7Fjx3DXXXfhyy+/RMeOHfH+++8DAGJjY3H69Gm89dZb8PLyqvH7tFwux2uvvYY333wTOp0Oer0eGo0G06dPh5eXF4qKihAXF4fbb79dPKZ79+744YcfsHXrVjzzzDPw9vaGUqlEQEAA2rdvL9ZbtmwZHn74Ybz00kti2QcffIBBgwbhk08+scoPysvL4e7ujgEDBli9ZiuRronDkrSAgAAoFAqr0aucnByrUS6zkJAQm/Xd3Nzg7+9fax3zOe1td8eOHThx4gTWrFlzw/ekVquhVltPCVQqlU7zR62+fSnVG53mPTgzZ/qsmyPGV1qMr/QYY2kxvtJqzvGtrKyETCaDXC4XR2s81EocnTdU8raNRiOKCovg5e0ltm3PdEfzhhm2Rpn27duHrVu32kxuMjIy0KlTJ/z999+YPXs2fvvtN+Tm5orTJs+fP49bb71VPG+vXr0s2pDJZOjSpYvFNREWFoZDhw5Z1av+vGvXruJzLy8veHl5ITc3F3K5HH/99ZdVO7179wYAi8/GlhdeeAFPPPEELl++jJdffhmDBw9Gv379xPdTWlqK119/Hd9//z0uXrwIg8GAsrIynDt3rtb+7tu3D6dOncJXX30llpmnl549exbR0dEW/ZDL5ZDJZDb/e7Hnvx+HJWkqlQqxsbFIS0vD/fffL5anpaVh5MiRNo/p27cvvvvuO4uy1NRU9OzZU3zTffv2RVpamsW6tNTUVMTFxdWr3RUrViA2NhZdu3at/5ttBkod+K9JRERERI1NJpPVeTTrZhiNRhhUCmhVbrUmIfU997333osFCxZYvRYaGgoAuPfeexEeHo5PPvkEYWFhMBqNiImJEad9mtlaf3V90iGTyWpcG1eXY2zNbKvrDo0BAQFo164d2rVrh7Vr16Jdu3bo06cPBg8eDAB48cUXkZqaioULF6Jdu3Zwd3fH6NGjrd7n9YxGI55++mlMnjzZ6rWIiIg69a0+HDrdcfr06UhKSkLPnj3Rt29fLF++HJmZmZg4cSIA0/TBCxcu4IsvvgAATJw4ER9++CGmT5+OCRMmID09HStWrMCqVavEc06ZMgUDBgzAggULMHLkSGzYsAE///wzdu7cWed2zQoLC/G///0P7777biNEw7mVVEi/cJaIiIiIGk6PHj2wdu1atG7dGm5u1l/78/LycOzYMXz88cfo378/AFh8Z25snTp1wqZNmyzK9uzZY/d5/Pz88Nxzz+H555/H3r17AZje1xNPPCEO0hQXF+PMmTMWx6lUKnGzELMePXrgyJEjaNeund39uBkO3YI/MTERKSkpmDdvHrp164bt27dj06ZNiIyMBGC6V1n1e5dFRUVh06ZN2Lp1K7p164bXX38dixcvtrh3WVxcHFavXo3PPvsMt956K1auXIk1a9aIQ6V1adds9erVEAQBDz/8sMSRcH6NsbsREREREdnv6tWr+PPPPy0emZmZeOaZZ5Cfn4+HH34Yv//+O06fPo3U1FSMHTsWlZWV8PPzg7+/P5YvX45Tp05h8+bNFvsrNLann34ax48fx0svvYS//voL//3vf7Fy5UoA1vtJ3MgzzzyDEydOiPdTbtu2LdatW4c///wTBw4cwCOPPGI16te6dWts374dFy5cQG5uLgDThinp6el45pln8Oeff+LkyZP49ttvxXV3UnFokgYAkyZNwpkzZ1BRUYG9e/diwIAB4msrV67E1q1bLerHx8dj3759qKioQEZGhtXoFwCMHj0ax48fh06nw7Fjx2zuylhbu2ZPPfUUSktL4ePjc/NvlIiIiIhIAlu3bkX37t0tHq+++irCwsLw66+/orKyEkOHDkVMTAymTJkCHx8fcY3X6tWrsXfvXsTExGDatGl45513HPY+oqKi8PXXX2PdunW49dZbsXTpUrz88ssAYHPfh9oEBgYiKSkJ8+bNg9FoxKJFi+Dn54e4uDjce++9GDp0KHr06GFxzLx588RbDgQGBgIAbr31Vmzbtg0nT55E//790b17d8yePVucLioVh+/uSM7LaLScA6yvNEKpcHheT0RERERVVq5cKY422dK+fXusW7euxtfvvPNOHD161KKs+jqw1q1b21wXZqtN832Jza6fTmjrPAUFBRbPR4wYYXHftDfffBOtWrWqdZf169sxW758OYxGIwoLC9G6dWts3rzZ4vVnnnnG4nmfPn1w4MABq/P06tULqampNbYvBSZpVKMKg+UQcH6JDsHetd+GgIiIiIiovpYsWYJevXrB398fv/76K9555x08++yzju5Wo2OSRjW6fkfH3OIKJmlEREREJJmTJ0/ijTfeQH5+PiIiIjBjxgwkJyc7uluNjkka1ej6zUJyi2vfopSIiIiI6Ga89957eO+99xzdDYfjAiOqUfl1SVpecYWDekJERERE5DqYpFGNSnXXj6QxSSMiIqLmq643TiaqSUNdQ0zSqEZluutH0jjdkYiIiJofpVIJACgtLXVwT6ipM19D5muqvrgmjWp0/Zq0yxxJIyIiomZIoVDA19cXOTk5AACtVmv3zZPry2g0QqfToby8HHI5x08aWmPFVxAElJaWIicnB76+vlAoFDd1PiZpVCPrNWkcSSMiIqLmKSQkBADERK2xCIKAsrIyuLu7N1pi6EoaO76+vr7itXQzmKRRja5fk5ZXwpE0IiIiap5kMhlCQ0MRFBQEvV7faO3q9Xps374dAwYMuOkpcmStMeOrVCpvegTNjEka1cg83THUR4Osq+XILeJIGhERETVvCoWiwb5o17U9g8EAjUbDJE0CTTW+nPhKNTJvHBLupwVg2t3RaOSuR0REREREUmKSRjUSk7QWpiTNYBRwpZSjaUREREREUmKSRjUyT3f0dndDgKcKAHCpkOvSiIiIiIikxCSNamRO0tyVCgR5aQAAl4rKHdklIiIiIqJmj0ka1cg83dFdqUCwtxoAkFPIJI2IiIiISEpM0qhG4kiaSoFg76qRNE53JCIiIiKSFJM0qpE4kqZSIEhM0jiSRkREREQkJSZpVKPqa9LM0x05kkZEREREJC3ezJpqZB5J06oU8NaYbv6Xw41DiIiIiIgkxSSNamQeSdMoFfD3MI+kMUkjIiIiIpISpztSjWxNd7xcVIFKo+DIbhERERERNWtM0qhG1TcO8fdUQy4DjAKQV8x1aUREREREUmGSRjUyj6RpVQoo5DIEenHzECIiIiIiqTFJoxqZR9I0SgUAVLtXGtelERERERFJhUka2VRpFFBhMAIwrUkDgCCvqiSNOzwSEREREUmGSRrZVF411REAtCrTJqDivdKuMkkjIiIiIpIKkzSyqaxakqZ2M10mIVXTHbM53ZGIiIiISDJM0sima+vR5JDLZQCAMF93AMDFAiZpRERERERSYZJGNl3b2fHa/c6vJWllDukTEREREZErYJJGNon3SKvaNAQAWlYlaRcKyiAIvKE1EREREZEUmKSRTeaRNI3y2iUS7KOGTAZUGIy4Uqp3VNeIiIiIiJo1JmlkkziSpro2kqZ2UyDQ07TDI6c8EhERERFJg0ka2SSuSVO6WZSHVZvySEREREREDY9JGtkk7u5YbSQNuLYujSNpRERERETSYJJGNpXqzRuHWF4iYb6me6UxSSMiIiIikgaTNLKpXGe9BT8AhPrwXmlERERERFJikkY2Xdvd0XK6I9ekERERERFJi0ka2VSmt75PGsA1aUREREREUnN4krZkyRJERUVBo9EgNjYWO3bsqLX+tm3bEBsbC41GgzZt2mDZsmVWddauXYvOnTtDrVajc+fOWL9+fb3aPXbsGEaMGAEfHx94eXmhT58+yMzMrP+bbULKxOmO14+kmdak5RRVoMJQ2ej9IiIiIiJq7hyapK1ZswZTp07Fyy+/jP3796N///4YNmxYjYlQRkYGhg8fjv79+2P//v2YNWsWJk+ejLVr14p10tPTkZiYiKSkJBw4cABJSUkYM2YMdu/ebVe7f//9N/r164dOnTph69atOHDgAGbPng2NRiNdQJyIrfukAUALDxXUbqbL5tLVikbvFxERERFRc+fQJG3RokUYN24cxo8fj+joaKSkpCA8PBxLly61WX/ZsmWIiIhASkoKoqOjMX78eIwdOxYLFy4U66SkpGDIkCFITk5Gp06dkJycjDvuuAMpKSl2tfvyyy9j+PDh+Oc//4nu3bujTZs2uPvuuxEUFCRZPJxJTWvSZDIZWvqZpjyev1La6P0iIiIiImru3G5cRRo6nQ579+7FzJkzLcoTEhKwa9cum8ekp6cjISHBomzo0KFYsWIF9Ho9lEol0tPTMW3aNKs65iStLu0ajUZs3LgRL774IoYOHYr9+/cjKioKycnJuO+++2p8TxUVFaiouDa6VFhYCADQ6/XQ6/U1B6MRmNuvaz9KKkz11ArrY8J93XH6cgkyLhehV6RPw3a0ibI3vmQfxldajK/0GGNpMb7SYnylxfhKy5nia08fHJak5ebmorKyEsHBwRblwcHByM7OtnlMdna2zfoGgwG5ubkIDQ2tsY75nHVpNycnB8XFxXj77bfxxhtvYMGCBfjxxx8xatQobNmyBfHx8Tb7N3/+fMydO9eqPDU1FVqttpZoNJ60tLQ61TuXJQcgx4kjh7Ap56DFa8ZC02tb9hyG53Wvubq6xpfqh/GVFuMrPcZYWoyvtBhfaTG+0nKG+JaW1n0WmsOSNDOZTGbxXBAEq7Ib1b++vC7nrK2O0WgEAIwcOVIclevWrRt27dqFZcuW1ZikJScnY/r06eLzwsJChIeHIyEhAd7e3jW+p8ag1+uRlpaGIUOGQKlU3rD+5xd+B64WoE+vHkjobJnQZv96Bjt+/Asqv1AMH95Vqi43KfbGl+zD+EqL8ZUeYywtxldajK+0GF9pOVN8zbPs6sJhSVpAQAAUCoXVqFlOTo7VKJdZSEiIzfpubm7w9/evtY75nHVpNyAgAG5ubujcubNFnejoaOzcubPG96RWq6FWq63KlUqlwy8Ks7r2pUxvSlQ93dVW9VsHegEAzheUO837chbO9Fk3R4yvtBhf6THG0mJ8pcX4SovxlZYzxNee9h22cYhKpUJsbKzV0GNaWhri4uJsHtO3b1+r+qmpqejZs6f4pmuqYz5nXdpVqVTo1asXTpw4YVHnr7/+QmRkpJ3vtGkq19vegh8AIv1NUzcz87lxCBERERFRQ3PodMfp06cjKSkJPXv2RN++fbF8+XJkZmZi4sSJAEzTBy9cuIAvvvgCADBx4kR8+OGHmD59OiZMmID09HSsWLECq1atEs85ZcoUDBgwAAsWLMDIkSOxYcMG/PzzzxYjYDdqFwBeeOEFJCYmYsCAARg0aBB+/PFHfPfdd9i6dWvjBMfBxC34ldZJWrifKUkrKNXjapkePu78Vx8iIiIioobi0CQtMTEReXl5mDdvHrKyshATE4NNmzaJo1VZWVkW9y6LiorCpk2bMG3aNHz00UcICwvD4sWL8cADD4h14uLisHr1arzyyiuYPXs22rZtizVr1qB37951bhcA7r//fixbtgzz58/H5MmT0bFjR6xduxb9+vVrhMg4Xk1b8AOAh9oNAZ4q5BbrcC6/FD4tucMjEREREVFDcfjGIZMmTcKkSZNsvrZy5Uqrsvj4eOzbt6/Wc44ePRqjR4+ud7tmY8eOxdixY2ut01yZR9JsTXcEgIgWWuQW65CZX4oYJmlERERERA3GoTezJudkqDRCV2naOMTWdEfAlKQBXJdGRERERNTQmKSRlXKDUfzdvZaRNAA4m8ckjYiIiIioITFJIyulOgMAQCYD1G62L5EIfw8AwDmOpBERERERNSgmaWSlXHdtqmNNNxbndEciIiIiImkwSSMr5p0da1qPBly7V9qFgjLoqk2PJCIiIiKim8MkjayYpzva2n7fLMhLDQ+VApVGgaNpREREREQNiEkaWTGPpNW0/T4AyGQyRAWa1qX9fbm4UfpFREREROQKmKSRlXLzdMdakjQAaBPgCQA4fblE8j4REREREbkKJmlkpaxq45DapjsCQJuqkbTTHEkjIiIiImowTNLIinlNWm3THQGgTWDVSFouR9KIiIiIiBoKkzSyUl6H3R0BoE0AR9KIiIiIiBoakzSyUpct+IFr0x2vlOpxpUQneb+IiIiIiFwBkzSyUqqr28YhWpUbQn00AIDTuRxNIyIiIiJqCEzSyEpdR9KAa6Npf3OHRyIiIiKiBsEkjayU13EkDeA2/EREREREDY1JGlkxT3e80Rb8ALfhJyIiIiJqaEzSyIp5uuONtuAHgLZV2/CfymGSRkRERETUEJikkZW6bsEPAB1DvAAAZ/JKxOOIiIiIiKj+mKSRlbru7ggAQV5q+LgrYRSAvznlkYiIiIjopjFJIyv27O4ok8nQMdg0mvbXpSJJ+0VERERE5AqYpJGVMjtG0oBrUx6PZzNJIyIiIiK6WUzSyIo9a9IAoENVkvYXkzQiIiIiopvGJI2s2LMmDUC16Y5ck0ZEREREdLOYpJEVe9akAUCHYNM2/BcKylBUrpesX0REREREroBJGlkRpzvWcSTNV6tCsLcaAEfTiIiIiIhuFpM0sqCvNEJfKQCo+0gaAHQM8QYAnOC6NCIiIiKim8IkjSyUVbshdV1H0gCgY9WUR27DT0RERER0c5ikkYXyqk1D5DJApaj75WEeSTuaVShJv4iIiIiIXAWTNLIg7uyoVEAmk9X5uC5hpiTt2MVCGI2CJH0jIiIiInIFTNLIgrizo8rNruPaBXlC5SZHUYUBmfmlUnSNiIiIiMglMEkjC9eSNPsuDaVCjk5VN7U+cpFTHomIiIiI6otJGlko19l3j7TquoT5AAAOX7zaoH0iIiIiInIlTNLIgrgmzc7pjgAQ09K0Lu3wBSZpRERERET1xSSNLIjTHZX2XxoxVSNpRy8WQhC4eQgRERERUX0wSSML15I0+6c7dgzxgkIuQ16JDtmF5Q3dNSIiIiIil8AkjSyUidMd7U/SNEoF2geZbmp9+AI3DyEiIiIiqg8maWTh2kia/WvSgGqbh3BdGhERERFRvTBJIwvXRtLqd2mYNw85xCSNiIiIiKhemKSRhZtZkwYA3cJ9AQB/nivg5iFERERERPXg8CRtyZIliIqKgkajQWxsLHbs2FFr/W3btiE2NhYajQZt2rTBsmXLrOqsXbsWnTt3hlqtRufOnbF+/Xq7233iiScgk8ksHn369Lm5N9sElN3EFvwA0DnMGyqFHPklOpzLL2vIrhERERERuQSHJmlr1qzB1KlT8fLLL2P//v3o378/hg0bhszMTJv1MzIyMHz4cPTv3x/79+/HrFmzMHnyZKxdu1ask56ejsTERCQlJeHAgQNISkrCmDFjsHv3brvbveuuu5CVlSU+Nm3aJE0gnMjNjqSp3RToUjXlcf+5Kw3WLyIiIiIiV+HQJG3RokUYN24cxo8fj+joaKSkpCA8PBxLly61WX/ZsmWIiIhASkoKoqOjMX78eIwdOxYLFy4U66SkpGDIkCFITk5Gp06dkJycjDvuuAMpKSl2t6tWqxESEiI+WrRoIUkcnMnN3CfNzDzlcX9mQQP0iIiIiIjItdRvTlsD0Ol02Lt3L2bOnGlRnpCQgF27dtk8Jj09HQkJCRZlQ4cOxYoVK6DX66FUKpGeno5p06ZZ1TEnafa0u3XrVgQFBcHX1xfx8fF48803ERQUVON7qqioQEVFhfi8sNC0Db1er4der6/xuMZgbv9G/SgpN72uUsjq3edbw7wAAPvO5jv8fTeWusaX6ofxlRbjKz3GWFqMr7QYX2kxvtJypvja0weHJWm5ubmorKxEcHCwRXlwcDCys7NtHpOdnW2zvsFgQG5uLkJDQ2usYz5nXdsdNmwYHnzwQURGRiIjIwOzZ8/G4MGDsXfvXqjVapv9mz9/PubOnWtVnpqaCq1WW0MkGldaWlqtr1/IlgOQ48SRg9h06UC92rhSDgBuOHzxKr75bhPqccu1JutG8aWbw/hKi/GVHmMsLcZXWoyvtBhfaTlDfEtLS+tc12FJmplMJrN4LgiCVdmN6l9fXpdz3qhOYmKi+HtMTAx69uyJyMhIbNy4EaNGjbLZt+TkZEyfPl18XlhYiPDwcCQkJMDb27vG99QY9Ho90tLSMGTIECiVyhrrfXpuN1B4FX17xeKO6JpHDWsjCAKWnNyG3GIdIrrGoUeEbz173XTUNb5UP4yvtBhf6THG0mJ8pcX4SovxlZYzxdc8y64uHJakBQQEQKFQWI2a5eTkWI1ymYWEhNis7+bmBn9//1rrmM9Zn3YBIDQ0FJGRkTh58mSNddRqtc1RNqVS6fCLwuxGfSnXGwEAnu7qm+pz9wg/pB29hEMXi9C7bWC9z9PUONNn3RwxvtJifKXHGEuL8ZUW4ystxldazhBfe9p32MYhKpUKsbGxVkOPaWlpiIuLs3lM3759reqnpqaiZ8+e4puuqY75nPVpFwDy8vJw7tw5hIaG1u0NNlHixiE3OUexe9Xo2b5M7vBIRERERGQPh053nD59OpKSktCzZ0/07dsXy5cvR2ZmJiZOnAjANH3wwoUL+OKLLwAAEydOxIcffojp06djwoQJSE9Px4oVK7Bq1SrxnFOmTMGAAQOwYMECjBw5Ehs2bMDPP/+MnTt31rnd4uJivPbaa3jggQcQGhqKM2fOYNasWQgICMD999/fiBFqfDe7Bb9ZbIQfAOCPM1duOIWViIiIiIiucWiSlpiYiLy8PMybNw9ZWVmIiYnBpk2bEBkZCQDIysqyuHdZVFQUNm3ahGnTpuGjjz5CWFgYFi9ejAceeECsExcXh9WrV+OVV17B7Nmz0bZtW6xZswa9e/euc7sKhQKHDh3CF198gYKCAoSGhmLQoEFYs2YNvLy8Gik6jnHtZtY3l6R1DfeFyk2Oy0UVyMgtQZtAz4boHhERERFRs+fwjUMmTZqESZMm2Xxt5cqVVmXx8fHYt29freccPXo0Ro8eXe923d3d8dNPP9V6fHMkCII4kqa9ySRNo1SgW7gvfs/Ix+8Z+UzSiIiIiIjqyKE3sybnoq8UUGk07ZapucnpjgDQO8p08+/fM/Jv+lxERERERK6CSRqJzKNowM2vSQOA3lGmHTd3M0kjIiIiIqozJmkkMq9Hc5PLoHK7+UujR6Qv3OQyXCgow/krdb95HxERERGRK2OSRqKG2tnRTKtyQ0xLHwCc8khEREREVFdM0khkHknT3OSmIdX1bmNal7b7NJM0IiIiIqK6YJJGojK9AUDDjaQB1zYP+S0jr8HOSURERETUnDFJI1GZzgjg5rffr65X6xZQyGU4m1eKc/lcl0ZEREREdCNM0khkXpPWENvvm3lplOgR4QsA2Hkqt8HOS0RERETUXDFJI1GpruGnOwJAv3aBAIAdJy836HmJiIiIiJojJmkkKq8aSWvI6Y4A0K99AADg11N54s2yiYiIiIjINiZpJJJid0cA6NrKB14aN1wt0+PQhasNem4iIiIiouaGSRqJyvSmjUMaerqjm0KOuLb+AICdnPJIRERERFQrJmkkKqtak9bQ0x0BoF9707q07Se5eQgRERERUW2YpJHIvLtjQ4+kAcCAqnVp+85eQXGFocHPT0RERETUXDBJI5EUW/CbRfp7oLW/FgajwCmPRERERES1YJJGotKqjUPcJZjuCACDOwUDAH4+liPJ+YmIiIiImgMmaSSSagt+szujgwAAm4/ncCt+IiIiIqIaMEkjkbgFvwTTHQGgV1QLeGnckF+iw5/nrkjSBhERERFRU8ckjUTidEeJkjSlQo6BHU2jaZzySERERERkG5M0Ekk93RG4NuXxl2OXJGuDiIiIiKgpY5JGIim34Dcb2CEICrkMf10qxrn8UsnaISIiIiJqquqdpOl0Opw4cQIGA+951VyIW/BLOJLmo1WiZ6QfAOCnI9mStUNERERE1FTZnaSVlpZi3Lhx0Gq16NKlCzIzMwEAkydPxttvv93gHaTGY944RMrpjgBwV0wIAOCHw0zSiIiIiIiuZ3eSlpycjAMHDmDr1q3QaDRi+Z133ok1a9Y0aOeocZVJvHGI2bCYUADA3rNXkHW1TNK2iIiIiIiaGruTtG+++QYffvgh+vXrB5lMJpZ37twZf//9d4N2jhqPIAiNsiYNAEJ8NOKUxx8OcTSNiIiIiKg6u5O0y5cvIygoyKq8pKTEImmjpqXCYIT5/tJSrkkzu/tW02japkNZkrdFRERERNSU2J2k9erVCxs3bhSfmxOzTz75BH379m24nlGjMm+/D0g/kgZcm/K4h1MeiYiIiIgsuNl7wPz583HXXXfh6NGjMBgMeP/993HkyBGkp6dj27ZtUvSRGoF5qqNSIYNSIf2dGcxTHvecvYIfDmVjbL8oydskIiIiImoK7P42HhcXh19//RWlpaVo27YtUlNTERwcjPT0dMTGxkrRR2oEpVWbhmgaYRTNzDzlcSOnPBIRERERieweSQOAW265BZ9//nlD94UcqLG236/u7ltC8fr3R7H37BWczStBpL9Ho7VNREREROSs7B5JUygUyMnJsSrPy8uDQtF4X/CpYZU30s6O1QV5a9CvfSAAYN2+C43WLhERERGRM7M7SRMEwWZ5RUUFVCrVTXeIHMO8Jq0xpzsCwAM9WgIA1u0/X+O1RURERETkSuo83XHx4sUATLs5/utf/4Knp6f4WmVlJbZv345OnTo1fA+pUZQ6YLojACR0DoGHSoFz+WXYc/YKerVu0ajtExERERE5mzonae+99x4A00jasmXLLKY2qlQqtG7dGsuWLWv4HlKjEKc7NnKS5q5SYPgtofjf3vNYt+88kzQiIiIicnl1TtIyMjIAAIMGDcK6devg5+cnWaeo8Zk3DmnMNWlmo3q0wv/2nsf3B7Mw594ujT7lkoiIiIjImdi9Jm3Lli1M0JohR2zBb9Y7qgVa+rqjqNyAn45kN3r7RERERETOpF5b8J8/fx7ffvstMjMzodPpLF5btGhRg3SMGpd545DGXpMGAHK5DKNjW+H9X07iq92ZGNmtZaP3gYiIiIjIWdidpP3yyy8YMWIEoqKicOLECcTExODMmTMQBAE9evSQoo/UCByxBX91D90Wjg82n8TujHycyilGuyDPGx9ERERERNQM2T3dMTk5GTNmzMDhw4eh0Wiwdu1anDt3DvHx8XjwwQel6CM1AnG6owNG0gAg1McdgzsFAwC+2p3pkD4QERERETkDu5O0Y8eO4fHHHwcAuLm5oaysDJ6enpg3bx4WLFhgdweWLFmCqKgoaDQaxMbGYseOHbXW37ZtG2JjY6HRaNCmTRubO0quXbsWnTt3hlqtRufOnbF+/fqbavfpp5+GTCZDSkqK3e+vqRCnOyrrNQO2QTzaOwIAsHbfeXFkj4iIiIjI1didpHl4eKCiogIAEBYWhr///lt8LTc3165zrVmzBlOnTsXLL7+M/fv3o3///hg2bBgyM22PpGRkZGD48OHo378/9u/fj1mzZmHy5MlYu3atWCc9PR2JiYlISkrCgQMHkJSUhDFjxmD37t31avebb77B7t27ERYWZtd7a2rKzbs7quy+JBrMgA6BaOnrjqtlemw6lOWwfhAREREROZLd38j79OmDX3/9FQBw9913Y8aMGXjzzTcxduxY9OnTx65zLVq0COPGjcP48eMRHR2NlJQUhIeHY+nSpTbrL1u2DBEREUhJSUF0dDTGjx+PsWPHYuHChWKdlJQUDBkyBMnJyejUqROSk5Nxxx13WIyC1bXdCxcu4Nlnn8WXX34JpVJp13trasocvCYNABRyGR6+LRwA8J/fzjqsH0REREREjmT33LZFixahuLgYAPDaa6+huLgYa9asQbt27cQbXteFTqfD3r17MXPmTIvyhIQE7Nq1y+Yx6enpSEhIsCgbOnQoVqxYAb1eD6VSifT0dEybNs2qjjlJq2u7RqMRSUlJeOGFF9ClS5c6vaeKigpxlBEACgsLAQB6vR56vb5O55CKuf2a+lFSYSpXKWqu0xhGdQvF+7+cxL7MAuzNyMWtrXwc1hd73Ci+dHMYX2kxvtJjjKXF+EqL8ZUW4ystZ4qvPX2wO0lr06aN+LtWq8WSJUvsPQUA09TIyspKBAcHW5QHBwcjO9v2vbKys7Nt1jcYDMjNzUVoaGiNdcznrGu7CxYsgJubGyZPnlzn9zR//nzMnTvXqjw1NRVarbbO55FSWlqazfIL2QoAMhw7fBCbsg40bqeu081Pjj9y5Xjz63Q83sHo0L7Yq6b4UsNgfKXF+EqPMZYW4ystxldajK+0nCG+paWlda7bYLtErFu3Dq+99hoOHjxo13EymcziuSAIVmU3qn99eV3OWVudvXv34v3338e+fftq7cv1kpOTMX36dPF5YWEhwsPDkZCQAG9v7zqfRwp6vR5paWkYMmSIzamb/8r8DSgqRNxtPTGoY6ADenhN5MVC3Lf0Nxy4okD32wci1Efj0P7UxY3iSzeH8ZUW4ys9xlhajK+0GF9pMb7Scqb4mmfZ1YVdSdonn3yC1NRUKJVKTJkyBb1798bmzZsxY8YMnDhxAklJSXU+V0BAABQKhdWoWU5OjtUol1lISIjN+m5ubvD396+1jvmcdWl3x44dyMnJQUREhPh6ZWUlZsyYgZSUFJw5c8Zm/9RqNdRqtVW5Uql0+EVhVlNfyvSmEStPd5XD+9ot0h992rTAb6fz8eUf55E8LNqh/bGHM33WzRHjKy3GV3qMsbQYX2kxvtJifKXlDPG1p/06bxyycOFCPPPMM8jIyMCGDRswePBgvPXWWxgzZgzuu+8+ZGZm4uOPP65zwyqVCrGxsVZDj2lpaYiLi7N5TN++fa3qp6amomfPnuKbrqmO+Zx1aTcpKQkHDx7En3/+KT7CwsLwwgsv4Keffqrze2xKyqp2d9SqHLcFf3Xj+5mm1X61OxMlFQYH94aIiIiIqPHU+Rv5ihUrsGzZMowdOxZbt27F4MGDsXnzZpw6dQq+vr71anz69OlISkpCz5490bdvXyxfvhyZmZmYOHEiANP0wQsXLuCLL74AAEycOBEffvghpk+fjgkTJiA9PR0rVqzAqlWrxHNOmTIFAwYMwIIFCzBy5Ehs2LABP//8M3bu3Fnndv39/cWROTOlUomQkBB07NixXu/V2ZU7we6O1Q3uFISoAA9k5Jbgv3vO4cnboxzdJSIiIiKiRlHnJO3s2bO48847AQADBw6EUqnEm2++We8EDQASExORl5eHefPmISsrCzExMdi0aRMiIyMBAFlZWRb3LouKisKmTZswbdo0fPTRRwgLC8PixYvxwAMPiHXi4uKwevVqvPLKK5g9ezbatm2LNWvWoHfv3nVu1xWV6pwrSZPLZRjbLwqzvzmMT7afxqO9I6Fyc9w93IiIiIiIGkudk7Ty8nJoNNc2cFCpVAgMvPkNJiZNmoRJkybZfG3lypVWZfHx8di3b1+t5xw9ejRGjx5d73ZtqWkdWnMgCMK1+6SpnCNJA4AHY1th8S8ncfFqOdbvP4/EXhE3PoiIiIiIqImzawHSv/71L3h6egIADAYDVq5ciYCAAIs69mxZT86hwnBtm3tnStI0SgWeHtAGb2w8hiVb/8YDPVrBTcHRNCIiIiJq3uqcpEVEROCTTz4Rn4eEhODf//63RR2ZTMYkrQkybxoCOM90R7NHekfgoy2ncDavFN8fzMJ93Vs6uktERERERJKqc5LWnKf7ubrSqqmOKjc5FPK63xeuMWhVbhjfvw3e+ekEPtxyCiO6hkHuZH0kIiIiImpInDtG4kias42imT3WNxLeGjecyinGpsNZju4OEREREZGkmKSR022/fz0vjRJj+5m24H839S/oK403OIKIiIiIqOlikkbi9vtaJ9o05Hrj+7dBCw8VMnJL8PXe847uDhERERGRZJikkbj9vsZJR9IAwFPthmcGtQMAvP/zSXH0j4iIiIiouWGSRtfWpDnxSBoAPNo7Ai193ZFdWI4v0s84ujtERERERJKwO0krLCy0+SgqKoJOp5OijySxMr0BgPOuSTPTKBWYemd7AMBHW/7G1TK9g3tERERERNTw7E7SfH194efnZ/Xw9fWFu7s7IiMjMWfOHBiN3NyhqSjTmT4rZx9JA4BRPVqhfZAnrpbp8eHmk47uDhERERFRg7M7SVu5ciXCwsIwa9YsfPPNN1i/fj1mzZqFli1bYunSpXjqqaewePFivP3221L0lyRQ5uS7O1ankMvw8t3RAIDPfj2Dvy8XO7hHREREREQNq843szb7/PPP8e6772LMmDFi2YgRI3DLLbfg448/xi+//IKIiAi8+eabmDVrVoN2lqTh7FvwX29gxyAM7hSEzcdz8ObGY/j0iV6O7hIRERERUYOxeyQtPT0d3bt3tyrv3r070tPTAQD9+vVDZmbmzfeOGkWprmpNWhOY7mj2yt3RcJPLsPl4DracyHF0d4iIiIiIGozdSVqrVq2wYsUKq/IVK1YgPDwcAJCXlwc/P7+b7x01iqa0Js2sTaAnnry9NQDg9e+PQmfgGkgiIiIiah7snu64cOFCPPjgg/jhhx/Qq1cvyGQy/PHHHzh+/Di+/vprAMAff/yBxMTEBu8sSaMprUmr7rk72mPdvgs4fbkE/9p5GpMGtnN0l4iIiIiIbprdI2kjRozAiRMnMGzYMOTn5yM3NxfDhg3D8ePHcc899wAA/vGPf2DRokUN3lmSRlnVdEdtExpJAwBvjRLJw02biLz/80mczStxcI+IiIiIiG6e3SNpANC6dWvu3tiMmEfSNE1sJA0AHujREuv2nceuv/PwyjeH8cXY2yCTyRzdLSIiIiKieqtXklZQUIDff/8dOTk5VvdDe+yxxxqkY9R4yvRVa9KaYJImk8nw5v23YGjKduw4mYsNf17Efd1bOrpbRERERET1ZneS9t133+HRRx9FSUkJvLy8LEYtZDIZk7QmqKwJ7u5YXVSAByYPboeFqX/h9e+PIr5DIPw8VI7uFhERERFRvdi9Jm3GjBkYO3YsioqKUFBQgCtXroiP/Px8KfpIEhM3DmmiSRoAPDWgLToEeyKvRIc53x5xdHeIiIiIiOrN7iTtwoULmDx5MrRarRT9IQco0zXN3R2rU7nJ8c/RXaGQy/DtgYv4/uBFR3eJiIiIiKhe7E7Shg4dij179kjRF3KQ8ia8Jq26buG+mDSwLQDglW8OI6ew3ME9IiIiIiKyn91r0u6++2688MILOHr0KG655RYolUqL10eMGNFgnaPGUdpEt+C35bnB7bH5eA6OXCzEzHWHsOLxntztkYiIiIiaFLuTtAkTJgAA5s2bZ/WaTCZDZWXlzfeKGlVT3oL/eio3ORaN6YZ7P9iJzcdzsPqPc3j4tghHd4uIiIiIqM7snu5oNBprfDBBa3qMRuHadMdmMJIGAB1DvPD80A4AgLnfHcFfl4oc3CMiIiIiorqzO0mj5qXccC2xbg7THc3G92uD/u0DUK434pkv94mboxARERERObs6TXdcvHgxnnrqKWg0GixevLjWupMnT26QjlHjqJ68aNyaT5Iml8uwaEw3DF+8AydzijHn28P45+iuju4WEREREdEN1SlJe++99/Doo49Co9Hgvffeq7GeTCZjktbEmNejqd3kkMub1wYbgV5qvJ/YDY+u2I3/7jmPvm39cX/3Vo7uFhERERFRreqUpGVkZNj8nZo+8R5pzWiqY3Vx7QIweXB7vP/LSby8/jA6h/qgY4iXo7tFRERERFQjrklzceaRNG0z2NmxJpPvaI/b2/mjVFeJCV/sQUGpztFdIiIiIiKqkd1b8FdWVmLlypX45ZdfkJOTA6PRaPH65s2bG6xzJD3zSJqmmY6kAYBCLsMHD/fAiA93IjO/FM+t2o/PnugFNwX/jYKIiIiInI/d31KnTJmCKVOmoLKyEjExMejatavFg5oW80iaezMeSQOAFh4qLE/qCXelAjtO5uKfP51wdJeIiIiIiGyyeyRt9erV+O9//4vhw4dL0R9qZOaRtOa0/X5NOod5450Hb8WzX+3H8u2n0SnEC6N6cCMRIiIiInIudo+kqVQqtGvXToq+kAOYR9I0zXwkzeyeW8MwaWBbAMBLaw9i19+5Du4REREREZElu5O0GTNm4P3334cgCFL0hxqZq0x3rO75hI4YfksI9JUCnv73Xvx1qcjRXSIiIiIiEtk93XHnzp3YsmULfvjhB3Tp0gVKpdLi9XXr1jVY50h6rjTd0cx8o+ucwt3Yc/YKnvzsD6yfFIcgb42ju0ZEREREZP9Imq+vL+6//37Ex8cjICAAPj4+Fg9qWpr7fdJqolEq8MljPREV4IELBWV4cuUfKK4wOLpbRERERET2jaQZDAYMHDgQQ4cORUhIiFR9okbkamvSqvPzUGHlk70waskuHLlYiPGf/4GVT97mkrEgIiIiIudh10iam5sb/vGPf6CiokKq/lAjK9W53pq06iL9PfDZk73gqXbDb6fz8Y//7IXOYLzxgUREREREErF7umPv3r2xf//+BuvAkiVLEBUVBY1Gg9jYWOzYsaPW+tu2bUNsbCw0Gg3atGmDZcuWWdVZu3YtOnfuDLVajc6dO2P9+vV2t/vaa6+hU6dO8PDwgJ+fH+68807s3r375t6sEyrXu96atOvd2soXnz7RCxqlHFtOXMa0NX/CUMlEjYiIiIgcw+4kbdKkSZgxYwY+/PBDpKen4+DBgxYPe6xZswZTp07Fyy+/jP3796N///4YNmwYMjMzbdbPyMjA8OHD0b9/f+zfvx+zZs3C5MmTsXbtWrFOeno6EhMTkZSUhAMHDiApKQljxoyxSLDq0m6HDh3w4Ycf4tChQ9i5cydat26NhIQEXL582c6IOTdXnu5Y3W1RLfBxUk+oFHJsPJSFmesOwWjkDqZERERE1PjsTtISExORkZGByZMn4/bbb0e3bt3QvXt38ac9Fi1ahHHjxmH8+PGIjo5GSkoKwsPDsXTpUpv1ly1bhoiICKSkpCA6Ohrjx4/H2LFjsXDhQrFOSkoKhgwZguTkZHTq1AnJycm44447kJKSYle7jzzyCO688060adMGXbp0waJFi1BYWGh3IursXHXjEFviOwRi8cPdoZDL8PXe83hx7UFUMlEjIiIiokZm9xb8GRkZDdKwTqfD3r17MXPmTIvyhIQE7Nq1y+Yx6enpSEhIsCgbOnQoVqxYAb1eD6VSifT0dEybNs2qjjlJq0+7Op0Oy5cvh4+PD7p27Vrje6qoqLBYr1dYWAgA0Ov10Ov1NR7XGMztX9+PkqodDdVy69dc0R0d/bHwgRg8v/Ywvt57HhV6A/45KgZuitr/PaOm+FLDYHylxfhKjzGWFuMrLcZXWoyvtJwpvvb0we4kLTIy0t5DbMrNzUVlZSWCg4MtyoODg5GdnW3zmOzsbJv1DQYDcnNzERoaWmMd8zntaff777/HQw89hNLSUoSGhiItLQ0BAQE1vqf58+dj7ty5VuWpqanQarU1HteY0tLSLJ5fzFEAkOHooQNQXvzTIX1yNnIAj7WT4fOTcnx3MBvnL1xEUjsjbpCnAbCOLzUsxldajK/0GGNpMb7SYnylxfhKyxniW1paWue6didpZkePHkVmZiZ0Op1F+YgRI+w6j0wms3guCIJV2Y3qX19el3PWpc6gQYPw559/Ijc3F5988om4ti0oKMhm35KTkzF9+nTxeWFhIcLDw5GQkABvb+8a31Nj0Ov1SEtLw5AhQyxuQP7xmXSgqAi39+mFAe1rTkBdzXAAtx3LweQ1B7A/T46AoBC8N+ZWqN1sZ2o1xZcaBuMrLcZXeoyxtBhfaTG+0mJ8peVM8TXPsqsLu5O006dP4/7778ehQ4cgk8mskqTKyso6nScgIAAKhcJq9ConJ8dqlMssJCTEZn03Nzf4+/vXWsd8Tnva9fDwQLt27dCuXTv06dMH7du3x4oVK5CcnGyzf2q1Gmq12qpcqVQ6/KIwu74v5XrTLoZe7mqn6aOzGHZrSyxXKfH0f/Yi7VgOxv97H5Y/1hPemprj5EyfdXPE+EqL8ZUeYywtxldajK+0GF9pOUN87Wnf7o1DpkyZgqioKFy6dAlarRZHjhzB9u3b0bNnT2zdurXO51GpVIiNjbUaekxLS0NcXJzNY/r27WtVPzU1FT179hTfdE11zOesT7tmgiA0u3vEmXd3dNX7pN3IoE5BWPnEtfuoJX78G3IKyx3dLSIiIiJqxuxO0tLT0zFv3jwEBgZCLpdDLpejX79+mD9/PiZPnmzXuaZPn45//etf+PTTT3Hs2DFMmzYNmZmZmDhxIgDT9MHHHntMrD9x4kScPXsW06dPx7Fjx/Dpp59ixYoVeP7558U6U6ZMQWpqKhYsWIDjx49jwYIF+PnnnzF16tQ6t1tSUoJZs2bht99+w9mzZ7Fv3z6MHz8e58+fx4MPPmhvyJyamKSp7L4UXEZcuwCsfqoPAjzVOJZViFFLd+H05WJHd4uIiIiImim7pztWVlbC09MTgGnq4MWLF9GxY0dERkbixIkTdp0rMTEReXl5mDdvHrKyshATE4NNmzaJm5NkZWVZ3LssKioKmzZtwrRp0/DRRx8hLCwMixcvxgMPPCDWiYuLw+rVq/HKK69g9uzZaNu2LdasWYPevXvXuV2FQoHjx4/j888/R25uLvz9/dGrVy/s2LEDXbp0sTdkTq1Ux/uk1UVMSx+s+0ccHvt0N87klWL0snR88lgsYiNbOLprRERERNTM2J2kxcTE4ODBg2jTpg169+6Nf/7zn1CpVFi+fDnatGljdwcmTZqESZMm2Xxt5cqVVmXx8fHYt29freccPXo0Ro8eXe92NRoN1q1bV+vxzUGlUYDOYFqTplXVew8ZlxHhr8XX/4jDk5/9gUMXruLh5bvx9gO3YFSPVo7uGhERERE1I3bPcXvllVdgNJq+2L/xxhs4e/Ys+vfvj02bNmHx4sUN3kGSTrn+2iYvXJNWNwGeaqx5ug+GdgmGrtKI6f89gAU/HoeRN70mIiIiogZi9/DJ0KFDxd/btGmDo0ePIj8/H35+frVunU/OxzzVEUCNW8uTNa3KDUsfjcW7aSfw0Za/sXTr3zh1qQhDvBzdMyIiIiJqDur9zfzUqVP46aefUFZWhhYtuC6nKSqvtrOjXM4E2x5yuQwvDO2E9xK7QqWQI+1YDt47rMCZvBJHd42IiIiImji7k7S8vDzccccd6NChA4YPH46srCwAwPjx4zFjxowG7yBJ59rOjpzqWF/3d2+FVU/1QYCnClmlMty/dDd+PJzl6G4RERERURNmd5I2bdo0KJVKZGZmQqvViuWJiYn48ccfG7RzJK0yHe+R1hBiI/2wYVJftPUSUFxhwMT/7MObG49CX2l0dNeIiIiIqAmyO0kz34OsVSvLHe3at2+Ps2fPNljHSHrmNWkcSbt5QV5qPNO5EuNuN93G4ZMdGXj0k93IvsobXxMRERGRfexO0kpKSixG0Mxyc3OhVqsbpFPUOKqvSaObp5ADM+/qiGX/1wOeajf8fiYfd72/HT8eznZ014iIiIioCbE7SRswYAC++OIL8blMJoPRaMQ777yDQYMGNWjnSFplTNIkcVdMKL57rh9uaemDglI9Jv5nL5LXHUSpzuDorhERERFRE2D3FvzvvPMOBg4ciD179kCn0+HFF1/EkSNHkJ+fj19//VWKPpJEzNMdNZzu2OCiAjyw9h9xeDftBJZvP41Vv5/D7ox8LH6oO2Ja+ji6e0RERETkxOweSevcuTMOHjyI2267DUOGDEFJSQlGjRqF/fv3o23btlL0kSRiHknTciRNEio3OZKHRePLcb0R4q3B6csluH/Jr3j/55PcVISIiIiIamT3SBoAhISEYO7cuRZl586dw9ixY/Hpp582SMdIeuXcOKRRxLULwA9T+iN53SH8eCQb7/38F348ko2FD96KLmEcVSMiIiIiS/W+mfX18vPz8fnnnzfU6agRiNMdOZImOT8PFZb+Xw+8/1A3+GqVOJZViJEf/opFqSegM3BUjYiIiIiuabAkjZoecbojR9IahUwmw8huLZE2LR7DYkJgMApYvPkU7v1gJ/ZnXnF094iIiIjISTBJc2Hcgt8xAr3UWPp/sfjokR7w91DhxKUijFq6C8nrDqGgVOfo7hERERGRgzFJc2FlXJPmUHffGoq06fF4oEcrCAKw6vdMDH53G/635xwEQXB094iIiIjIQeq8ccioUaNqfb2goOBm+0KNrJQjaQ7XwkOFd8d0xZierfDKN4dxMqcYL3x9EP/bcx6v3xeDjiFeju4iERERETWyOidpPj6170Ln4+ODxx577KY7RI2HI2nOo3cbf2ya0h8rdmbg/Z9P4vcz+Rj2/nY8fFsEpg/pAH9PtaO7SERERESNpM5J2meffSZlP8gBuCbNuSgVckyMb4t7u4bh9e+O4scj2fhydya+/fMinh3cDk/c3hpqN35WRERERM0d16S5sFKdAQC34Hc2LX3dsSwpFqsm9EGXMG8UVRgw/4fjGLJoO344lMX1akRERETNHJM0F1amN92fi1vwO6e+bf3x3bP98M7oWxHkpUZmfin+8eU+jF6Wjt9O5zm6e0REREQkESZpLkyc7sgkzWnJ5TI82DMcW54fiMl3tIdGKcfes1fw0PLfkLRiNw6eL3B0F4mIiIiogTFJc2Hm6Y5ck+b8PNRumD6kA7a/MAiP9Y2EUiHDjpO5GPHhr5j47704eanI0V0kIiIiogbCJM2FcXfHpifIW4N5I2OwecZAPNCjFeQy4Mcj2UhI2Y4pq/fjLyZrRERERE0ekzQXVl61Jo0jaU1PeAst3h3TFT9NHYBhMSEQBGDDnxeR8N52TPz3Xhy+cNXRXSQiIiKiemKS5qIMlUboKpmkNXXtg72w9P9i8f1z/TAsJgSAaWTtng924onPfsfes/kO7iERERER2avO90mj5qWsatMQgNMdm4OYlj5Y+n+x+OtSEZZsOYVvD1zE1hOXsfXEZfRp0wJPDWiDgR2CIJfLHN1VIiIiIroBjqS5KHOSJpMBajdeBs1Fh2AvpDzUHZtnDMRDvcKhVMjw2+l8jF25B0Pe24avdmeKu3oSERERkXPit3MXVa67NtVRJuPoSnPTOsADbz9wK7a9MAhPDWgDL7Ub/r5cglnrDyHu7c1YlPYXcosrHN1NIiIiIrKBSZqLKtVz+31XEObrjlnDo7EreTBeuTsaLX3dkV+iw+JfTiLu7c144X8HcOg8NxkhIiIiciZck+aiuP2+a/HSKDG+fxs8EdcaPx7Jxic7MnDgXAH+t/c8/rf3PLq28sH/9YnEvV3DoGHiTkRERORQTNJclHlNGkfSXIubQo57bg3D3beEYl/mFfw7/Sw2HcrGgfNXceDrg3hj4zGM6dkKj/aOROsAD0d3l4iIiMglMUlzURxJc20ymQyxkS0QG9kCr9xTgf/uOYcvf8vEhYIyfLIjA5/syED/9gEY0zMcQzoHc3SNiIiIqBExSXNRHEkjswBPNSYNbIenB7TF1hM5+PdvZ7Htr8vYcTIXO07mwsddifu6heHBnuGIaenj6O4SERERNXtM0lwUR9Loegq5DHdEB+OO6GBk5pXif3vP4eu955F1tRyfp5/F5+lnER3qjTE9W+G+bi3h56FydJeJiIiImiUmaS6qnCNpVIsIfy1mJHTE1Ds7YOepXPxvzzmkHrmEY1mFmPvdUby16RgGdwrCfd1aYlCnIE6HJCIiImpATNJcVClH0qgOFHIZ4jsEIr5DIApKddjw50X8b+85HL5QiJ+OXMJPRy7BS+2GoTEhGNktDHFtA6CQ8757RERERDeDSZqL4po0spevVoXH41rj8bjWOJZViA1/XsS3f17Axavl+HrveXy99zwCPNW4t2soRnZria6tfHijdCIiIqJ6YJLmopik0c2IDvVGdKg3XhzaEXvOXsGGPy9g46Es5BZX4LNfz+CzX88gooUWd8WEYFhMCLq28oWcI2xEREREdcIkzUVx4xBqCHK5DLdFtcBtUS0w594u2HnqMjb8eRGpRy4hM78Uy7efxvLtpxHqo8HQLqaErWfrFpwSSURERFQLuaM7sGTJEkRFRUGj0SA2NhY7duyotf62bdsQGxsLjUaDNm3aYNmyZVZ11q5di86dO0OtVqNz585Yv369Xe3q9Xq89NJLuOWWW+Dh4YGwsDA89thjuHjx4s2/YSfBJI0amspNjsGdgvH+Q92xd/adWPJoD9zbNQweKgWyrpZj5a4zSFz+G3q/9TNmrT+EHScvQ19pdHS3iYiIiJyOQ5O0NWvWYOrUqXj55Zexf/9+9O/fH8OGDUNmZqbN+hkZGRg+fDj69++P/fv3Y9asWZg8eTLWrl0r1klPT0diYiKSkpJw4MABJCUlYcyYMdi9e3ed2y0tLcW+ffswe/Zs7Nu3D+vWrcNff/2FESNGSBuQRsTpjiQlrcoNw28JxQcPd8fe2UPwr8d6YlSPlvDWuCG3WIevdmciacXv6DEvDc98tQ/r95/HlRKdo7tNRERE5BQcOt1x0aJFGDduHMaPHw8ASElJwU8//YSlS5di/vz5VvWXLVuGiIgIpKSkAACio6OxZ88eLFy4EA888IB4jiFDhiA5ORkAkJycjG3btiElJQWrVq2qU7s+Pj5IS0uzaPuDDz7AbbfdhszMTEREREgSj8YkjqQxSSOJaZQK3Nk5GHd2DobOYET66Tz8eDgLqUcuIa9Eh40Hs7DxYBbkMiA20g93RAfjzuggtA305MYjRERE5JIclqTpdDrs3bsXM2fOtChPSEjArl27bB6Tnp6OhIQEi7KhQ4dixYoV0Ov1UCqVSE9Px7Rp06zqmBO7+rQLAFevXoVMJoOvr2+NdSoqKlBRUSE+LywsBGCaPqnX62s8rjGY2zf/LNUZAAAqBRzet+bg+viSbTIAcVG+iIvyxZy7O+HghavYcvwytpy4jOOXivHHmSv448wVvP3DcYT7uWNwp0AM7BCIbi09ADC+UuH1Kz3GWFqMr7QYX2kxvtJypvja0weHJWm5ubmorKxEcHCwRXlwcDCys7NtHpOdnW2zvsFgQG5uLkJDQ2usYz5nfdotLy/HzJkz8cgjj8Db27vG9zR//nzMnTvXqjw1NRVarbbG4xqTeYQwK0cBQIajB/+E4vx+x3aqGbl+BJZurBOATm2A/JbAkSsyHLkiw19XZTh3pQyfp2fi8/RMKGUC2nrLseXiz+jkKyDEHeAgW8Pj9Ss9xlhajK+0GF9pMb7Scob4lpaW1rmuw3d3vH46kyAItU5xslX/+vK6nLOu7er1ejz00EMwGo1YsmRJLe/ENLVy+vTp4vPCwkKEh4cjISGh1uSuMej1eqSlpWHIkCFQKpVYenoXUFyM2/vchn7t/B3at+bg+vjSzSmpMGDX3/nYfOIydpzKxaXCChy/KsPxqwDOAsHeavRr549+bf1xezt/+GlVju5yk8brV3qMsbQYX2kxvtJifKXlTPE1z7KrC4claQEBAVAoFFajVzk5OVajXGYhISE267u5ucHf37/WOuZz2tOuXq/HmDFjkJGRgc2bN98w0VKr1VCr1VblSqXS4ReFmbkvZQbTrnreWpXT9K05cKbPuinzVSoxvGtLDO/aEoIg4NiFAiz/bgfylEH4/cwVXCqswNp9F7F230XIZMAtLX1we7sA9G3jj56t/aBVOfzfn5okXr/SY4ylxfhKi/GVFuMrLWeIrz3tO2x3R5VKhdjYWKuhx7S0NMTFxdk8pm/fvlb1U1NT0bNnT/FN11THfM66tmtO0E6ePImff/5ZTAKbC/PGIRpuHEJOTiaToX2wJwaFCfj08VgcmJOAf4+7DRP6R6FTiBcEATh4/iqWbv0bj336O7rOTcXopbvwbuoJ7DqVi/KqnUyJiIiImgqH/nPz9OnTkZSUhJ49e6Jv375Yvnw5MjMzMXHiRACm6YMXLlzAF198AQCYOHEiPvzwQ0yfPh0TJkxAeno6VqxYIe7aCABTpkzBgAEDsGDBAowcORIbNmzAzz//jJ07d9a5XYPBgNGjR2Pfvn34/vvvUVlZKY68tWjRAipV059axS34qanSKBXo3z4Q/dsHAgAuFZZjx8lcpP+dh99O5+FCQRn2nL2CPWev4IPNp6BSyNEtwhd92/ijb1t/dI/whdqN1z0RERE5L4cmaYmJicjLy8O8efOQlZWFmJgYbNq0CZGRkQCArKwsi3umRUVFYdOmTZg2bRo++ugjhIWFYfHixeL2+wAQFxeH1atX45VXXsHs2bPRtm1brFmzBr17965zu+fPn8e3334LAOjWrZtFn7ds2YKBAwdKFJHGw5tZU3MR7K3B6NhWGB3bCoIg4Fx+GdJPm5K29NN5uFRYgd8z8vF7Rj7e/+Uk1G5ydG3li56t/dCrdQv0iPCDj5bTS4iIiMh5OHzhxqRJkzBp0iSbr61cudKqLD4+Hvv27av1nKNHj8bo0aPr3W7r1q3FDUmaI32lEQaj6f1plQ6/BIgajEwmQ4S/FhH+EUjsFQFBEHAmr1RM2NL/zkNucQV+P5OP38/kA/gbANAx2As9W/uZHpEt0MrPnfdoIyIiIofhN3QXVFZtjY5G5bBliUSSk8lkiArwQFSABx7pbUraTueWYO+ZK/jjTD72nr2C07klOHGpCCcuFeHL3aaR+xBvDWJb+6FXpB+6R/ghOtQbKjf+t0JERESNg0maCzJPdZTLAJWCXzzJdchkMrQN9ETbQE+M6RUOAMgtrsCeM1ew92w+/jhzBYcvXEV2YTk2HszCxoNZAACVmxxdwrzRLdxXfES00HK0jYiIiCTBJM0FmZM0rcqNXzLJ5QV4qnFXTAjuigkBYPrv48D5Auw5k489Z6/gz3MFKCjVY39mAfZnFojH+WmV6Fotaevayhd+Hk1/UyEiIiJyPCZpLsg83ZHb7xNZc1cp0KeNP/q0Md12QxAEnM0rxZ/nCsTH0YuFuFKqx9YTl7H1xGXx2Nb+WtzSyhe3tPRGTJgPuoT5cFMSIiIishuTNBckbr/P9WhENySTydA6wAOtAzxwX/eWAIAKQyWOZRXhz8wrOHD+Kv48V4CM3BKcySvFmbxSfHfgonh8RAstYlp6o0uYD2Ja+iAmzBv+ntY3vSciIiIyY5LmgsTpjtzZkahe1G4KcZqjWUGpDgfOX8XhC1WPi1dxLr8MmfmlyMwvxaZD2WLdMB8NurT0QUyYD2JaeqNzmDdCvDWcfkxEREQAmKS5JHOSpuE90ogajK9WhfgOgYjvECiWFZTqcPRiIQ5duIrDFwtx5MJVnM4twcWr5bh4tRxpRy+JdX3clegU4oXoUG90CvFCp1BvdAj2hFbFP9NERESuhv/3d0HidEclpzsSSclXq0JcuwDEtQsQy4rK9TiWVSSOth2+cBV/Xy7B1TI9dmfkY3dGvlhXJgNa+3uYkrYQb3QK9UJ0iDda+blDLueoGxERUXPFJM0FmUfS3LlxCFGj89IocVtUC9wW1UIsqzBU4lROMY5nFeF4diGOZxfhWFYRcosrkJFbgozcEvxw+Np0SQ+VAh1DvNAxxAvtgrzQPsgT7YM9OWWSiIiomWCS5oLMI2mcRkXkHNRuCnSp2g2yustFFTiRbUrcjmYV4nhWEU7lFKNEV4l9mQXYV+2WAADgqXZDuyBPMWlrH+SF9sGeCPPhyBsREVFTwm/pLohb8BM1DYFeagR6qdGv/bXpkvpKIzJyS3AsqxCncopx8lIxTuYU4UxeKYorDOJtAqrTqhRoF+RZlcCZRt7aBHogvIUWSt7QnoiIyOkwSXNBpTpuwU/UVCkVcnQI9kKHYC+Lcp3BiDN5JWLSdjKnGKcuFeN0bjFKdZU4eP4qDp6/anGMm1yGiBZatPbXQiiUo2jPebQL9kabQA8Eeqo5dZKIiMhBmKS5oHJOdyRqdlRu1ZO3ULFcX2lEZn4pTl4qqkrgTI+M3GKU6404nVuC07klAOTYsuGoeJyX2g1RgR6ICvBAmwBPRAV6oE2A6bmHmn87iIiIpMT/07ogcQt+TnckavaUCjnaBnqibaAn7oq5Vm40CsguLEdGbglOZl/Flj1HIXgF4kxeGc5fKUVRhcHm6BsAhHhrEOmvrXp4VI3GeSDCXwsfd2UjvjsiIqLmiUmaC7q2BT+TNCJXJZfLEObrjjBfd9wW6QO/vMMYPjwWSqUSFYZKZOaV4u/Lpp0lT18uNv3MLUF+iQ7ZheXILiy3uF2Ama9WicgWWkT4e6C1vxYRLUyJXKS/FkFenEJJRERUF0zSXJB5JE3Lm1kTkQ1qNwXaB3uh/XXr3gDTDbpP55YgM68UZ/NKcTbf9PuZvFLkFlegoFSPgtKrOGBjBE6jlCOyhWnELbKFaSSulZ8Wrfzc0dLPnVOwiYiIqvD/iC6II2lEVF++WhV6RKjQI8LP6rWSCgMy803JW2Z+SdXPUpzJK8HFgnKU6404cakIJy4V2Ty3v4cKrfzcxcSt+u9M4oiIyJXw/3guSFyTxpE0ImpAHmo3RId6IzrU2+o1faURF66U4Wx+KTLzTAncuSulOH+lDOevlOFqmR55JTrklehsjsIBtSdxYb7u3NCEiIiaDf4fzQWVciSNiBqZUiFH6wAPtA7wABBo9frVMj0uXDFtWmJO3K79XorCcsMNkzhvjZu4zi7URyP+DPVxR5ivBiE+Gqjd+HePiIicH5M0F1TONWlE5GR83JXwcVeic5j1KBxQexJ37kopisoNKCw3oDC7CMezbU+nBIAATzXCfDUWyZvpp+n3IC8NFHJubkJERI7FJM0FmdekcQt+ImoqbpTEFZXrkXW1HBcLypB1tRxZBWW4WO35xYIyVBiMyC2uQG5xhc1bCwCAQi5DsJcaIT6mkbdgb9MjxFuDIG81Qqqec2olERFJif+XcUGlOk53JKLmxUujhJdGWXUzb2uCIOBKqR4XC8quJW5Xy5BVcC2Ryy4sR6VRMCV3V8trb0/thmAfDYK91RaJXPXngV5qKBVyKd4uERE1c0zSXFC5ntMdici1yGQytPBQoYWHCjEtfWzWqTQKuFxUgQsFZbhUWI7sq+W4VFSOS1fLcamwwlRWWI5SXSWKKgwoyinGqZziWtoE/D3UCPFRI9BThYoCOf7e8jdCfLQI9FKLjwBPFdfKERGRBSZpLkYQhGtb8DNJIyISKeQycZpjbYrK9WLSZk7ccgorLJK6nKIKGIyCOL3SRI5dl/62eU4fd6UpafNUI8jb9LN6Imd+zU+rgpxr5oiImj0maS5GXymg0igA4Jo0IqL6ME+tbBfkWWMdo1FAXolOTOQuXinFzn2H4RsSjrwSPS4XVZgexRXQVwq4WqbH1TJ9rSNzgCmRDPBUiUlb9QQu0EuDAE8V/D1No3PeGiUTOiKiJopJmosxj6IBnO5IRCQVuVwmJlAxLX2g1+vhffkghg/vAqVSKdYTBFOCZk7acqolb2IiV/U8v0SHSqNQNYpXUUvrJm5yGfw8VPD3UCHAUw1/TxX8PUw/AzxVaGH+veqnVqWATMakjojIGTBJczHmJM1NLuOCdiIiB5PJZPDVquCrVaF9DZuemOkrjcgr1iGnqNwqgTMnePklOuQWV6Co3ABD1Rq7y0UVAGq+LYGZRikXkzh/D9OIXPUkzt9TXVWugp9WxdkYREQSYpLmYsp5I2sioiZJqZDXac0cAFQYKpFfokNesekG4HnFFcgr1iG3pAL51cpyi3XIK6lAud6Icr0RFwrKcKGgrE790aoU8NOq4OehhJ/WtCmLn1ZV9bsSfh4qtKhKQFt4qOCrVTKxIyKqIyZpLkbcfp9THYmImi21mwKhPu4I9XGvU/1SncGUxFUlc3klFVWJXFWCV6JDbrEO+SWm1w1GAaW6SpTq6p7UAYCHSgE/czLnoUILrfK655ZJn69WyZ0vicglMUlzMeV6IwAmaUREdI1W5QZtCzeEt9DesK4gCCiqMOBKiQ5XSvW4UqJDfokOV0pNj/ySqrJS3bU6pab1dCW6SpToynD+in2Jna9WBR93JXy1poePuymB8626ybmnSo6TV2U4nl2EAG93+LqroFHKucaOiJosJmkupozTHYmI6CbIZDJ4a5Tw1igR6V+3YwRBQGG5ObGzTuYKSqsSvRK9mNwVlOktErsbj9gp8OHRdPGZSiGHT1UiVz2x83GvVqZVVXtdCV93Fbw0btwVk4gcjkmaiymrmu7IdQFERNRYZDIZfKpGvVrDo07HGI0CisoNyC/V4WqZHgXiz6pHmen51aqRuguXr8AgV+NqmR4GowBdpbHaxin29BViIufjroS3uykh9XZ3q/qphLfGrVq5Ej7VXlO7cQSPiG4ekzQXYx5J4/b7RETkzORyGXy0SvholTesq9frsWnTJgwfPhBubm4o1VWiwJzYlepRUHUfOjG5s0j0DLhaahq5K9VVQhAgJoL1oVLIxYTOqyqhq1uyZ6rHNXhEBDBJcznc3ZGIiJozmUwGD7UbPNRuaOlbt41TzCoMleLoXEGZHoVlehSW61FYZhB/v1pW9by82mvlprpGAdBVGpFbbNpopT7UbnKLBM5083Q3eKnd4KVxg6fa9NxT4wbv656b6im5Ho+oGWCS5mLKqjYO0XAkjYiIyILaTYEgLwWCvG58m4PrCYJp/dxVc3JXpkdhucEi0bsq/m6d4BVVGCAIQIWhftM0q3OTy8SkzZzEiUmexg1eGiU81VVJXlViZ67vXfWap8aN91MlciAmaS7GvCZNy5E0IiKiBiOTyUzJTT1G8ICqNXgV1kldcYUBReV6FJcbUFRhQFF51fOq34urnhdVGFBclegZjEK1KZt130nzehql3JTQqRSoLFdgzaU98HJXwqPqfYo/VQqLsmu/K8QyJnxE9mGS5mLE3R05kkZEROQ05PJrm6vUl9EooFRfKSZ1heUGyyRPTPSuPS+usC4zf1cw3eS8ApcBADJkns6vd99UbnIxcfNQWSZ5135XXJfkWSZ65p9apYI7cFKzxyTNxXBNGhERUfMkl18bzYNP/c9jqDSKI3VF5QYUlJRjy6+/oWNMN5QbBJRUGFBSYUBxRWXVT9PD/HuJzoCSikoUVxigM5iWWegMRuQbdMgvaZj3aj16Z0rmtCrT71qVG7QqhfjcXWmqby7TVh3voVLAvapMwcSPnAiTNBdTquNIGhEREdXMTSGHr1YFX60KAKDXu+PyUQHDu4ZCqbRvpE9fabyWvFUlbiXVE7oKA0p018qLy68leuYksHpdo2A6r+n+eZXIuYm1e9fTKOXXEjiVG7RqxbVET6WAe9VPrdpcp1oSaH7NnBxWjRi6c9SP6snhSdqSJUvwzjvvICsrC126dEFKSgr69+9fY/1t27Zh+vTpOHLkCMLCwvDiiy9i4sSJFnXWrl2L2bNn4++//0bbtm3x5ptv4v7777er3XXr1uHjjz/G3r17kZeXh/3796Nbt24N+t4dgSNpRERE1FiU1yV8N0MQBJTrjZajdjYSurKqBK5UZ0Bp1c+SiurPK6vVu5b4maZ3Ntxon5lpFK/66J7pd/eq39UKGS5dkONY2kl4apTQKM2vy+GuNCWA7kpTXU3VT1O5gvfla8YcmqStWbMGU6dOxZIlS3D77bfj448/xrBhw3D06FFERERY1c/IyMDw4cMxYcIE/Oc//8Gvv/6KSZMmITAwEA888AAAID09HYmJiXj99ddx//33Y/369RgzZgx27tyJ3r1717ndkpIS3H777XjwwQcxYcKExguKxMy7O3IkjYiIiJoSmUwG96rpiYFe6gY5pyAIqDAYxcSttCpxK6v23CLR0xtQWmGqU1pRiVJ9JUqrRgPLdKafpRUGlOpN99wDTPsBmNb51XZbBjm2ZWfY3X+5DGLC5i4mb25wV8qrEju3a4ldteTOVsJnrn/9+TgN1DEcmqQtWrQI48aNw/jx4wEAKSkp+Omnn7B06VLMnz/fqv6yZcsQERGBlJQUAEB0dDT27NmDhQsXiklaSkoKhgwZguTkZABAcnIytm3bhpSUFKxatarO7SYlJQEAzpw5I9n7dwTz7o4ajqQRERGRi5PJZNAoTQlLC4+bH+0zM4/6XUvmrh/NM/0s01WiuFyPw8f/Qlh4a+gqBZTpTYlhedXPMp0pySurOq5cb4Su0vSP7kbh2tRPqajc5OJIXvWEzhQ3uRg/96rn7koF1ErLOtd+r3quUkDjdu04tVLOUcHrOCxJ0+l02Lt3L2bOnGlRnpCQgF27dtk8Jj09HQkJCRZlQ4cOxYoVK6DX66FUKpGeno5p06ZZ1TEndvVpt64qKipQUXFtbnRhYSEAQK/XQ6/X39S5b5a5/VKdAQCglsPhfWpOzLFkTKXB+EqL8ZUeYywtxldajG/9uMkAH7UcPmo5gJrX8un1eqSVHseQIW3rvObPUGlEmd4ojtKZE7lyMcEzWiR65eZ6Yl3jteSvqqxcbxoZLK86r3kkUGcwQmcw4mqZtJ+/TAZo3K4lfdd+l4uJnDkB1LhZlokJo1v1xNH00w0C8sqd4/q1pw8OS9Jyc3NRWVmJ4OBgi/Lg4GBkZ2fbPCY7O9tmfYPBgNzcXISGhtZYx3zO+rRbV/Pnz8fcuXOtylNTU6HVam/q3A3lUu4VADIcPrgfOCc4ujvNTlpamqO70KwxvtJifKXHGEuL8ZUW4yuthoyvDIBH1cO/+gsKAO5Vj1oIAqA3Ajrzo9L0vMII6Cpl0BuvvX7tpwz6Ssvy6q9ZlwH6SsAImdimKfE0AmjYhCpAo4C/xvHXb2lpaZ3rOnzjkOuHNQVBqHWo01b968vrck57262L5ORkTJ8+XXxeWFiI8PBwJCQkwNvb+6bOfbP0ej3S0tKg0noCJSXo3/c29G3jf+MDqU7M8R0yZIjdO1/RjTG+0mJ8pccYS4vxlRbjKy1Xj6++0ojyqhG8ckMlynWmn2X6SlRUjeqV642oMJhGAMurRgzLzb8bjBbPy/SVqDCYRgrNr3nJKpwivuZZdnXhsCQtICAACoXCavQqJyfHapTLLCQkxGZ9Nzc3+Pv711rHfM76tFtXarUaarX1QlalUunwi8LMvLujl7vaafrUnDjTZ90cMb7SYnylxxhLi/GVFuMrLVeNr1IJaDXSnV+v12PTpk1OEV972pdL2I9aqVQqxMbGWg3tpqWlIS4uzuYxffv2taqfmpqKnj17im+6pjrmc9an3eaEuzsSERERETk3h053nD59OpKSktCzZ0/07dsXy5cvR2Zmpnjfs+TkZFy4cAFffPEFAGDixIn48MMPMX36dEyYMAHp6elYsWKFuGsjAEyZMgUDBgzAggULMHLkSGzYsAE///wzdu7cWed2ASA/Px+ZmZm4ePEiAODEiRMATCN1ISEhksdGKrxPGhERERGRc3NokpaYmIi8vDzMmzcPWVlZiImJwaZNmxAZGQkAyMrKQmZmplg/KioKmzZtwrRp0/DRRx8hLCwMixcvFrffB4C4uDisXr0ar7zyCmbPno22bdtizZo14j3S6tIuAHz77bd48sknxecPPfQQAGDOnDl47bXXpAqJpAQBKDUnaRxJIyIiIiJySg7fOGTSpEmYNGmSzddWrlxpVRYfH499+/bVes7Ro0dj9OjR9W4XAJ544gk88cQTtZ6jqTEIELdT5UgaEREREZFzctiaNGp81e9zyJtZExERERE5JyZpLkRn2jMESoUMSgU/eiIiIiIiZ8Rv6i7EnKRxqiMRERERkfNikuZC9OYkjZuGEBERERE5LSZpLsS8Jo0jaUREREREzotJmgvRGWUAAHeVwzf1JCIiIiKiGjBJcyHX1qTxYyciIiIiclb8tu5CxOmOXJNGREREROS0mKS5kGsjaZzuSERERETkrJikuRAdd3ckIiIiInJ6TNJciJ5r0oiIiIiInB6/rbsQXWXV7o7cgp+IiIiIyGkxSXMh16Y7ck0aEREREZGzYpLmQq5tHMKRNCIiIiIiZ8UkzYXoxS34+bETERERETkrflt3IRWc7khERERE5PSYpLkQPac7EhERERE5PSZpLoS7OxIREREROT8maS7EvHGIljezJiIiIiJyWkzSXIg5SdNwJI2IiIiIyGkxSXMh4po0jqQRERERETktJmkupMK8BT9H0oiIiIiInBaTNBei55o0IiIiIiKnxyTNRQiCAJ3RtLsj16QRERERETkvJmkuosJgFH/nmjQiIiIiIufFJM1FlOoqxd+5Jo2IiIiIyHkxSXMR5XpTkqZyk0Mhlzm4N0REREREVBMmaS6irGrXEHclP3IiIiIiImfGb+wuoqxquiOnOhIREREROTcmaS6iTM8kjYiIiIioKWCS5iLMa9K4/T4RERERkXNjkuYizLs7cvt9IiIiIiLnxiTNRZRzuiMRERERUZPAJM1FcHdHIiIiIqKmgd/YXUQZ16QRERERETUJTNJchHkLfi3XpBEREREROTUmaS6CuzsSERERETUNTNJcBO+TRkRERETUNDBJcxFiksbpjkRERERETo1Jmoso03F3RyIiIiKipsDh39iXLFmCqKgoaDQaxMbGYseOHbXW37ZtG2JjY6HRaNCmTRssW7bMqs7atWvRuXNnqNVqdO7cGevXr7e7XUEQ8NprryEsLAzu7u4YOHAgjhw5cnNv1oG4uyMRERERUdPg0CRtzZo1mDp1Kl5++WXs378f/fv3x7Bhw5CZmWmzfkZGBoYPH47+/ftj//79mDVrFiZPnoy1a9eKddLT05GYmIikpCQcOHAASUlJGDNmDHbv3m1Xu//85z+xaNEifPjhh/jjjz8QEhKCIUOGoKioSLqASIhr0oiIiIiImgY3Rza+aNEijBs3DuPHjwcApKSk4KeffsLSpUsxf/58q/rLli1DREQEUlJSAADR0dHYs2cPFi5ciAceeEA8x5AhQ5CcnAwASE5OxrZt25CSkoJVq1bVqV1BEJCSkoKXX34Zo0aNAgB8/vnnCA4OxldffYWnn37a5vupqKhARUWF+LywsBAAoNfrodfrbzZcN6W0wgAAUCkEh/elOTLHlLGVBuMrLcZXeoyxtBhfaTG+0mJ8peVM8bWnDw5L0nQ6Hfbu3YuZM2dalCckJGDXrl02j0lPT0dCQoJF2dChQ7FixQro9XoolUqkp6dj2rRpVnXMiV1d2s3IyEB2drZFW2q1GvHx8di1a1eNSdr8+fMxd+5cq/LU1FRotVqbxzSWnHwFABmOHToI2fkDDu1Lc5aWluboLjRrjK+0GF/pMcbSYnylxfhKi/GVljPEt7S0tM51HZak5ebmorKyEsHBwRblwcHByM7OtnlMdna2zfoGgwG5ubkIDQ2tsY75nHVp1/zTVp2zZ8/W+J6Sk5Mxffp08XlhYSHCw8ORkJAAb2/vGo9rDGFd8rH51934v7sHIMjHw6F9aY70ej3S0tIwZMgQKJVKR3en2WF8pcX4So8xlhbjKy3GV1qMr7ScKb7mWXZ14dDpjgAgk8ksnguCYFV2o/rXl9flnA1Vpzq1Wg21Wm1VrlQqHX5RdItsgYtHBAT5eDi8L82ZM3zWzRnjKy3GV3qMsbQYX2kxvtJifKXlDPG1p32HbRwSEBAAhUJhNWqWk5NjNYJlFhISYrO+m5sb/P39a61jPmdd2g0JCQEAu/pGRERERETUEByWpKlUKsTGxlrND01LS0NcXJzNY/r27WtVPzU1FT179hQz05rqmM9Zl3ajoqIQEhJiUUen02Hbtm019o2IiIiIiKghOHS64/Tp05GUlISePXuib9++WL58OTIzMzFx4kQApjVeFy5cwBdffAEAmDhxIj788ENMnz4dEyZMQHp6OlasWCHu2ggAU6ZMwYABA7BgwQKMHDkSGzZswM8//4ydO3fWuV2ZTIapU6firbfeQvv27dG+fXu89dZb0Gq1eOSRRxoxQkRERERE5GocmqQlJiYiLy8P8+bNQ1ZWFmJiYrBp0yZERkYCALKysizuXRYVFYVNmzZh2rRp+OijjxAWFobFixeL2+8DQFxcHFavXo1XXnkFs2fPRtu2bbFmzRr07t27zu0CwIsvvoiysjJMmjQJV65cQe/evZGamgovL69GiAwREREREbkqh28cMmnSJEyaNMnmaytXrrQqi4+Px759+2o95+jRozF69Oh6twuYRtNee+01vPbaa7Weh4iIiIiIqCE5bE0aERERERERWWOSRkRERERE5ESYpBERERERETkRJmlEREREREROhEkaERERERGRE2GSRkRERERE5ESYpBERERERETkRJmlEREREREROhEkaERERERGRE3FzdAeaM0EQAACFhYUO7gmg1+tRWlqKwsJCKJVKR3en2WF8pcX4SovxlR5jLC3GV1qMr7QYX2k5U3zNOYE5R6gNkzQJFRUVAQDCw8Md3BMiIiIiInIGRUVF8PHxqbWOTKhLKkf1YjQacfHiRXh5eUEmkzm0L4WFhQgPD8e5c+fg7e3t0L40R4yvtBhfaTG+0mOMpcX4SovxlRbjKy1niq8gCCgqKkJYWBjk8tpXnXEkTUJyuRytWrVydDcseHt7O/wCbc4YX2kxvtJifKXHGEuL8ZUW4ystxldazhLfG42gmXHjECIiIiIiIifCJI2IiIiIiMiJMElzEWq1GnPmzIFarXZ0V5olxldajK+0GF/pMcbSYnylxfhKi/GVVlONLzcOISIiIiIiciIcSSMiIiIiInIiTNKIiIiIiIicCJM0IiIiIiIiJ8IkjYiIiIiIyIkwSXMRS5YsQVRUFDQaDWJjY7Fjxw5Hd8mh5s+fj169esHLywtBQUG47777cOLECYs6TzzxBGQymcWjT58+FnUqKirw3HPPISAgAB4eHhgxYgTOnz9vUefKlStISkqCj48PfHx8kJSUhIKCAos6mZmZuPfee+Hh4YGAgABMnjwZOp1OkvfeGF577TWr2IWEhIivC4KA1157DWFhYXB3d8fAgQNx5MgRi3MwtjVr3bq1VXxlMhmeeeYZALx27bV9+3bce++9CAsLg0wmwzfffGPxurNdr4cOHUJ8fDzc3d3RsmVLzJs3D86+B1htMdbr9XjppZdwyy23wMPDA2FhYXjsscdw8eJFi3MMHDjQ6rp+6KGHLOq4aoxvdA0729+E5hZfW3+PZTIZ3nnnHbEOr1/b6vJ9zGX/BgvU7K1evVpQKpXCJ598Ihw9elSYMmWK4OHhIZw9e9bRXXOYoUOHCp999plw+PBh4c8//xTuvvtuISIiQiguLhbrPP7448Jdd90lZGVliY+8vDyL80ycOFFo2bKlkJaWJuzbt08YNGiQ0LVrV8FgMIh17rrrLiEmJkbYtWuXsGvXLiEmJka45557xNcNBoMQExMjDBo0SNi3b5+QlpYmhIWFCc8++6z0gZDInDlzhC5duljELicnR3z97bffFry8vIS1a9cKhw4dEhITE4XQ0FChsLBQrMPY1iwnJ8citmlpaQIAYcuWLYIg8Nq116ZNm4SXX35ZWLt2rQBAWL9+vcXrznS9Xr16VQgODhYeeugh4dChQ8LatWsFLy8vYeHChdIFqAHUFuOCggLhzjvvFNasWSMcP35cSE9PF3r37i3ExsZanCM+Pl6YMGGCxXVdUFBgUcdVY3yja9iZ/iY0x/hWj2tWVpbw6aefCjKZTPj777/FOrx+bavL9zFX/RvMJM0F3HbbbcLEiRMtyjp16iTMnDnTQT1yPjk5OQIAYdu2bWLZ448/LowcObLGYwoKCgSlUimsXr1aLLtw4YIgl8uFH3/8URAEQTh69KgAQPjtt9/EOunp6QIA4fjx44IgmP74y+Vy4cKFC2KdVatWCWq1Wrh69WpDvcVGNWfOHKFr1642XzMajUJISIjw9ttvi2Xl5eWCj4+PsGzZMkEQGFt7TZkyRWjbtq1gNBoFQeC1ezOu/wLmbNfrkiVLBB8fH6G8vFysM3/+fCEsLEz8/J2drS+51/v9998FABb/mBgfHy9MmTKlxmMYY5OakjRn+ZvQHON7vZEjRwqDBw+2KOP1WzfXfx9z5b/BnO7YzOl0OuzduxcJCQkW5QkJCdi1a5eDeuV8rl69CgBo0aKFRfnWrVsRFBSEDh06YMKECcjJyRFf27t3L/R6vUVsw8LCEBMTI8Y2PT0dPj4+6N27t1inT58+8PHxsagTExODsLAwsc7QoUNRUVGBvXv3NvybbSQnT55EWFgYoqKi8NBDD+H06dMAgIyMDGRnZ1vETa1WIz4+XowJY1t3Op0O//nPfzB27FjIZDKxnNduw3C26zU9PR3x8fEWN2UdOnQoLl68iDNnzjR8ABzk6tWrkMlk8PX1tSj/8ssvERAQgC5duuD5559HUVGR+BpjXDtn+ZvQXONrdunSJWzcuBHjxo2zeo3X741d/33Mlf8GM0lr5nJzc1FZWYng4GCL8uDgYGRnZzuoV85FEARMnz4d/fr1Q0xMjFg+bNgwfPnll9i8eTPeffdd/PHHHxg8eDAqKioAANnZ2VCpVPDz87M4X/XYZmdnIygoyKrNoKAgizrXfz5+fn5QqVRN9jPq3bs3vvjiC/z000/45JNPkJ2djbi4OOTl5YnvqbZrkrGtu2+++QYFBQV44oknxDJeuw3H2a5XW3XMz5tLzMvLyzFz5kw88sgj8Pb2FssfffRRrFq1Clu3bsXs2bOxdu1ajBo1SnydMa6ZM/1NaI7xre7zzz+Hl5eXxbUJ8PqtC1vfx1z5b7Bbg56NnFb1f2EHTP8hXF/mqp599lkcPHgQO3futChPTEwUf4+JiUHPnj0RGRmJjRs3Wv3xre762NqKc33qNCXDhg0Tf7/lllvQt29ftG3bFp9//rm4WL0+1yRja23FihUYNmyYxb/88dpteM50vdrqS03HNjV6vR4PPfQQjEYjlixZYvHahAkTxN9jYmLQvn179OzZE/v27UOPHj0AMMY1cba/Cc0tvtV9+umnePTRR6HRaCzKef3eWE3fxwDX/BvMkbRmLiAgAAqFwiq7z8nJsfqXAFf03HPP4dtvv8WWLVvQqlWrWuuGhoYiMjISJ0+exP+3d+8xVdZ/HMDfR+R28IjDxIMhYDCwySWB4cAC8kaBGdMlMiwYYziTyI3UWJa40NUfdFkrosWwdWG4ydoSSzgIxcZRk/tNgjyAW4cuhExDLsHn90fj+XVUDmgqR3i/tmec53m+3+/58jnffXc+e57zfQBAq9ViZGQE/f39JuX+HVutVotff/31prZ+//13kzI3fj79/f0YHR2dNZ+Rg4MD/Pz80NHRoazyaG5MMrbT093dDZ1Oh5SUFLPlOHbvnKWN11uVmbht7UGP+ejoKLZv3w6DwYCysjKTq2i3EhgYCGtra5NxzRhPz0zOCbM5vlVVVWhvb59yTgY4fm802fexuTwHM0mb5WxsbBAUFISysjKT42VlZQgLC5uhXs08EUFaWhqKi4tx5swZrFixYso6fX19uHz5MlxcXAAAQUFBsLa2Nomt0WhEc3OzEtvQ0FAMDAzg/PnzSplz585hYGDApExzczOMRqNSprS0FLa2tggKCror/+9MGx4eRltbG1xcXLBixQpotVqTuI2MjOD7779XYsLYTk9BQQGcnZ0RExNjthzH7p2ztPEaGhqKH374wWRJ6NLSUixbtgweHh53PwD3yUSC1tHRAZ1Oh8WLF09Zp6WlBaOjo8q4ZoynbybnhNkc3/z8fAQFBSEgIGDKshy//5jq+9icnoPv6jIkZJEmluDPz8+X1tZW2bt3rzg4OEhXV9dMd23G7N69WxwdHaWystJkOdzBwUEREbl69apkZGRIdXW1GAwGqaiokNDQUHn44YdvWvLV1dVVdDqd1NbWyrp162655Ku/v7/o9XrR6/Xi5+d3yyVf169fL7W1taLT6cTV1fWBW8b83zIyMqSyslIuXbokZ8+elc2bN4tGo1HG3FtvvSWOjo5SXFwsTU1NEh8ff8vldBnbyY2NjYmbm5scOHDA5DjH7u27evWq1NXVSV1dnQCQd955R+rq6pSVBS1pvF65ckWWLl0q8fHx0tTUJMXFxbJw4UKLXV57grkYj46OypYtW8TV1VXq6+tN5uTh4WEREens7JTDhw/Ljz/+KAaDQUpKSmTlypWyevVqxljMx9fS5oTZFt8JAwMDolarJTc396b6HL+Tm+r7mMjcnYOZpM0RH374obi7u4uNjY0EBgaaLDU/FwG45VZQUCAiIoODg7Jp0yZZsmSJWFtbi5ubmyQmJkpPT49JO9evX5e0tDRxcnISe3t72bx5801l+vr6JCEhQTQajWg0GklISJD+/n6TMt3d3RITEyP29vbi5OQkaWlpJsu7PmgmnmFibW0ty5Ytk61bt0pLS4tyfnx8XA4dOiRarVZsbW0lPDxcmpqaTNpgbM07ffq0AJD29naT4xy7t6+iouKW80FiYqKIWN54bWxslCeeeEJsbW1Fq9VKVlaWxS+tbS7GBoNh0jl54tl/PT09Eh4eLk5OTmJjYyOenp6Snp5+07O+5mqMzcXXEueE2RTfCXl5eWJvb3/Ts89EOH7Nmer7mMjcnYNVIhb6CHIiIiIiIqI5iL9JIyIiIiIisiBM0oiIiIiIiCwIkzQiIiIiIiILwiSNiIiIiIjIgjBJIyIiIiIisiBM0oiIiIiIiCwIkzQiIiIiIiILwiSNiIiIiIjIgjBJIyKiOSkyMhJ79+6ddvmuri6oVCrU19ffsz4REREBTNKIiMjCqVQqs1tSUtIdtVtcXIw333xz2uWXL18Oo9EIX1/fO3q/23HixAmsWbMGjo6O0Gg0WLVqFTIyMpTzWVlZeOyxx+55P4iIaGbMn+kOEBERmWM0GpXXRUVFeOONN9De3q4cs7e3Nyk/OjoKa2vrKdt1cnK6rX5YWVlBq9XeVp07odPpsGPHDhw9ehRbtmyBSqVCa2srysvL7/l7ExGRZeCVNCIismharVbZHB0doVKplP2hoSEsWrQIx48fR2RkJOzs7PDFF1+gr68P8fHxcHV1hVqthp+fHwoLC03avfF2Rw8PDxw9ehTJycnQaDRwc3PDJ598opy/8XbHyspKqFQqlJeXIzg4GGq1GmFhYSYJJABkZ2fD2dkZGo0GKSkpePXVV81eBTt58iQef/xx7Nu3Dz4+PvD29kZsbCw++OADAMCxY8dw+PBhNDQ0KFcTjx07BgAYGBhAamoqnJ2dsXDhQqxbtw4NDQ1K2xNX4PLy8rB8+XKo1Wo899xzuHLlilKmsrISISEhcHBwwKJFi7B27Vp0d3ffxidGRET/FZM0IiJ64B04cADp6eloa2tDVFQUhoaGEBQUhJMnT6K5uRmpqal4/vnnce7cObPt5OTkIDg4GHV1dXjxxRexe/duXLx40Wyd1157DTk5Obhw4QLmz5+P5ORk5dyXX36JI0eO4O2330ZNTQ3c3NyQm5trtj2tVouWlhY0Nzff8nxcXBwyMjKwatUqGI1GGI1GxMXFQUQQExOD3t5enDp1CjU1NQgMDMT69evx559/KvU7Oztx/PhxfPPNN/juu+9QX1+PPXv2AAD+/vtvxMbGIiIiAo2NjdDr9UhNTYVKpTLbZyIiusuEiIjoAVFQUCCOjo7KvsFgEADy3nvvTVk3OjpaMjIylP2IiAh5+eWXlX13d3fZuXOnsj8+Pi7Ozs6Sm5tr8l51dXUiIlJRUSEARKfTKXVKSkoEgFy/fl1ERNasWSN79uwx6cfatWslICBg0n5eu3ZNoqOjBYC4u7tLXFyc5Ofny9DQkFLm0KFDN7VRXl4uCxcuNCknIuLp6Sl5eXlKPSsrK7l8+bJy/ttvv5V58+aJ0WiUvr4+ASCVlZWT9o+IiO49XkkjIqIHXnBwsMn+2NgYjhw5An9/fyxevBgLFixAaWkpenp6zLbj7++vvJ64rfK3336bdh0XFxcAUOq0t7cjJCTEpPyN+zdycHBASUkJOjs7cfDgQSxYsAAZGRkICQnB4ODgpPVqampw7do15f+d2AwGA37++WelnJubG1xdXZX90NBQjI+Po729HU5OTkhKSkJUVBSeeeYZvP/++ya/CSQiovuDSRoRET3wHBwcTPZzcnLw7rvvYv/+/Thz5gzq6+sRFRWFkZERs+3cuOCISqXC+Pj4tOtM3Bb47zo33iooImbbm+Dp6YmUlBR8+umnqK2tRWtrK4qKiiYtPz4+DhcXF9TX15ts7e3t2Ldv36T1Jvo38begoAB6vR5hYWEoKiqCt7c3zp49O60+ExHR3cEkjYiIZp2qqio8++yz2LlzJwICAvDII4+go6PjvvfDx8cH58+fNzl24cKF227Hw8MDarUaf/31FwDAxsYGY2NjJmUCAwPR29uL+fPnw8vLy2R76KGHlHI9PT345ZdflH29Xo958+bB29tbObZ69WpkZmaiuroavr6++Oqrr267z0REdOeYpBER0azj5eWFsrIyVFdXo62tDbt27UJvb+9978dLL72E/Px8fPbZZ+jo6EB2djYaGxvNLsSRlZWF/fv3o7KyEgaDAXV1dUhOTsbo6Cg2btwI4J+kzWAwoL6+Hn/88QeGh4exYcMGhIaGIjY2FqdPn0ZXVxeqq6tx8OBBk8TQzs4OiYmJaGhoQFVVFdLT07F9+3ZotVoYDAZkZmZCr9eju7sbpaWl+Omnn/Doo4/e81gREdH/MUkjIqJZ5/XXX0dgYCCioqIQGRkJrVaL2NjY+96PhIQEZGZm4pVXXkFgYCAMBgOSkpJgZ2c3aZ2IiAhcunQJL7zwAlauXImnn34avb29KC0thY+PDwBg27ZteOqpp/Dkk09iyZIlKCwshEqlwqlTpxAeHo7k5GR4e3tjx44d6OrqwtKlS5X2vby8sHXrVkRHR2PTpk3w9fXFRx99BABQq9W4ePEitm3bBm9vb6SmpiItLQ27du26t4EiIiITKpnuzfFERET0n23cuBFarRaff/75fX/vrKwsfP3118qz3oiIyDLNn+kOEBERzVaDg4P4+OOPERUVBSsrKxQWFkKn06GsrGymu0ZERBaMSRoREdE9MnELYnZ2NoaHh+Hj44MTJ05gw4YNM901IiKyYLzdkYiIiIiIyIJw4RAiIiIiIiILwiSNiIiIiIjIgjBJIyIiIiIisiBM0oiIiIiIiCwIkzQiIiIiIiILwiSNiIiIiIjIgjBJIyIiIiIisiBM0oiIiIiIiCzI/wAJbKG1MXgffAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n",
    "\n",
    "# 학습률 스케줄 시각화\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec95c4d7-49e1-4b54-bcbc-261e45767928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=4000))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    모델 예측과 실제 정답을 비교하여 정확도를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (Tensor): 모델 출력, shape = (batch_size, seq_len, vocab_size)\n",
    "        y_true (Tensor): 실제 정답 토큰, shape = (batch_size, seq_len)\n",
    "        pad_id (int): 패딩 토큰 ID (정답에 포함되어도 정확도 계산에서 제외)\n",
    "    \n",
    "    Returns:\n",
    "        acc (Tensor): 배치 단위 정확도 (0~1)\n",
    "    \"\"\"\n",
    "    # 1) vocab 차원에서 가장 높은 확률을 가진 토큰 선택\n",
    "    preds = y_pred.argmax(dim=-1)  # shape = (batch_size, seq_len)\n",
    "\n",
    "    # 2) 패딩이 아닌 위치만 선택\n",
    "    mask = (y_true != pad_id)      # shape = (batch_size, seq_len)\n",
    "\n",
    "    # 3) 예측이 정답과 같고, 패딩이 아닌 위치만 True\n",
    "    correct = (preds == y_true) & mask\n",
    "\n",
    "    # 4) 정확도 = 맞춘 토큰 수 / 패딩 제외 전체 토큰 수\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e98edfd5-a328-4d61-b19d-14f1a0c25fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee116c08-9009-4310-ac68-4170a72fe43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    \"\"\"\n",
    "    한 배치(batch)에 대한 학습 단계 수행\n",
    "    \"\"\"\n",
    "    model.train()  \n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch] \n",
    "\n",
    "    optimizer.zero_grad()  # 이전 gradient 초기화\n",
    "\n",
    "    # 1) 모델 forward pass: (batch_size, seq_len, vocab_size) 출력\n",
    "    logits = model(enc_input, dec_input)\n",
    "\n",
    "    # 2) Loss 계산\n",
    "    # CrossEntropyLoss는 (batch_size, vocab_size, seq_len) 형태 필요\n",
    "    # pad_id 위치는 loss 계산에서 무시 가능\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)\n",
    "\n",
    "    # 3) Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 4) 정확도 계산 (패딩 토큰 제외)\n",
    "    acc = accuracy_function(logits, target, pad_id=sp.pad_id())\n",
    "\n",
    "    return loss.item(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e419f5fd-a584-475c-838b-ee5a377dab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    \"\"\"\n",
    "    전체 학습 루프\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            # 배치 학습 수행\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            # 100 스텝마다 로그 출력\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # 학습률 스케줄러 업데이트 (step 단위)\n",
    "            scheduler.step()\n",
    "\n",
    "        # 에포크 평균 Loss, Accuracy 출력\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85bb17da-b1d7-4e97-8142-add8891f2e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.0383, Acc: 0.0000\n",
      "[Epoch 1, Step 100] Loss: 8.9969, Acc: 0.0000\n",
      "[Epoch 1, Step 200] Loss: 9.0644, Acc: 0.0025\n",
      "[Epoch 1, Step 300] Loss: 9.0081, Acc: 0.0023\n",
      "[Epoch 1, Step 400] Loss: 8.9794, Acc: 0.0000\n",
      "[Epoch 1, Step 500] Loss: 9.0225, Acc: 0.0000\n",
      "[Epoch 1, Step 600] Loss: 8.9746, Acc: 0.0024\n",
      "[Epoch 1, Step 700] Loss: 8.9713, Acc: 0.0000\n",
      "[Epoch 1, Step 800] Loss: 8.9830, Acc: 0.0023\n",
      "[Epoch 1, Step 900] Loss: 8.9258, Acc: 0.0000\n",
      "[Epoch 1, Step 1000] Loss: 8.9203, Acc: 0.0025\n",
      "[Epoch 1, Step 1100] Loss: 8.8273, Acc: 0.0216\n",
      "[Epoch 1, Step 1200] Loss: 8.9272, Acc: 0.0076\n",
      "[Epoch 1, Step 1300] Loss: 8.8585, Acc: 0.0216\n",
      "Epoch 1 Completed - Avg Loss: 8.9575, Avg Acc: 0.0047\n",
      "[Epoch 2, Step 0] Loss: 8.8141, Acc: 0.0218\n",
      "[Epoch 2, Step 100] Loss: 8.7983, Acc: 0.0188\n",
      "[Epoch 2, Step 200] Loss: 8.7960, Acc: 0.0340\n",
      "[Epoch 2, Step 300] Loss: 8.7856, Acc: 0.0277\n",
      "[Epoch 2, Step 400] Loss: 8.7337, Acc: 0.0363\n",
      "[Epoch 2, Step 500] Loss: 8.5755, Acc: 0.0560\n",
      "[Epoch 2, Step 600] Loss: 8.6214, Acc: 0.0381\n",
      "[Epoch 2, Step 700] Loss: 8.5548, Acc: 0.0729\n",
      "[Epoch 2, Step 800] Loss: 8.5589, Acc: 0.0495\n",
      "[Epoch 2, Step 900] Loss: 8.4335, Acc: 0.0872\n",
      "[Epoch 2, Step 1000] Loss: 8.4941, Acc: 0.0589\n",
      "[Epoch 2, Step 1100] Loss: 8.4688, Acc: 0.0911\n",
      "[Epoch 2, Step 1200] Loss: 8.3990, Acc: 0.0714\n",
      "[Epoch 2, Step 1300] Loss: 8.0999, Acc: 0.1412\n",
      "Epoch 2 Completed - Avg Loss: 8.5686, Avg Acc: 0.0604\n",
      "[Epoch 3, Step 0] Loss: 8.2478, Acc: 0.0995\n",
      "[Epoch 3, Step 100] Loss: 8.1427, Acc: 0.1066\n",
      "[Epoch 3, Step 200] Loss: 8.0863, Acc: 0.0997\n",
      "[Epoch 3, Step 300] Loss: 7.7517, Acc: 0.1476\n",
      "[Epoch 3, Step 400] Loss: 7.8757, Acc: 0.1288\n",
      "[Epoch 3, Step 500] Loss: 7.9140, Acc: 0.1085\n",
      "[Epoch 3, Step 600] Loss: 8.0129, Acc: 0.0824\n",
      "[Epoch 3, Step 700] Loss: 7.7997, Acc: 0.1026\n",
      "[Epoch 3, Step 800] Loss: 7.7936, Acc: 0.1056\n",
      "[Epoch 3, Step 900] Loss: 7.7693, Acc: 0.0885\n",
      "[Epoch 3, Step 1000] Loss: 7.4697, Acc: 0.1269\n",
      "[Epoch 3, Step 1100] Loss: 7.4782, Acc: 0.1168\n",
      "[Epoch 3, Step 1200] Loss: 7.6635, Acc: 0.0883\n",
      "[Epoch 3, Step 1300] Loss: 7.5984, Acc: 0.1235\n",
      "Epoch 3 Completed - Avg Loss: 7.8287, Avg Acc: 0.1110\n",
      "[Epoch 4, Step 0] Loss: 7.3188, Acc: 0.1367\n",
      "[Epoch 4, Step 100] Loss: 7.5149, Acc: 0.0976\n",
      "[Epoch 4, Step 200] Loss: 7.3514, Acc: 0.1204\n",
      "[Epoch 4, Step 300] Loss: 7.3672, Acc: 0.1211\n",
      "[Epoch 4, Step 400] Loss: 7.3473, Acc: 0.1293\n",
      "[Epoch 4, Step 500] Loss: 7.2787, Acc: 0.1303\n",
      "[Epoch 4, Step 600] Loss: 7.2899, Acc: 0.1173\n",
      "[Epoch 4, Step 700] Loss: 7.4357, Acc: 0.0986\n",
      "[Epoch 4, Step 800] Loss: 7.1544, Acc: 0.1396\n",
      "[Epoch 4, Step 900] Loss: 7.0636, Acc: 0.1360\n",
      "[Epoch 4, Step 1000] Loss: 7.3235, Acc: 0.1109\n",
      "[Epoch 4, Step 1100] Loss: 7.1541, Acc: 0.1231\n",
      "[Epoch 4, Step 1200] Loss: 7.0345, Acc: 0.1608\n",
      "[Epoch 4, Step 1300] Loss: 7.0444, Acc: 0.1517\n",
      "Epoch 4 Completed - Avg Loss: 7.2714, Avg Acc: 0.1226\n",
      "[Epoch 5, Step 0] Loss: 7.2550, Acc: 0.0951\n",
      "[Epoch 5, Step 100] Loss: 6.9898, Acc: 0.1572\n",
      "[Epoch 5, Step 200] Loss: 7.0633, Acc: 0.1651\n",
      "[Epoch 5, Step 300] Loss: 6.9870, Acc: 0.1491\n",
      "[Epoch 5, Step 400] Loss: 6.9004, Acc: 0.1501\n",
      "[Epoch 5, Step 500] Loss: 7.0478, Acc: 0.1351\n",
      "[Epoch 5, Step 600] Loss: 7.0416, Acc: 0.1418\n",
      "[Epoch 5, Step 700] Loss: 6.9162, Acc: 0.1418\n",
      "[Epoch 5, Step 800] Loss: 6.8444, Acc: 0.1395\n",
      "[Epoch 5, Step 900] Loss: 6.9882, Acc: 0.1320\n",
      "[Epoch 5, Step 1000] Loss: 6.8503, Acc: 0.1332\n",
      "[Epoch 5, Step 1100] Loss: 6.8632, Acc: 0.1519\n",
      "[Epoch 5, Step 1200] Loss: 7.1011, Acc: 0.1299\n",
      "[Epoch 5, Step 1300] Loss: 6.7622, Acc: 0.1719\n",
      "Epoch 5 Completed - Avg Loss: 6.9707, Avg Acc: 0.1451\n",
      "[Epoch 6, Step 0] Loss: 6.8201, Acc: 0.1438\n",
      "[Epoch 6, Step 100] Loss: 6.9218, Acc: 0.1448\n",
      "[Epoch 6, Step 200] Loss: 6.6513, Acc: 0.1689\n",
      "[Epoch 6, Step 300] Loss: 6.8317, Acc: 0.1616\n",
      "[Epoch 6, Step 400] Loss: 7.0319, Acc: 0.1520\n",
      "[Epoch 6, Step 500] Loss: 6.8868, Acc: 0.1395\n",
      "[Epoch 6, Step 600] Loss: 6.7742, Acc: 0.1478\n",
      "[Epoch 6, Step 700] Loss: 6.8247, Acc: 0.1481\n",
      "[Epoch 6, Step 800] Loss: 6.7424, Acc: 0.1625\n",
      "[Epoch 6, Step 900] Loss: 6.5066, Acc: 0.1816\n",
      "[Epoch 6, Step 1000] Loss: 6.7138, Acc: 0.1643\n",
      "[Epoch 6, Step 1100] Loss: 6.8825, Acc: 0.1322\n",
      "[Epoch 6, Step 1200] Loss: 6.7614, Acc: 0.1499\n",
      "[Epoch 6, Step 1300] Loss: 6.7224, Acc: 0.1716\n",
      "Epoch 6 Completed - Avg Loss: 6.7303, Avg Acc: 0.1580\n",
      "[Epoch 7, Step 0] Loss: 6.7732, Acc: 0.1275\n",
      "[Epoch 7, Step 100] Loss: 6.6853, Acc: 0.1705\n",
      "[Epoch 7, Step 200] Loss: 6.8209, Acc: 0.1317\n",
      "[Epoch 7, Step 300] Loss: 6.5226, Acc: 0.1671\n",
      "[Epoch 7, Step 400] Loss: 6.6777, Acc: 0.1296\n",
      "[Epoch 7, Step 500] Loss: 6.4840, Acc: 0.1572\n",
      "[Epoch 7, Step 600] Loss: 6.3551, Acc: 0.1804\n",
      "[Epoch 7, Step 700] Loss: 6.5298, Acc: 0.1595\n",
      "[Epoch 7, Step 800] Loss: 6.5370, Acc: 0.1572\n",
      "[Epoch 7, Step 900] Loss: 6.4895, Acc: 0.1729\n",
      "[Epoch 7, Step 1000] Loss: 6.6478, Acc: 0.1469\n",
      "[Epoch 7, Step 1100] Loss: 6.2194, Acc: 0.1778\n",
      "[Epoch 7, Step 1200] Loss: 6.3573, Acc: 0.1888\n",
      "[Epoch 7, Step 1300] Loss: 6.4791, Acc: 0.1500\n",
      "Epoch 7 Completed - Avg Loss: 6.5295, Avg Acc: 0.1646\n",
      "[Epoch 8, Step 0] Loss: 6.4672, Acc: 0.1574\n",
      "[Epoch 8, Step 100] Loss: 6.3370, Acc: 0.1892\n",
      "[Epoch 8, Step 200] Loss: 6.3992, Acc: 0.1695\n",
      "[Epoch 8, Step 300] Loss: 6.4268, Acc: 0.1521\n",
      "[Epoch 8, Step 400] Loss: 6.2898, Acc: 0.1952\n",
      "[Epoch 8, Step 500] Loss: 6.3985, Acc: 0.1772\n",
      "[Epoch 8, Step 600] Loss: 6.3026, Acc: 0.1622\n",
      "[Epoch 8, Step 700] Loss: 6.0656, Acc: 0.1818\n",
      "[Epoch 8, Step 800] Loss: 6.0840, Acc: 0.1709\n",
      "[Epoch 8, Step 900] Loss: 6.4690, Acc: 0.1503\n",
      "[Epoch 8, Step 1000] Loss: 6.1573, Acc: 0.1662\n",
      "[Epoch 8, Step 1100] Loss: 6.5592, Acc: 0.1687\n",
      "[Epoch 8, Step 1200] Loss: 6.2224, Acc: 0.1931\n",
      "[Epoch 8, Step 1300] Loss: 6.2122, Acc: 0.1800\n",
      "Epoch 8 Completed - Avg Loss: 6.3618, Avg Acc: 0.1652\n",
      "[Epoch 9, Step 0] Loss: 6.1757, Acc: 0.1751\n",
      "[Epoch 9, Step 100] Loss: 6.1044, Acc: 0.1713\n",
      "[Epoch 9, Step 200] Loss: 6.1625, Acc: 0.1559\n",
      "[Epoch 9, Step 300] Loss: 6.2508, Acc: 0.1689\n",
      "[Epoch 9, Step 400] Loss: 6.3084, Acc: 0.1757\n",
      "[Epoch 9, Step 500] Loss: 6.2257, Acc: 0.1576\n",
      "[Epoch 9, Step 600] Loss: 6.3410, Acc: 0.1512\n",
      "[Epoch 9, Step 700] Loss: 6.2329, Acc: 0.1419\n",
      "[Epoch 9, Step 800] Loss: 6.4121, Acc: 0.1474\n",
      "[Epoch 9, Step 900] Loss: 6.0461, Acc: 0.2000\n",
      "[Epoch 9, Step 1000] Loss: 6.1537, Acc: 0.1878\n",
      "[Epoch 9, Step 1100] Loss: 6.1254, Acc: 0.1698\n",
      "[Epoch 9, Step 1200] Loss: 6.0874, Acc: 0.1710\n",
      "[Epoch 9, Step 1300] Loss: 6.3909, Acc: 0.1529\n",
      "Epoch 9 Completed - Avg Loss: 6.2193, Avg Acc: 0.1657\n",
      "[Epoch 10, Step 0] Loss: 5.9488, Acc: 0.1778\n",
      "[Epoch 10, Step 100] Loss: 5.9376, Acc: 0.1703\n",
      "[Epoch 10, Step 200] Loss: 6.3243, Acc: 0.1383\n",
      "[Epoch 10, Step 300] Loss: 6.1180, Acc: 0.1679\n",
      "[Epoch 10, Step 400] Loss: 5.8572, Acc: 0.1813\n",
      "[Epoch 10, Step 500] Loss: 6.0257, Acc: 0.1904\n",
      "[Epoch 10, Step 600] Loss: 6.3221, Acc: 0.1629\n",
      "[Epoch 10, Step 700] Loss: 6.1477, Acc: 0.1562\n",
      "[Epoch 10, Step 800] Loss: 6.0425, Acc: 0.1630\n",
      "[Epoch 10, Step 900] Loss: 6.1491, Acc: 0.1636\n",
      "[Epoch 10, Step 1000] Loss: 6.1600, Acc: 0.1626\n",
      "[Epoch 10, Step 1100] Loss: 6.2905, Acc: 0.1383\n",
      "[Epoch 10, Step 1200] Loss: 6.2224, Acc: 0.1406\n",
      "[Epoch 10, Step 1300] Loss: 6.1177, Acc: 0.1759\n",
      "Epoch 10 Completed - Avg Loss: 6.1014, Avg Acc: 0.1681\n",
      "[Epoch 11, Step 0] Loss: 6.1404, Acc: 0.1558\n",
      "[Epoch 11, Step 100] Loss: 5.9679, Acc: 0.1867\n",
      "[Epoch 11, Step 200] Loss: 5.9545, Acc: 0.1824\n",
      "[Epoch 11, Step 300] Loss: 6.1651, Acc: 0.1574\n",
      "[Epoch 11, Step 400] Loss: 6.0620, Acc: 0.1777\n",
      "[Epoch 11, Step 500] Loss: 5.9052, Acc: 0.1788\n",
      "[Epoch 11, Step 600] Loss: 5.8662, Acc: 0.1763\n",
      "[Epoch 11, Step 700] Loss: 5.7289, Acc: 0.2072\n",
      "[Epoch 11, Step 800] Loss: 6.1269, Acc: 0.1833\n",
      "[Epoch 11, Step 900] Loss: 5.8445, Acc: 0.1800\n",
      "[Epoch 11, Step 1000] Loss: 5.9020, Acc: 0.1548\n",
      "[Epoch 11, Step 1100] Loss: 5.7787, Acc: 0.2197\n",
      "[Epoch 11, Step 1200] Loss: 5.9943, Acc: 0.1923\n",
      "[Epoch 11, Step 1300] Loss: 5.9851, Acc: 0.1714\n",
      "Epoch 11 Completed - Avg Loss: 5.9997, Avg Acc: 0.1732\n",
      "[Epoch 12, Step 0] Loss: 5.7706, Acc: 0.2078\n",
      "[Epoch 12, Step 100] Loss: 6.0879, Acc: 0.1637\n",
      "[Epoch 12, Step 200] Loss: 6.0092, Acc: 0.1682\n",
      "[Epoch 12, Step 300] Loss: 5.8606, Acc: 0.1769\n",
      "[Epoch 12, Step 400] Loss: 5.9874, Acc: 0.2041\n",
      "[Epoch 12, Step 500] Loss: 5.9904, Acc: 0.1560\n",
      "[Epoch 12, Step 600] Loss: 5.8114, Acc: 0.1973\n",
      "[Epoch 12, Step 700] Loss: 5.9052, Acc: 0.1615\n",
      "[Epoch 12, Step 800] Loss: 5.6920, Acc: 0.1849\n",
      "[Epoch 12, Step 900] Loss: 5.9628, Acc: 0.1732\n",
      "[Epoch 12, Step 1000] Loss: 5.8061, Acc: 0.1744\n",
      "[Epoch 12, Step 1100] Loss: 5.8906, Acc: 0.1885\n",
      "[Epoch 12, Step 1200] Loss: 5.7238, Acc: 0.1811\n",
      "[Epoch 12, Step 1300] Loss: 6.0104, Acc: 0.1754\n",
      "Epoch 12 Completed - Avg Loss: 5.9165, Avg Acc: 0.1774\n",
      "[Epoch 13, Step 0] Loss: 6.0109, Acc: 0.1534\n",
      "[Epoch 13, Step 100] Loss: 5.8358, Acc: 0.1989\n",
      "[Epoch 13, Step 200] Loss: 5.8636, Acc: 0.1774\n",
      "[Epoch 13, Step 300] Loss: 5.8708, Acc: 0.1712\n",
      "[Epoch 13, Step 400] Loss: 5.8022, Acc: 0.1716\n",
      "[Epoch 13, Step 500] Loss: 5.8929, Acc: 0.1825\n",
      "[Epoch 13, Step 600] Loss: 6.0453, Acc: 0.1523\n",
      "[Epoch 13, Step 700] Loss: 6.1019, Acc: 0.1526\n",
      "[Epoch 13, Step 800] Loss: 5.5186, Acc: 0.2205\n",
      "[Epoch 13, Step 900] Loss: 5.9721, Acc: 0.1524\n",
      "[Epoch 13, Step 1000] Loss: 5.8761, Acc: 0.1714\n",
      "[Epoch 13, Step 1100] Loss: 5.7813, Acc: 0.1784\n",
      "[Epoch 13, Step 1200] Loss: 5.8361, Acc: 0.1689\n",
      "[Epoch 13, Step 1300] Loss: 5.9192, Acc: 0.1607\n",
      "Epoch 13 Completed - Avg Loss: 5.8435, Avg Acc: 0.1797\n",
      "[Epoch 14, Step 0] Loss: 5.7734, Acc: 0.1827\n",
      "[Epoch 14, Step 100] Loss: 5.6958, Acc: 0.1946\n",
      "[Epoch 14, Step 200] Loss: 5.9685, Acc: 0.1864\n",
      "[Epoch 14, Step 300] Loss: 5.7185, Acc: 0.2379\n",
      "[Epoch 14, Step 400] Loss: 5.7208, Acc: 0.1716\n",
      "[Epoch 14, Step 500] Loss: 5.9460, Acc: 0.1684\n",
      "[Epoch 14, Step 600] Loss: 5.8118, Acc: 0.1683\n",
      "[Epoch 14, Step 700] Loss: 5.7781, Acc: 0.1823\n",
      "[Epoch 14, Step 800] Loss: 5.6386, Acc: 0.1926\n",
      "[Epoch 14, Step 900] Loss: 5.8311, Acc: 0.1756\n",
      "[Epoch 14, Step 1000] Loss: 5.6326, Acc: 0.1788\n",
      "[Epoch 14, Step 1100] Loss: 5.7694, Acc: 0.1758\n",
      "[Epoch 14, Step 1200] Loss: 5.8384, Acc: 0.2016\n",
      "[Epoch 14, Step 1300] Loss: 5.7178, Acc: 0.1918\n",
      "Epoch 14 Completed - Avg Loss: 5.7812, Avg Acc: 0.1806\n",
      "[Epoch 15, Step 0] Loss: 5.7627, Acc: 0.1861\n",
      "[Epoch 15, Step 100] Loss: 6.0572, Acc: 0.1535\n",
      "[Epoch 15, Step 200] Loss: 5.8757, Acc: 0.1789\n",
      "[Epoch 15, Step 300] Loss: 5.7823, Acc: 0.1736\n",
      "[Epoch 15, Step 400] Loss: 5.6932, Acc: 0.1807\n",
      "[Epoch 15, Step 500] Loss: 5.8360, Acc: 0.1905\n",
      "[Epoch 15, Step 600] Loss: 5.8495, Acc: 0.1671\n",
      "[Epoch 15, Step 700] Loss: 5.6117, Acc: 0.1897\n",
      "[Epoch 15, Step 800] Loss: 5.8479, Acc: 0.1663\n",
      "[Epoch 15, Step 900] Loss: 5.6219, Acc: 0.1738\n",
      "[Epoch 15, Step 1000] Loss: 5.7184, Acc: 0.2070\n",
      "[Epoch 15, Step 1100] Loss: 5.9099, Acc: 0.1855\n",
      "[Epoch 15, Step 1200] Loss: 5.6034, Acc: 0.1913\n",
      "[Epoch 15, Step 1300] Loss: 5.7725, Acc: 0.1623\n",
      "Epoch 15 Completed - Avg Loss: 5.7283, Avg Acc: 0.1808\n",
      "[Epoch 16, Step 0] Loss: 5.5420, Acc: 0.1791\n",
      "[Epoch 16, Step 100] Loss: 5.7769, Acc: 0.1955\n",
      "[Epoch 16, Step 200] Loss: 5.5292, Acc: 0.1952\n",
      "[Epoch 16, Step 300] Loss: 5.7822, Acc: 0.1759\n",
      "[Epoch 16, Step 400] Loss: 5.7699, Acc: 0.1758\n",
      "[Epoch 16, Step 500] Loss: 5.6894, Acc: 0.1914\n",
      "[Epoch 16, Step 600] Loss: 5.6050, Acc: 0.1802\n",
      "[Epoch 16, Step 700] Loss: 5.7576, Acc: 0.1795\n",
      "[Epoch 16, Step 800] Loss: 5.5998, Acc: 0.2085\n",
      "[Epoch 16, Step 900] Loss: 5.7248, Acc: 0.1865\n",
      "[Epoch 16, Step 1000] Loss: 5.6923, Acc: 0.1667\n",
      "[Epoch 16, Step 1100] Loss: 5.7524, Acc: 0.1724\n",
      "[Epoch 16, Step 1200] Loss: 5.5933, Acc: 0.1952\n",
      "[Epoch 16, Step 1300] Loss: 5.6993, Acc: 0.1835\n",
      "Epoch 16 Completed - Avg Loss: 5.6824, Avg Acc: 0.1812\n",
      "[Epoch 17, Step 0] Loss: 5.7733, Acc: 0.1881\n",
      "[Epoch 17, Step 100] Loss: 5.3698, Acc: 0.2099\n",
      "[Epoch 17, Step 200] Loss: 5.8898, Acc: 0.1620\n",
      "[Epoch 17, Step 300] Loss: 5.4796, Acc: 0.2071\n",
      "[Epoch 17, Step 400] Loss: 5.6824, Acc: 0.1724\n",
      "[Epoch 17, Step 500] Loss: 5.6715, Acc: 0.1612\n",
      "[Epoch 17, Step 600] Loss: 5.8080, Acc: 0.1953\n",
      "[Epoch 17, Step 700] Loss: 5.4090, Acc: 0.1954\n",
      "[Epoch 17, Step 800] Loss: 5.5160, Acc: 0.1950\n",
      "[Epoch 17, Step 900] Loss: 5.9476, Acc: 0.1519\n",
      "[Epoch 17, Step 1000] Loss: 5.8122, Acc: 0.1698\n",
      "[Epoch 17, Step 1100] Loss: 5.5337, Acc: 0.1718\n",
      "[Epoch 17, Step 1200] Loss: 5.8281, Acc: 0.1688\n",
      "[Epoch 17, Step 1300] Loss: 5.6390, Acc: 0.1924\n",
      "Epoch 17 Completed - Avg Loss: 5.6413, Avg Acc: 0.1816\n",
      "[Epoch 18, Step 0] Loss: 5.5623, Acc: 0.1873\n",
      "[Epoch 18, Step 100] Loss: 5.5065, Acc: 0.1929\n",
      "[Epoch 18, Step 200] Loss: 5.6437, Acc: 0.1542\n",
      "[Epoch 18, Step 300] Loss: 5.6896, Acc: 0.1853\n",
      "[Epoch 18, Step 400] Loss: 5.7520, Acc: 0.1561\n",
      "[Epoch 18, Step 500] Loss: 5.4250, Acc: 0.1924\n",
      "[Epoch 18, Step 600] Loss: 5.6201, Acc: 0.1960\n",
      "[Epoch 18, Step 700] Loss: 5.4830, Acc: 0.1816\n",
      "[Epoch 18, Step 800] Loss: 5.5395, Acc: 0.1751\n",
      "[Epoch 18, Step 900] Loss: 5.7309, Acc: 0.1745\n",
      "[Epoch 18, Step 1000] Loss: 5.3771, Acc: 0.1799\n",
      "[Epoch 18, Step 1100] Loss: 5.6405, Acc: 0.1528\n",
      "[Epoch 18, Step 1200] Loss: 5.6351, Acc: 0.1886\n",
      "[Epoch 18, Step 1300] Loss: 5.5559, Acc: 0.1720\n",
      "Epoch 18 Completed - Avg Loss: 5.6071, Avg Acc: 0.1818\n",
      "[Epoch 19, Step 0] Loss: 5.7621, Acc: 0.1527\n",
      "[Epoch 19, Step 100] Loss: 5.8832, Acc: 0.1642\n",
      "[Epoch 19, Step 200] Loss: 5.6951, Acc: 0.1857\n",
      "[Epoch 19, Step 300] Loss: 5.3880, Acc: 0.2041\n",
      "[Epoch 19, Step 400] Loss: 5.8241, Acc: 0.1678\n",
      "[Epoch 19, Step 500] Loss: 5.6047, Acc: 0.1646\n",
      "[Epoch 19, Step 600] Loss: 5.6706, Acc: 0.1791\n",
      "[Epoch 19, Step 700] Loss: 5.6891, Acc: 0.1681\n",
      "[Epoch 19, Step 800] Loss: 5.6508, Acc: 0.1754\n",
      "[Epoch 19, Step 900] Loss: 5.6039, Acc: 0.1674\n",
      "[Epoch 19, Step 1000] Loss: 5.3327, Acc: 0.1781\n",
      "[Epoch 19, Step 1100] Loss: 5.6353, Acc: 0.2141\n",
      "[Epoch 19, Step 1200] Loss: 5.4448, Acc: 0.1681\n",
      "[Epoch 19, Step 1300] Loss: 5.4004, Acc: 0.1786\n",
      "Epoch 19 Completed - Avg Loss: 5.5754, Avg Acc: 0.1824\n",
      "[Epoch 20, Step 0] Loss: 5.7964, Acc: 0.1702\n",
      "[Epoch 20, Step 100] Loss: 5.6978, Acc: 0.1674\n",
      "[Epoch 20, Step 200] Loss: 5.5660, Acc: 0.1750\n",
      "[Epoch 20, Step 300] Loss: 5.5044, Acc: 0.1708\n",
      "[Epoch 20, Step 400] Loss: 5.6103, Acc: 0.1642\n",
      "[Epoch 20, Step 500] Loss: 5.7649, Acc: 0.1603\n",
      "[Epoch 20, Step 600] Loss: 5.4210, Acc: 0.1856\n",
      "[Epoch 20, Step 700] Loss: 5.6242, Acc: 0.1841\n",
      "[Epoch 20, Step 800] Loss: 5.6212, Acc: 0.1944\n",
      "[Epoch 20, Step 900] Loss: 5.2555, Acc: 0.2122\n",
      "[Epoch 20, Step 1000] Loss: 5.4342, Acc: 0.1820\n",
      "[Epoch 20, Step 1100] Loss: 5.4485, Acc: 0.2152\n",
      "[Epoch 20, Step 1200] Loss: 5.2319, Acc: 0.2382\n",
      "[Epoch 20, Step 1300] Loss: 5.3812, Acc: 0.2275\n",
      "Epoch 20 Completed - Avg Loss: 5.5467, Avg Acc: 0.1830\n",
      "[Epoch 21, Step 0] Loss: 5.7892, Acc: 0.1628\n",
      "[Epoch 21, Step 100] Loss: 5.3486, Acc: 0.1979\n",
      "[Epoch 21, Step 200] Loss: 5.6590, Acc: 0.1769\n",
      "[Epoch 21, Step 300] Loss: 5.6300, Acc: 0.1720\n",
      "[Epoch 21, Step 400] Loss: 5.4330, Acc: 0.2086\n",
      "[Epoch 21, Step 500] Loss: 5.4677, Acc: 0.1979\n",
      "[Epoch 21, Step 600] Loss: 5.4455, Acc: 0.1922\n",
      "[Epoch 21, Step 700] Loss: 5.2638, Acc: 0.1789\n",
      "[Epoch 21, Step 800] Loss: 5.5872, Acc: 0.1746\n",
      "[Epoch 21, Step 900] Loss: 5.5333, Acc: 0.1699\n",
      "[Epoch 21, Step 1000] Loss: 5.5069, Acc: 0.1888\n",
      "[Epoch 21, Step 1100] Loss: 5.6367, Acc: 0.1632\n",
      "[Epoch 21, Step 1200] Loss: 5.5288, Acc: 0.1961\n",
      "[Epoch 21, Step 1300] Loss: 5.3228, Acc: 0.1985\n",
      "Epoch 21 Completed - Avg Loss: 5.5238, Avg Acc: 0.1836\n",
      "[Epoch 22, Step 0] Loss: 5.8016, Acc: 0.1748\n",
      "[Epoch 22, Step 100] Loss: 5.6027, Acc: 0.1794\n",
      "[Epoch 22, Step 200] Loss: 5.5074, Acc: 0.1821\n",
      "[Epoch 22, Step 300] Loss: 5.6800, Acc: 0.1799\n",
      "[Epoch 22, Step 400] Loss: 5.3193, Acc: 0.1811\n",
      "[Epoch 22, Step 500] Loss: 5.4564, Acc: 0.1884\n",
      "[Epoch 22, Step 600] Loss: 5.6121, Acc: 0.1802\n",
      "[Epoch 22, Step 700] Loss: 5.4437, Acc: 0.2044\n",
      "[Epoch 22, Step 800] Loss: 5.4332, Acc: 0.2090\n",
      "[Epoch 22, Step 900] Loss: 5.7040, Acc: 0.1754\n",
      "[Epoch 22, Step 1000] Loss: 5.2129, Acc: 0.2276\n",
      "[Epoch 22, Step 1100] Loss: 5.5663, Acc: 0.1770\n",
      "[Epoch 22, Step 1200] Loss: 5.6894, Acc: 0.1754\n",
      "[Epoch 22, Step 1300] Loss: 5.4838, Acc: 0.1807\n",
      "Epoch 22 Completed - Avg Loss: 5.5001, Avg Acc: 0.1852\n",
      "[Epoch 23, Step 0] Loss: 5.3060, Acc: 0.1866\n",
      "[Epoch 23, Step 100] Loss: 5.3887, Acc: 0.2012\n",
      "[Epoch 23, Step 200] Loss: 5.4151, Acc: 0.1854\n",
      "[Epoch 23, Step 300] Loss: 5.5597, Acc: 0.1897\n",
      "[Epoch 23, Step 400] Loss: 5.3483, Acc: 0.2047\n",
      "[Epoch 23, Step 500] Loss: 5.4323, Acc: 0.1766\n",
      "[Epoch 23, Step 600] Loss: 5.4678, Acc: 0.2044\n",
      "[Epoch 23, Step 700] Loss: 5.2861, Acc: 0.1962\n",
      "[Epoch 23, Step 800] Loss: 5.1011, Acc: 0.2033\n",
      "[Epoch 23, Step 900] Loss: 5.4115, Acc: 0.1891\n",
      "[Epoch 23, Step 1000] Loss: 5.4782, Acc: 0.2032\n",
      "[Epoch 23, Step 1100] Loss: 5.6901, Acc: 0.1594\n",
      "[Epoch 23, Step 1200] Loss: 5.7005, Acc: 0.1603\n",
      "[Epoch 23, Step 1300] Loss: 5.6912, Acc: 0.1618\n",
      "Epoch 23 Completed - Avg Loss: 5.4800, Avg Acc: 0.1871\n",
      "[Epoch 24, Step 0] Loss: 5.3101, Acc: 0.2149\n",
      "[Epoch 24, Step 100] Loss: 5.6486, Acc: 0.1644\n",
      "[Epoch 24, Step 200] Loss: 5.4009, Acc: 0.1858\n",
      "[Epoch 24, Step 300] Loss: 5.6100, Acc: 0.1838\n",
      "[Epoch 24, Step 400] Loss: 5.5151, Acc: 0.2102\n",
      "[Epoch 24, Step 500] Loss: 5.4454, Acc: 0.1960\n",
      "[Epoch 24, Step 600] Loss: 5.5615, Acc: 0.1820\n",
      "[Epoch 24, Step 700] Loss: 5.5423, Acc: 0.1872\n",
      "[Epoch 24, Step 800] Loss: 5.3440, Acc: 0.2069\n",
      "[Epoch 24, Step 900] Loss: 5.6836, Acc: 0.1852\n",
      "[Epoch 24, Step 1000] Loss: 5.2622, Acc: 0.2188\n",
      "[Epoch 24, Step 1100] Loss: 5.2167, Acc: 0.1960\n",
      "[Epoch 24, Step 1200] Loss: 5.7942, Acc: 0.1687\n",
      "[Epoch 24, Step 1300] Loss: 5.3706, Acc: 0.1825\n",
      "Epoch 24 Completed - Avg Loss: 5.4625, Avg Acc: 0.1889\n",
      "[Epoch 25, Step 0] Loss: 5.1889, Acc: 0.2030\n",
      "[Epoch 25, Step 100] Loss: 5.4083, Acc: 0.1800\n",
      "[Epoch 25, Step 200] Loss: 5.3518, Acc: 0.1935\n",
      "[Epoch 25, Step 300] Loss: 5.4643, Acc: 0.1893\n",
      "[Epoch 25, Step 400] Loss: 5.2815, Acc: 0.2393\n",
      "[Epoch 25, Step 500] Loss: 5.2399, Acc: 0.2078\n",
      "[Epoch 25, Step 600] Loss: 5.1441, Acc: 0.2113\n",
      "[Epoch 25, Step 700] Loss: 5.6574, Acc: 0.1944\n",
      "[Epoch 25, Step 800] Loss: 5.5204, Acc: 0.1675\n",
      "[Epoch 25, Step 900] Loss: 5.4514, Acc: 0.2070\n",
      "[Epoch 25, Step 1000] Loss: 5.6747, Acc: 0.1988\n",
      "[Epoch 25, Step 1100] Loss: 5.3378, Acc: 0.1927\n",
      "[Epoch 25, Step 1200] Loss: 5.4888, Acc: 0.1787\n",
      "[Epoch 25, Step 1300] Loss: 5.6985, Acc: 0.1642\n",
      "Epoch 25 Completed - Avg Loss: 5.4453, Avg Acc: 0.1911\n",
      "CPU times: user 21min 17s, sys: 3.3 s, total: 21min 20s\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=25,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62234e44-cdaf-44bf-ad7c-465ce752ffb9",
   "metadata": {},
   "source": [
    "# 14. 챗봇 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db0488be-19f1-4372-b8bc-22cec16196f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    \"\"\"\n",
    "    Transformer 디코더를 이용한 시퀀스 생성 (Inference)\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 Transformer 모델\n",
    "        sentence: 입력 문장 (string)\n",
    "        tokenizer: SentencePiece tokenizer\n",
    "        device: 연산 디바이스 ('cpu' 또는 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        output_sequence: 생성된 토큰 ID 시퀀스 (list of int)\n",
    "    \"\"\"\n",
    "    # 특수 토큰\n",
    "    START_TOKEN = tokenizer.bos_id()   # <s> (문장 시작)\n",
    "    END_TOKEN = tokenizer.eos_id()     # </s> (문장 종료)\n",
    "    MAX_LENGTH = 40                    # 생성 최대 길이\n",
    "\n",
    "    # 1) 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 2) 인코더 입력 생성: [START] + 토큰화 + [END]\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # 차원 확장: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 3) 디코더 입력 초기화: START_TOKEN만 포함\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # 평가 모드로 전환 (dropout 등 비활성화)\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 4) 모델 forward\n",
    "            # enc_input: 인코더 입력\n",
    "            # dec_input: 지금까지 생성된 디코더 입력\n",
    "            logits = model(enc_input, dec_input)  # (batch_size=1, seq_len, vocab_size)\n",
    "\n",
    "            # 5) 마지막 시점의 예측만 사용\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # 6) argmax로 가장 높은 확률의 토큰 선택\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # (1,)\n",
    "\n",
    "            # 7) 종료 토큰이면 생성 중단\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # 8) 디코더 입력에 예측 토큰 추가\n",
    "            predicted_id = predicted_id.unsqueeze(0)      # (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)  # (1, seq_len+1)\n",
    "\n",
    "    # 9) 최종 출력 시퀀스: batch 차원 제거\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., 토큰들...]\n",
    "\n",
    "    return output_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51c24bdb-3ab3-48ff-a635-958f8ef0da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    \"\"\"\n",
    "    Transformer 모델을 이용해 입력 문장에 대한 응답 문장 생성\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 Transformer 모델\n",
    "        sentence: 입력 문장 (string)\n",
    "        tokenizer: SentencePiece tokenizer\n",
    "        device: 연산 디바이스 ('cpu' 또는 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        predicted_sentence: 모델이 생성한 문장 (string)\n",
    "    \"\"\"\n",
    "    # 1) 디코더 인퍼런스를 통해 예측된 토큰 ID 시퀀스 생성\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 2) 토크나이저로 디코딩\n",
    "    # - START/END 토큰 및 패딩 토큰은 제거\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    # 3) 결과 출력\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50205587-013e-4af4-ad7d-c34fd5c9af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m .'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Where have you been?'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c73a7de9-cb56-44ad-aee3-de3888d35bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : i m .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"It's a trap\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
